{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trey Tuscai and Gordon Doore\n",
    "\n",
    "Spring 2025\n",
    "\n",
    "CS 444: Deep Learning\n",
    "\n",
    "Project 2: Branch Neural Networks\n",
    "\n",
    "#### Week 2: Residual networks\n",
    "\n",
    "The focus this week is on the ResNet architecture. You will build several neural networks in the ResNet family and and train them on CIFAR-10 and CIFAR-100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=7)\n",
    "\n",
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: The Residual Block\n",
    "\n",
    "This task focuses on implementing and testing the **Residual Block** in preparation of creating the first ResNet (**ResNet-8**). \n",
    "\n",
    "Much like how Inception Blocks represent the building blocks of Inception Net, stacks of Residual Blocks represent the basis of ResNet. Residual Blocks possess a simpler structure than Inception Blocks — they only contain two parallel branches with fewer layers. Here is a refresher on the structure of the branches:\n",
    "\n",
    "**Main branch:** sequence of two 2D convolutional layers.\n",
    "\n",
    "**Residual branch:** the input signal to the Residual Block passes through \"as-is\", without modification (usually).\n",
    "\n",
    "Like Inception Block, the output of both branches comes together at the end of the block. However, the branch outputs are SUMMED together rather than being concatenated.\n",
    "\n",
    "\n",
    "This is the story for most Residual Blocks, however, like most CNNs:\n",
    "1. the spatial resolution of the activations occasionally decreases\n",
    "2. the number of conv filters/neurons increases\n",
    "\n",
    "as we go deeper in a ResNet. Both of these factors tend to change *at the same time* in a small number of Residual Blocks located at various depths of the ResNet. Put another way, the spatial resolution and number of filters tends to remain constant across most successive Residual Blocks and they only changes in a few blocks throughout the net.\n",
    "1. The decrease in spatial resolution is implemented in these small number of Residual Blocks with a convolutional stride > 1.\n",
    "2. A 1x1 convolutional layer is needed as the \"special sauce\" along the residual branch to make the shapes of signals in both branches match (*otherwise they could not be summed!*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a. Implement and test the Residual Block\n",
    "\n",
    "The class is in `residual_block.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from residual_block import ResidualBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: `ResidualBlock` Stride 1 (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestResidualBlock_S1:\n",
      "\tConv2D layer output(TestResidualBlock_S1/main_3x3conv_2) shape: [1, 4, 4, 7]\n",
      "\tConv2D layer output(TestResidualBlock_S1/main_3x3conv_1) shape: [1, 4, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "# Testing architecture and shapes\n",
    "# Stride 1\n",
    "tf.random.set_seed(0)\n",
    "res1 = ResidualBlock('TestResidualBlock_S1', 7, prev_layer_or_block=None, strides=1)\n",
    "res1(tf.ones([1, 4, 4, 7]))\n",
    "print(res1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell should print:\n",
    "\n",
    "```\n",
    "TestResidualBlock_S1:\n",
    "\tConv2D layer output(TestResidualBlock_S1/main_3x3conv_2) shape: [1, 4, 4, 7]\n",
    "\tConv2D layer output(TestResidualBlock_S1/main_3x3conv_1) shape: [1, 4, 4, 7]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the netAct output from the block is (2, 4, 4, 7) and should be (2, 4, 4, 7)\n",
      "The first few activations are:\n",
      "[[0.        0.5208229 0.1888617 0.       ]\n",
      " [0.        0.7621396 0.1734907 0.8486799]\n",
      " [0.        0.6156112 0.4272217 0.       ]\n",
      " [0.5561852 0.4888234 1.0138505 0.5533389]]\n",
      "and should be:\n",
      "[[0.        0.520823  0.1888617 0.       ]\n",
      " [0.        0.7621396 0.1734907 0.8486798]\n",
      " [0.        0.6156113 0.4272216 0.       ]\n",
      " [0.5561852 0.4888234 1.0138503 0.5533389]]\n"
     ]
    }
   ],
   "source": [
    "# Test activations\n",
    "tf.random.set_seed(0)\n",
    "net_acts1 = res1(tf.random.uniform([2, 4, 4, 7]))\n",
    "print(f'The shape of the netAct output from the block is {net_acts1.shape} and should be (2, 4, 4, 7)')\n",
    "print(f'The first few activations are:\\n{net_acts1[0,:,:, 0]}')\n",
    "print('and should be:')\n",
    "print('''[[0.        0.520823  0.1888617 0.       ]\n",
    " [0.        0.7621396 0.1734907 0.8486798]\n",
    " [0.        0.6156113 0.4272216 0.       ]\n",
    " [0.5561852 0.4888234 1.0138503 0.5533389]]''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: `ResidualBlock` Stride 2 (2/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestResidualBlock_S2:\n",
      "\tConv2D layer output(TestResidualBlock_S2/main_3x3conv_2) shape: [1, 3, 3, 5]\n",
      "\tConv2D layer output(TestResidualBlock_S2/main_3x3conv_1) shape: [1, 3, 3, 5]\n",
      "\t-->Conv2D1x1 layer output(TestResidualBlock_S2/skip_conv1x1) shape: [1, 3, 3, 5]-->\n"
     ]
    }
   ],
   "source": [
    "# Testing architecture and shapes\n",
    "# Stride 2\n",
    "tf.random.set_seed(0)\n",
    "res2 = ResidualBlock('TestResidualBlock_S2', 5, prev_layer_or_block=None, strides=2)\n",
    "res2(tf.ones([1, 6, 6, 5]))\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell should print:\n",
    "\n",
    "```\n",
    "TestResidualBlock_S2:\n",
    "\tConv2D layer output(TestResidualBlock_S2/main_3x3conv_2) shape: [1, 3, 3, 5]\n",
    "\tConv2D layer output(TestResidualBlock_S2/main_3x3conv_1) shape: [1, 3, 3, 5]\n",
    "\t-->Conv2D1x1 layer output(TestResidualBlock_S2/skip_conv1x1) shape: [1, 3, 3, 5]-->\n",
    "```\n",
    "\n",
    "*The layer with the --> is the residual branch.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the netAct output from the block is (3, 3, 3, 5) and should be (3, 3, 3, 5)\n",
      "The first few activations are:\n",
      "[[[0.2403671 0.        0.        0.2852962 0.       ]\n",
      "  [0.        0.        0.        0.1339119 0.6897169]\n",
      "  [0.        0.        0.        0.4595791 0.2781491]]\n",
      "\n",
      " [[0.        0.        0.        0.6591121 1.3700994]\n",
      "  [0.2664362 0.        0.        0.9615825 0.       ]\n",
      "  [0.        0.        0.        0.3844296 0.7109971]]\n",
      "\n",
      " [[0.0933685 0.        0.        0.1379156 0.3004903]\n",
      "  [0.1871759 0.        0.        0.4464865 1.1061924]\n",
      "  [0.        0.        0.        0.7911265 0.3450609]]]\n",
      "and should be:\n",
      "[[[0.2404823 0.        0.        0.2851936 0.       ]\n",
      "  [0.        0.        0.        0.1339086 0.6898913]\n",
      "  [0.        0.        0.        0.4596353 0.2781557]]\n",
      "\n",
      " [[0.        0.        0.        0.6591434 1.3703969]\n",
      "  [0.2665227 0.        0.        0.9614864 0.       ]\n",
      "  [0.        0.        0.        0.3844326 0.7111533]]\n",
      "\n",
      " [[0.0933782 0.        0.        0.1378801 0.3006183]\n",
      "  [0.1873689 0.        0.        0.4464224 1.1067129]\n",
      "  [0.        0.        0.        0.7910071 0.345379 ]]]\n"
     ]
    }
   ],
   "source": [
    "# Test activations\n",
    "tf.random.set_seed(0)\n",
    "net_acts2 = res2(tf.random.uniform([3, 6, 6, 5]))\n",
    "print(f'The shape of the netAct output from the block is {net_acts2.shape} and should be (3, 3, 3, 5)')\n",
    "print(f'The first few activations are:\\n{net_acts2[0,:,:, :]}')\n",
    "print('and should be:')\n",
    "print('''[[[0.2404823 0.        0.        0.2851936 0.       ]\n",
    "  [0.        0.        0.        0.1339086 0.6898913]\n",
    "  [0.        0.        0.        0.4596353 0.2781557]]\n",
    "\n",
    " [[0.        0.        0.        0.6591434 1.3703969]\n",
    "  [0.2665227 0.        0.        0.9614864 0.       ]\n",
    "  [0.        0.        0.        0.3844326 0.7111533]]\n",
    "\n",
    " [[0.0933782 0.        0.        0.1378801 0.3006183]\n",
    "  [0.1873689 0.        0.        0.4464224 1.1067129]\n",
    "  [0.        0.        0.        0.7910071 0.345379 ]]]''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: ResNet-8\n",
    "\n",
    "Assemble the Residual Blocks and several other layers to build ResNet-8:\n",
    "\n",
    "Conv2D → ResidualBlock → ResidualBlock → ResidualBlock → GlobalAveragePooling2D → Dense\n",
    "\n",
    "After an overfit test to help check whether the network is working, you will train the network on both CIFAR-10 and CIFAR-100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnets import ResNet8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7a. Build ResNet-8\n",
    "\n",
    "Implement the following classes in `resnets.py`:\n",
    "1. `ResNet`: Parent class of all specific ResNets (e.g. ResNet-8, ResNet-18, etc.). Having this class helps reduce code size/duplication because the forward pass thru all ResNets is exactly the same!\n",
    "2. `ResNet8`: Assemble the first (*and smallest*) net in the family!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: `ResNet8` architecture and shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output) shape: [1, 3]\n",
      "Global Avg Pooling 2D layer output(GlobalAveragePool2D) shape: [1, 128]\n",
      "ResidualBlock_3:\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_2) shape: [1, 8, 8, 128]\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_1) shape: [1, 8, 8, 128]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_3/skip_conv1x1) shape: [1, 8, 8, 128]-->\n",
      "ResidualBlock_2:\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_2) shape: [1, 16, 16, 64]\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_1) shape: [1, 16, 16, 64]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_2/skip_conv1x1) shape: [1, 16, 16, 64]-->\n",
      "ResidualBlock_1:\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_2) shape: [1, 32, 32, 32]\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_1) shape: [1, 32, 32, 32]\n",
      "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 32]\n"
     ]
    }
   ],
   "source": [
    "res8 = ResNet8(C=3, input_feats_shape=(32, 32, 3))\n",
    "res8.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell should print:\n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "Dense layer output(Output) shape: [1, 3]\n",
    "Global Avg Pooling 2D layer output(GlobalAvgPool2D) shape: [1, 128]\n",
    "ResidualBlock_3:\n",
    "\tConv2D layer output(ResidualBlock_3/main_3x3conv_2) shape: [1, 8, 8, 128]\n",
    "\tConv2D layer output(ResidualBlock_3/main_3x3conv_1) shape: [1, 8, 8, 128]\n",
    "\t-->Conv2D1x1 layer output(ResidualBlock_3/skip_conv1x1) shape: [1, 8, 8, 128]-->\n",
    "ResidualBlock_2:\n",
    "\tConv2D layer output(ResidualBlock_2/main_3x3conv_2) shape: [1, 16, 16, 64]\n",
    "\tConv2D layer output(ResidualBlock_2/main_3x3conv_1) shape: [1, 16, 16, 64]\n",
    "\t-->Conv2D1x1 layer output(ResidualBlock_2/skip_conv1x1) shape: [1, 16, 16, 64]-->\n",
    "ResidualBlock_1:\n",
    "\tConv2D layer output(ResidualBlock_1/main_3x3conv_2) shape: [1, 32, 32, 32]\n",
    "\tConv2D layer output(ResidualBlock_1/main_3x3conv_1) shape: [1, 32, 32, 32]\n",
    "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 32]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7b. CIFAR-10 overfit test\n",
    "\n",
    "In the cell below, import CIFAR-10 and reproduce our usual overfit protocol:\n",
    "1. Create a dev set from the 1st 500 training CIFAR-10 samples.\n",
    "2. Train your net on the dev set for `80` epochs (turn off early stopping for this test). *Do not use any regularization.* \n",
    "\n",
    "Your training loss should start out at ~2.3 after the first epoch and rapidly plummet to 0.01 or less by about 70 epochs.\n",
    "\n",
    "**Note:** If you coded `fit` to assume there will always be a validation set present, no problem, just plug in the dev set for both the train and val sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test, classnames = get_dataset('cifar10')\n",
    "x_dev = x_train[:500]\n",
    "y_dev = y_train[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output) shape: [1, 10]\n",
      "Global Avg Pooling 2D layer output(GlobalAveragePool2D) shape: [1, 128]\n",
      "ResidualBlock_3:\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_2) shape: [1, 8, 8, 128]\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_1) shape: [1, 8, 8, 128]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_3/skip_conv1x1) shape: [1, 8, 8, 128]-->\n",
      "ResidualBlock_2:\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_2) shape: [1, 16, 16, 64]\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_1) shape: [1, 16, 16, 64]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_2/skip_conv1x1) shape: [1, 16, 16, 64]-->\n",
      "ResidualBlock_1:\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_2) shape: [1, 32, 32, 32]\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_1) shape: [1, 32, 32, 32]\n",
      "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 32]\n",
      "Epoch 1: Training Loss = 2.5859, Validation Loss = 2.3268, Validation Accuracy = 0.1473\n",
      "Epoch 1/80 took 3.0821 seconds\n",
      "Epoch 2: Training Loss = 2.2501, Validation Loss = 2.1905, Validation Accuracy = 0.1920\n",
      "Epoch 2/80 took 0.2701 seconds\n",
      "Epoch 3: Training Loss = 2.1550, Validation Loss = 2.1454, Validation Accuracy = 0.2188\n",
      "Epoch 3/80 took 0.2455 seconds\n",
      "Epoch 4: Training Loss = 2.1165, Validation Loss = 2.0982, Validation Accuracy = 0.2054\n",
      "Epoch 4/80 took 0.2379 seconds\n",
      "Epoch 5: Training Loss = 2.0972, Validation Loss = 2.0727, Validation Accuracy = 0.2277\n",
      "Epoch 5/80 took 0.2582 seconds\n",
      "Epoch 6: Training Loss = 2.0260, Validation Loss = 2.0173, Validation Accuracy = 0.2433\n",
      "Epoch 6/80 took 0.2845 seconds\n",
      "Epoch 7: Training Loss = 2.0231, Validation Loss = 2.0277, Validation Accuracy = 0.2232\n",
      "Epoch 7/80 took 0.2790 seconds\n",
      "Epoch 8: Training Loss = 2.0136, Validation Loss = 1.9717, Validation Accuracy = 0.2879\n",
      "Epoch 8/80 took 0.2787 seconds\n",
      "Epoch 9: Training Loss = 1.9304, Validation Loss = 1.9460, Validation Accuracy = 0.2701\n",
      "Epoch 9/80 took 0.3026 seconds\n",
      "Epoch 10: Training Loss = 1.9226, Validation Loss = 1.8933, Validation Accuracy = 0.2634\n",
      "Epoch 10/80 took 0.2521 seconds\n",
      "Epoch 11: Training Loss = 1.8499, Validation Loss = 1.8713, Validation Accuracy = 0.2902\n",
      "Epoch 11/80 took 0.2814 seconds\n",
      "Epoch 12: Training Loss = 1.8931, Validation Loss = 1.8104, Validation Accuracy = 0.3661\n",
      "Epoch 12/80 took 0.2357 seconds\n",
      "Epoch 13: Training Loss = 1.8809, Validation Loss = 1.8137, Validation Accuracy = 0.3058\n",
      "Epoch 13/80 took 0.2329 seconds\n",
      "Epoch 14: Training Loss = 1.7811, Validation Loss = 1.7660, Validation Accuracy = 0.3192\n",
      "Epoch 14/80 took 0.2361 seconds\n",
      "Epoch 15: Training Loss = 1.7544, Validation Loss = 1.7034, Validation Accuracy = 0.3929\n",
      "Epoch 15/80 took 0.2313 seconds\n",
      "Epoch 16: Training Loss = 1.7158, Validation Loss = 1.7349, Validation Accuracy = 0.3393\n",
      "Epoch 16/80 took 0.2678 seconds\n",
      "Epoch 17: Training Loss = 1.6975, Validation Loss = 1.6578, Validation Accuracy = 0.3862\n",
      "Epoch 17/80 took 0.2379 seconds\n",
      "Epoch 18: Training Loss = 1.6018, Validation Loss = 1.6930, Validation Accuracy = 0.3906\n",
      "Epoch 18/80 took 0.2308 seconds\n",
      "Epoch 19: Training Loss = 1.5912, Validation Loss = 1.5940, Validation Accuracy = 0.4263\n",
      "Epoch 19/80 took 0.2306 seconds\n",
      "Epoch 20: Training Loss = 1.6294, Validation Loss = 1.6412, Validation Accuracy = 0.3906\n",
      "Epoch 20/80 took 0.2294 seconds\n",
      "Epoch 21: Training Loss = 1.5982, Validation Loss = 1.5063, Validation Accuracy = 0.4710\n",
      "Epoch 21/80 took 0.2292 seconds\n",
      "Epoch 22: Training Loss = 1.5428, Validation Loss = 1.5529, Validation Accuracy = 0.4263\n",
      "Epoch 22/80 took 0.2292 seconds\n",
      "Epoch 23: Training Loss = 1.5560, Validation Loss = 1.3952, Validation Accuracy = 0.5469\n",
      "Epoch 23/80 took 0.2299 seconds\n",
      "Epoch 24: Training Loss = 1.4302, Validation Loss = 1.4128, Validation Accuracy = 0.5067\n",
      "Epoch 24/80 took 0.2315 seconds\n",
      "Epoch 25: Training Loss = 1.4503, Validation Loss = 1.4207, Validation Accuracy = 0.4911\n",
      "Epoch 25/80 took 0.2279 seconds\n",
      "Epoch 26: Training Loss = 1.3065, Validation Loss = 1.3553, Validation Accuracy = 0.5134\n",
      "Epoch 26/80 took 0.2308 seconds\n",
      "Epoch 27: Training Loss = 1.2755, Validation Loss = 1.3333, Validation Accuracy = 0.5201\n",
      "Epoch 27/80 took 0.2283 seconds\n",
      "Epoch 28: Training Loss = 1.3468, Validation Loss = 1.2512, Validation Accuracy = 0.5536\n",
      "Epoch 28/80 took 0.2311 seconds\n",
      "Epoch 29: Training Loss = 1.1839, Validation Loss = 1.1689, Validation Accuracy = 0.6049\n",
      "Epoch 29/80 took 0.2300 seconds\n",
      "Epoch 30: Training Loss = 1.1582, Validation Loss = 1.1337, Validation Accuracy = 0.6138\n",
      "Epoch 30/80 took 0.2280 seconds\n",
      "Epoch 31: Training Loss = 1.1745, Validation Loss = 1.1020, Validation Accuracy = 0.6027\n",
      "Epoch 31/80 took 0.2294 seconds\n",
      "Epoch 32: Training Loss = 1.1734, Validation Loss = 1.1146, Validation Accuracy = 0.6049\n",
      "Epoch 32/80 took 0.2277 seconds\n",
      "Epoch 33: Training Loss = 1.1117, Validation Loss = 1.1082, Validation Accuracy = 0.6205\n",
      "Epoch 33/80 took 0.2995 seconds\n",
      "Epoch 34: Training Loss = 1.0662, Validation Loss = 1.0626, Validation Accuracy = 0.6138\n",
      "Epoch 34/80 took 0.2329 seconds\n",
      "Epoch 35: Training Loss = 0.9416, Validation Loss = 0.9449, Validation Accuracy = 0.7098\n",
      "Epoch 35/80 took 0.2283 seconds\n",
      "Epoch 36: Training Loss = 1.0371, Validation Loss = 1.1169, Validation Accuracy = 0.5781\n",
      "Epoch 36/80 took 0.2289 seconds\n",
      "Epoch 37: Training Loss = 1.0608, Validation Loss = 0.9726, Validation Accuracy = 0.6853\n",
      "Epoch 37/80 took 0.2297 seconds\n",
      "Epoch 38: Training Loss = 0.9574, Validation Loss = 0.9683, Validation Accuracy = 0.6540\n",
      "Epoch 38/80 took 0.2296 seconds\n",
      "Epoch 39: Training Loss = 0.9442, Validation Loss = 0.9268, Validation Accuracy = 0.6607\n",
      "Epoch 39/80 took 0.2295 seconds\n",
      "Epoch 40: Training Loss = 0.9074, Validation Loss = 0.8526, Validation Accuracy = 0.7210\n",
      "Epoch 40/80 took 0.2260 seconds\n",
      "Epoch 41: Training Loss = 0.8692, Validation Loss = 0.9706, Validation Accuracy = 0.6741\n",
      "Epoch 41/80 took 0.2309 seconds\n",
      "Epoch 42: Training Loss = 0.9556, Validation Loss = 0.8115, Validation Accuracy = 0.7321\n",
      "Epoch 42/80 took 0.2275 seconds\n",
      "Epoch 43: Training Loss = 0.7631, Validation Loss = 0.8452, Validation Accuracy = 0.6942\n",
      "Epoch 43/80 took 0.2252 seconds\n",
      "Epoch 44: Training Loss = 0.8013, Validation Loss = 0.7212, Validation Accuracy = 0.7790\n",
      "Epoch 44/80 took 0.2299 seconds\n",
      "Epoch 45: Training Loss = 0.6858, Validation Loss = 0.7032, Validation Accuracy = 0.7723\n",
      "Epoch 45/80 took 0.2301 seconds\n",
      "Epoch 46: Training Loss = 0.6362, Validation Loss = 0.6833, Validation Accuracy = 0.7790\n",
      "Epoch 46/80 took 0.2299 seconds\n",
      "Epoch 47: Training Loss = 0.6473, Validation Loss = 0.6779, Validation Accuracy = 0.7545\n",
      "Epoch 47/80 took 0.2297 seconds\n",
      "Epoch 48: Training Loss = 0.7099, Validation Loss = 0.7031, Validation Accuracy = 0.7478\n",
      "Epoch 48/80 took 0.2348 seconds\n",
      "Epoch 49: Training Loss = 0.7088, Validation Loss = 0.6422, Validation Accuracy = 0.7746\n",
      "Epoch 49/80 took 0.2303 seconds\n",
      "Epoch 50: Training Loss = 0.6179, Validation Loss = 0.5718, Validation Accuracy = 0.7991\n",
      "Epoch 50/80 took 0.2295 seconds\n",
      "Epoch 51: Training Loss = 0.6199, Validation Loss = 0.5467, Validation Accuracy = 0.8103\n",
      "Epoch 51/80 took 0.2313 seconds\n",
      "Epoch 52: Training Loss = 0.5262, Validation Loss = 0.5187, Validation Accuracy = 0.8348\n",
      "Epoch 52/80 took 0.2307 seconds\n",
      "Epoch 53: Training Loss = 0.5047, Validation Loss = 0.4546, Validation Accuracy = 0.8705\n",
      "Epoch 53/80 took 0.2288 seconds\n",
      "Epoch 54: Training Loss = 0.4507, Validation Loss = 0.4377, Validation Accuracy = 0.8862\n",
      "Epoch 54/80 took 0.2293 seconds\n",
      "Epoch 55: Training Loss = 0.4166, Validation Loss = 0.4436, Validation Accuracy = 0.8616\n",
      "Epoch 55/80 took 0.2305 seconds\n",
      "Epoch 56: Training Loss = 0.4445, Validation Loss = 0.3765, Validation Accuracy = 0.8862\n",
      "Epoch 56/80 took 0.2274 seconds\n",
      "Epoch 57: Training Loss = 0.3991, Validation Loss = 0.5360, Validation Accuracy = 0.8259\n",
      "Epoch 57/80 took 0.2306 seconds\n",
      "Epoch 58: Training Loss = 0.4683, Validation Loss = 0.3680, Validation Accuracy = 0.9040\n",
      "Epoch 58/80 took 0.2276 seconds\n",
      "Epoch 59: Training Loss = 0.3704, Validation Loss = 0.4071, Validation Accuracy = 0.8661\n",
      "Epoch 59/80 took 0.2288 seconds\n",
      "Epoch 60: Training Loss = 0.2765, Validation Loss = 0.2926, Validation Accuracy = 0.9263\n",
      "Epoch 60/80 took 0.2298 seconds\n",
      "Epoch 61: Training Loss = 0.2745, Validation Loss = 0.2673, Validation Accuracy = 0.9174\n",
      "Epoch 61/80 took 0.2308 seconds\n",
      "Epoch 62: Training Loss = 0.2309, Validation Loss = 0.3061, Validation Accuracy = 0.8906\n",
      "Epoch 62/80 took 0.2280 seconds\n",
      "Epoch 63: Training Loss = 0.3058, Validation Loss = 0.2644, Validation Accuracy = 0.9174\n",
      "Epoch 63/80 took 0.2308 seconds\n",
      "Epoch 64: Training Loss = 0.3288, Validation Loss = 0.2205, Validation Accuracy = 0.9554\n",
      "Epoch 64/80 took 0.2298 seconds\n",
      "Epoch 65: Training Loss = 0.3335, Validation Loss = 0.2838, Validation Accuracy = 0.9152\n",
      "Epoch 65/80 took 0.2298 seconds\n",
      "Epoch 66: Training Loss = 0.2790, Validation Loss = 0.2939, Validation Accuracy = 0.9152\n",
      "Epoch 66/80 took 0.2274 seconds\n",
      "Epoch 67: Training Loss = 0.3005, Validation Loss = 0.2413, Validation Accuracy = 0.9263\n",
      "Epoch 67/80 took 0.2303 seconds\n",
      "Epoch 68: Training Loss = 0.2354, Validation Loss = 0.1831, Validation Accuracy = 0.9688\n",
      "Epoch 68/80 took 0.2298 seconds\n",
      "Epoch 69: Training Loss = 0.1988, Validation Loss = 0.2098, Validation Accuracy = 0.9531\n",
      "Epoch 69/80 took 0.2271 seconds\n",
      "Epoch 70: Training Loss = 0.1985, Validation Loss = 0.2103, Validation Accuracy = 0.9420\n",
      "Epoch 70/80 took 0.2272 seconds\n",
      "Epoch 71: Training Loss = 0.2061, Validation Loss = 0.1666, Validation Accuracy = 0.9643\n",
      "Epoch 71/80 took 0.2296 seconds\n",
      "Epoch 72: Training Loss = 0.1611, Validation Loss = 0.1477, Validation Accuracy = 0.9688\n",
      "Epoch 72/80 took 0.2870 seconds\n",
      "Epoch 73: Training Loss = 0.1448, Validation Loss = 0.1072, Validation Accuracy = 0.9888\n",
      "Epoch 73/80 took 0.2288 seconds\n",
      "Epoch 74: Training Loss = 0.1081, Validation Loss = 0.1040, Validation Accuracy = 0.9888\n",
      "Epoch 74/80 took 0.2279 seconds\n",
      "Epoch 75: Training Loss = 0.0982, Validation Loss = 0.0800, Validation Accuracy = 0.9978\n",
      "Epoch 75/80 took 0.2316 seconds\n",
      "Epoch 76: Training Loss = 0.1067, Validation Loss = 0.0849, Validation Accuracy = 0.9844\n",
      "Epoch 76/80 took 0.2274 seconds\n",
      "Epoch 77: Training Loss = 0.0895, Validation Loss = 0.0859, Validation Accuracy = 0.9844\n",
      "Epoch 77/80 took 0.2299 seconds\n",
      "Epoch 78: Training Loss = 0.1067, Validation Loss = 0.0667, Validation Accuracy = 0.9911\n",
      "Epoch 78/80 took 0.2296 seconds\n",
      "Epoch 79: Training Loss = 0.0929, Validation Loss = 0.1446, Validation Accuracy = 0.9576\n",
      "Epoch 79/80 took 0.2617 seconds\n",
      "Epoch 80: Training Loss = 0.1132, Validation Loss = 0.0573, Validation Accuracy = 0.9955\n",
      "Epoch 80/80 took 0.2279 seconds\n",
      "Finished training after 80 epochs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2.585876,\n",
       "  2.250068,\n",
       "  2.154974,\n",
       "  2.1165404,\n",
       "  2.0972285,\n",
       "  2.0259666,\n",
       "  2.0230687,\n",
       "  2.0135818,\n",
       "  1.9304352,\n",
       "  1.9226068,\n",
       "  1.8499062,\n",
       "  1.893059,\n",
       "  1.8808895,\n",
       "  1.7810826,\n",
       "  1.7544332,\n",
       "  1.7158421,\n",
       "  1.6975046,\n",
       "  1.6018388,\n",
       "  1.5912101,\n",
       "  1.6294423,\n",
       "  1.5981907,\n",
       "  1.5428162,\n",
       "  1.5559764,\n",
       "  1.4302149,\n",
       "  1.4503202,\n",
       "  1.3064842,\n",
       "  1.2755228,\n",
       "  1.3468122,\n",
       "  1.1838591,\n",
       "  1.1581795,\n",
       "  1.1745156,\n",
       "  1.1733913,\n",
       "  1.1116767,\n",
       "  1.0661972,\n",
       "  0.94160336,\n",
       "  1.0370742,\n",
       "  1.0608397,\n",
       "  0.95743537,\n",
       "  0.9441985,\n",
       "  0.90743303,\n",
       "  0.86918575,\n",
       "  0.95563865,\n",
       "  0.76309776,\n",
       "  0.8012848,\n",
       "  0.68576235,\n",
       "  0.6362476,\n",
       "  0.647308,\n",
       "  0.70989585,\n",
       "  0.70884216,\n",
       "  0.6179085,\n",
       "  0.61989576,\n",
       "  0.52616465,\n",
       "  0.5047246,\n",
       "  0.45069832,\n",
       "  0.41657683,\n",
       "  0.44449043,\n",
       "  0.39906406,\n",
       "  0.4683032,\n",
       "  0.37041134,\n",
       "  0.2764516,\n",
       "  0.27448654,\n",
       "  0.23092845,\n",
       "  0.3058154,\n",
       "  0.32880962,\n",
       "  0.33348837,\n",
       "  0.2790051,\n",
       "  0.30054623,\n",
       "  0.23541424,\n",
       "  0.19884443,\n",
       "  0.19847618,\n",
       "  0.20611505,\n",
       "  0.16108611,\n",
       "  0.14479114,\n",
       "  0.10806472,\n",
       "  0.098150685,\n",
       "  0.10668438,\n",
       "  0.08950176,\n",
       "  0.10672492,\n",
       "  0.09286399,\n",
       "  0.11321913],\n",
       " [2.3267777,\n",
       "  2.1905475,\n",
       "  2.1454456,\n",
       "  2.0981596,\n",
       "  2.0726964,\n",
       "  2.0172987,\n",
       "  2.0276885,\n",
       "  1.9716597,\n",
       "  1.945976,\n",
       "  1.8933381,\n",
       "  1.8713444,\n",
       "  1.810375,\n",
       "  1.8137157,\n",
       "  1.7660389,\n",
       "  1.7034084,\n",
       "  1.7349101,\n",
       "  1.6577865,\n",
       "  1.693012,\n",
       "  1.5939821,\n",
       "  1.6411656,\n",
       "  1.506336,\n",
       "  1.5528618,\n",
       "  1.3952013,\n",
       "  1.4127861,\n",
       "  1.4206825,\n",
       "  1.3552649,\n",
       "  1.3332747,\n",
       "  1.2512437,\n",
       "  1.1688845,\n",
       "  1.1336501,\n",
       "  1.1019748,\n",
       "  1.1145948,\n",
       "  1.1081761,\n",
       "  1.0626068,\n",
       "  0.944868,\n",
       "  1.1169282,\n",
       "  0.97258055,\n",
       "  0.9682523,\n",
       "  0.9268369,\n",
       "  0.8526365,\n",
       "  0.97061867,\n",
       "  0.81147677,\n",
       "  0.8451725,\n",
       "  0.7212427,\n",
       "  0.70324624,\n",
       "  0.6833087,\n",
       "  0.67792636,\n",
       "  0.70314306,\n",
       "  0.6422439,\n",
       "  0.57179797,\n",
       "  0.5467035,\n",
       "  0.5186767,\n",
       "  0.45464736,\n",
       "  0.43774572,\n",
       "  0.44361144,\n",
       "  0.37645254,\n",
       "  0.5360279,\n",
       "  0.3679561,\n",
       "  0.4070708,\n",
       "  0.29262123,\n",
       "  0.2673066,\n",
       "  0.30611372,\n",
       "  0.2643883,\n",
       "  0.22047874,\n",
       "  0.28382108,\n",
       "  0.293919,\n",
       "  0.24132904,\n",
       "  0.18305798,\n",
       "  0.20981964,\n",
       "  0.21033981,\n",
       "  0.16657533,\n",
       "  0.1477318,\n",
       "  0.107202284,\n",
       "  0.10404839,\n",
       "  0.08003577,\n",
       "  0.084894955,\n",
       "  0.08594137,\n",
       "  0.0667035,\n",
       "  0.14457151,\n",
       "  0.05729897],\n",
       " [0.14732143,\n",
       "  0.19196428,\n",
       "  0.21875,\n",
       "  0.20535715,\n",
       "  0.22767857,\n",
       "  0.24330357,\n",
       "  0.22321428,\n",
       "  0.28794643,\n",
       "  0.2700893,\n",
       "  0.26339287,\n",
       "  0.29017857,\n",
       "  0.36607143,\n",
       "  0.30580357,\n",
       "  0.31919643,\n",
       "  0.39285713,\n",
       "  0.3392857,\n",
       "  0.3861607,\n",
       "  0.390625,\n",
       "  0.4263393,\n",
       "  0.390625,\n",
       "  0.47098213,\n",
       "  0.4263393,\n",
       "  0.546875,\n",
       "  0.5066964,\n",
       "  0.49107143,\n",
       "  0.51339287,\n",
       "  0.52008927,\n",
       "  0.5535714,\n",
       "  0.60491073,\n",
       "  0.61383927,\n",
       "  0.6026786,\n",
       "  0.60491073,\n",
       "  0.62053573,\n",
       "  0.61383927,\n",
       "  0.7098214,\n",
       "  0.578125,\n",
       "  0.68526787,\n",
       "  0.65401787,\n",
       "  0.66071427,\n",
       "  0.72098213,\n",
       "  0.67410713,\n",
       "  0.73214287,\n",
       "  0.6941964,\n",
       "  0.77901787,\n",
       "  0.7723214,\n",
       "  0.77901787,\n",
       "  0.75446427,\n",
       "  0.74776787,\n",
       "  0.7745536,\n",
       "  0.79910713,\n",
       "  0.81026787,\n",
       "  0.8348214,\n",
       "  0.87053573,\n",
       "  0.88616073,\n",
       "  0.86160713,\n",
       "  0.88616073,\n",
       "  0.82589287,\n",
       "  0.90401787,\n",
       "  0.8660714,\n",
       "  0.92633927,\n",
       "  0.91741073,\n",
       "  0.890625,\n",
       "  0.91741073,\n",
       "  0.95535713,\n",
       "  0.9151786,\n",
       "  0.9151786,\n",
       "  0.92633927,\n",
       "  0.96875,\n",
       "  0.953125,\n",
       "  0.94196427,\n",
       "  0.96428573,\n",
       "  0.96875,\n",
       "  0.98883927,\n",
       "  0.98883927,\n",
       "  0.99776787,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.9910714,\n",
       "  0.95758927,\n",
       "  0.99553573],\n",
       " 80)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model = ResNet8(10, (32,32,3), reg = 0)\n",
    "model.compile(optimizer='adamw')\n",
    "model.fit(x_dev, y_dev, x_dev, y_dev, max_epochs = 80, val_every = 1, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7c. Train ResNet-8 on CIFAR-10\n",
    "\n",
    "Repeat our usual training and evaluation protocol:\n",
    "1. Train ResNet-8 on CIFAR-10. Use regularization strength of `1.5`, a patience of `15`, learning rate patience of `4`, and keep the rest of the hyperparameters to their defaults.\n",
    "2. Print the test accuracy.\n",
    "\n",
    "If everything is working as expected, you should get a test accuracy in the 80s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output) shape: [1, 10]\n",
      "Global Avg Pooling 2D layer output(GlobalAveragePool2D) shape: [1, 128]\n",
      "ResidualBlock_3:\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_2) shape: [1, 8, 8, 128]\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_1) shape: [1, 8, 8, 128]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_3/skip_conv1x1) shape: [1, 8, 8, 128]-->\n",
      "ResidualBlock_2:\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_2) shape: [1, 16, 16, 64]\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_1) shape: [1, 16, 16, 64]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_2/skip_conv1x1) shape: [1, 16, 16, 64]-->\n",
      "ResidualBlock_1:\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_2) shape: [1, 32, 32, 32]\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_1) shape: [1, 32, 32, 32]\n",
      "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 32]\n",
      "Epoch 1: Training Loss = 1.7527, Validation Loss = 1.4970, Validation Accuracy = 0.4563\n",
      "Epoch 1/10000 took 22.3899 seconds\n",
      "Epoch 2: Training Loss = 1.4369, Validation Loss = 1.3524, Validation Accuracy = 0.4946\n",
      "Epoch 2/10000 took 31.8606 seconds\n",
      "Epoch 3: Training Loss = 1.3350, Validation Loss = 1.3130, Validation Accuracy = 0.5170\n",
      "Epoch 3/10000 took 30.2077 seconds\n",
      "Epoch 4: Training Loss = 1.2816, Validation Loss = 1.1996, Validation Accuracy = 0.5673\n",
      "Epoch 4/10000 took 30.8060 seconds\n",
      "Epoch 5: Training Loss = 1.2912, Validation Loss = 1.1966, Validation Accuracy = 0.5711\n",
      "Epoch 5/10000 took 29.9050 seconds\n",
      "Epoch 6: Training Loss = 1.2608, Validation Loss = 1.2081, Validation Accuracy = 0.5759\n",
      "Epoch 6/10000 took 29.9444 seconds\n",
      "Epoch 7: Training Loss = 1.2472, Validation Loss = 1.1467, Validation Accuracy = 0.6008\n",
      "Epoch 7/10000 took 23.1514 seconds\n",
      "Epoch 8: Training Loss = 1.2133, Validation Loss = 1.1526, Validation Accuracy = 0.5933\n",
      "Epoch 8/10000 took 16.6272 seconds\n",
      "Epoch 9: Training Loss = 1.2307, Validation Loss = 1.1846, Validation Accuracy = 0.5757\n",
      "Epoch 9/10000 took 17.2410 seconds\n",
      "Current lr= 0.001 Updated lr= 0.0005\n",
      "Epoch 10: Training Loss = 1.2201, Validation Loss = 1.2577, Validation Accuracy = 0.5537\n",
      "Epoch 10/10000 took 16.5450 seconds\n",
      "Epoch 11: Training Loss = 1.1509, Validation Loss = 1.1398, Validation Accuracy = 0.6000\n",
      "Epoch 11/10000 took 16.4394 seconds\n",
      "Epoch 12: Training Loss = 1.1418, Validation Loss = 1.1489, Validation Accuracy = 0.5986\n",
      "Epoch 12/10000 took 16.4465 seconds\n",
      "Epoch 13: Training Loss = 1.1407, Validation Loss = 1.1415, Validation Accuracy = 0.6012\n",
      "Epoch 13/10000 took 16.4802 seconds\n",
      "Epoch 14: Training Loss = 1.1391, Validation Loss = 1.2229, Validation Accuracy = 0.5789\n",
      "Epoch 14/10000 took 16.4450 seconds\n",
      "Epoch 15: Training Loss = 1.1587, Validation Loss = 1.1716, Validation Accuracy = 0.5755\n",
      "Epoch 15/10000 took 16.4823 seconds\n",
      "Current lr= 0.0005 Updated lr= 0.00025\n",
      "Epoch 16: Training Loss = 1.1458, Validation Loss = 1.1545, Validation Accuracy = 0.6024\n",
      "Epoch 16/10000 took 16.5061 seconds\n",
      "Epoch 17: Training Loss = 1.1065, Validation Loss = 1.1328, Validation Accuracy = 0.6006\n",
      "Epoch 17/10000 took 16.5194 seconds\n",
      "Epoch 18: Training Loss = 1.1049, Validation Loss = 1.0849, Validation Accuracy = 0.6210\n",
      "Epoch 18/10000 took 16.5224 seconds\n",
      "Epoch 19: Training Loss = 1.1115, Validation Loss = 1.0912, Validation Accuracy = 0.6192\n",
      "Epoch 19/10000 took 16.5551 seconds\n",
      "Epoch 20: Training Loss = 1.1126, Validation Loss = 1.1253, Validation Accuracy = 0.6042\n",
      "Epoch 20/10000 took 16.6567 seconds\n",
      "Current lr= 0.00025 Updated lr= 0.000125\n",
      "Epoch 21: Training Loss = 1.1087, Validation Loss = 1.1288, Validation Accuracy = 0.6012\n",
      "Epoch 21/10000 took 16.8442 seconds\n",
      "Epoch 22: Training Loss = 1.0831, Validation Loss = 1.0696, Validation Accuracy = 0.6254\n",
      "Epoch 22/10000 took 16.9605 seconds\n",
      "Epoch 23: Training Loss = 1.0901, Validation Loss = 1.0866, Validation Accuracy = 0.6238\n",
      "Epoch 23/10000 took 17.0260 seconds\n",
      "Epoch 24: Training Loss = 1.0799, Validation Loss = 1.0820, Validation Accuracy = 0.6198\n",
      "Epoch 24/10000 took 16.7512 seconds\n",
      "Epoch 25: Training Loss = 1.0774, Validation Loss = 1.0996, Validation Accuracy = 0.6102\n",
      "Epoch 25/10000 took 16.7980 seconds\n",
      "Epoch 26: Training Loss = 1.0770, Validation Loss = 1.0693, Validation Accuracy = 0.6288\n",
      "Epoch 26/10000 took 16.7815 seconds\n",
      "Epoch 27: Training Loss = 1.0791, Validation Loss = 1.0605, Validation Accuracy = 0.6292\n",
      "Epoch 27/10000 took 16.7908 seconds\n",
      "Epoch 28: Training Loss = 1.0784, Validation Loss = 1.0858, Validation Accuracy = 0.6202\n",
      "Epoch 28/10000 took 17.0102 seconds\n",
      "Epoch 29: Training Loss = 1.0942, Validation Loss = 1.0926, Validation Accuracy = 0.6148\n",
      "Epoch 29/10000 took 17.0165 seconds\n",
      "Epoch 30: Training Loss = 1.0728, Validation Loss = 1.0523, Validation Accuracy = 0.6338\n",
      "Epoch 30/10000 took 17.0244 seconds\n",
      "Epoch 31: Training Loss = 1.0796, Validation Loss = 1.0639, Validation Accuracy = 0.6316\n",
      "Epoch 31/10000 took 17.1803 seconds\n",
      "Epoch 32: Training Loss = 1.0837, Validation Loss = 1.0635, Validation Accuracy = 0.6272\n",
      "Epoch 32/10000 took 16.6872 seconds\n",
      "Current lr= 0.000125 Updated lr= 6.25e-05\n",
      "Epoch 33: Training Loss = 1.0931, Validation Loss = 1.0847, Validation Accuracy = 0.6234\n",
      "Epoch 33/10000 took 16.6794 seconds\n",
      "Epoch 34: Training Loss = 1.0704, Validation Loss = 1.0773, Validation Accuracy = 0.6256\n",
      "Epoch 34/10000 took 16.5903 seconds\n",
      "Epoch 35: Training Loss = 1.0690, Validation Loss = 1.0613, Validation Accuracy = 0.6312\n",
      "Epoch 35/10000 took 17.0925 seconds\n",
      "Epoch 36: Training Loss = 1.0699, Validation Loss = 1.0866, Validation Accuracy = 0.6172\n",
      "Epoch 36/10000 took 16.7672 seconds\n",
      "Epoch 37: Training Loss = 1.0688, Validation Loss = 1.0534, Validation Accuracy = 0.6372\n",
      "Epoch 37/10000 took 16.8445 seconds\n",
      "Epoch 38: Training Loss = 1.0669, Validation Loss = 1.0637, Validation Accuracy = 0.6276\n",
      "Epoch 38/10000 took 16.7436 seconds\n",
      "Epoch 39: Training Loss = 1.0683, Validation Loss = 1.0532, Validation Accuracy = 0.6380\n",
      "Epoch 39/10000 took 16.8224 seconds\n",
      "Epoch 40: Training Loss = 1.0638, Validation Loss = 1.0801, Validation Accuracy = 0.6186\n",
      "Epoch 40/10000 took 16.8297 seconds\n",
      "Epoch 41: Training Loss = 1.0693, Validation Loss = 1.0486, Validation Accuracy = 0.6400\n",
      "Epoch 41/10000 took 16.9581 seconds\n",
      "Epoch 42: Training Loss = 1.0679, Validation Loss = 1.0657, Validation Accuracy = 0.6260\n",
      "Epoch 42/10000 took 16.9260 seconds\n",
      "Epoch 43: Training Loss = 1.0644, Validation Loss = 1.0616, Validation Accuracy = 0.6292\n",
      "Epoch 43/10000 took 16.5621 seconds\n",
      "Current lr= 6.25e-05 Updated lr= 3.125e-05\n",
      "Epoch 44: Training Loss = 1.0718, Validation Loss = 1.0508, Validation Accuracy = 0.6360\n",
      "Epoch 44/10000 took 17.1587 seconds\n",
      "Epoch 45: Training Loss = 1.0461, Validation Loss = 1.0499, Validation Accuracy = 0.6364\n",
      "Epoch 45/10000 took 16.7278 seconds\n",
      "Epoch 46: Training Loss = 1.0529, Validation Loss = 1.0434, Validation Accuracy = 0.6362\n",
      "Epoch 46/10000 took 16.8392 seconds\n",
      "Epoch 47: Training Loss = 1.0587, Validation Loss = 1.0584, Validation Accuracy = 0.6308\n",
      "Epoch 47/10000 took 16.5093 seconds\n",
      "Epoch 48: Training Loss = 1.0596, Validation Loss = 1.0543, Validation Accuracy = 0.6312\n",
      "Epoch 48/10000 took 16.4791 seconds\n",
      "Current lr= 3.125e-05 Updated lr= 1.5625e-05\n",
      "Epoch 49: Training Loss = 1.0528, Validation Loss = 1.0470, Validation Accuracy = 0.6356\n",
      "Epoch 49/10000 took 16.5276 seconds\n",
      "Epoch 50: Training Loss = 1.0419, Validation Loss = 1.0352, Validation Accuracy = 0.6410\n",
      "Epoch 50/10000 took 16.5053 seconds\n",
      "Epoch 51: Training Loss = 1.0459, Validation Loss = 1.0338, Validation Accuracy = 0.6402\n",
      "Epoch 51/10000 took 16.5195 seconds\n",
      "Epoch 52: Training Loss = 1.0469, Validation Loss = 1.0427, Validation Accuracy = 0.6400\n",
      "Epoch 52/10000 took 17.3036 seconds\n",
      "Epoch 53: Training Loss = 1.0397, Validation Loss = 1.0333, Validation Accuracy = 0.6398\n",
      "Epoch 53/10000 took 16.5695 seconds\n",
      "Epoch 54: Training Loss = 1.0429, Validation Loss = 1.0389, Validation Accuracy = 0.6354\n",
      "Epoch 54/10000 took 16.5941 seconds\n",
      "Epoch 55: Training Loss = 1.0335, Validation Loss = 1.0509, Validation Accuracy = 0.6374\n",
      "Epoch 55/10000 took 16.5775 seconds\n",
      "Current lr= 1.5625e-05 Updated lr= 7.8125e-06\n",
      "Epoch 56: Training Loss = 1.0323, Validation Loss = 1.0341, Validation Accuracy = 0.6430\n",
      "Epoch 56/10000 took 16.8636 seconds\n",
      "Epoch 57: Training Loss = 1.0366, Validation Loss = 1.0322, Validation Accuracy = 0.6430\n",
      "Epoch 57/10000 took 17.2559 seconds\n",
      "Epoch 58: Training Loss = 1.0358, Validation Loss = 1.0319, Validation Accuracy = 0.6408\n",
      "Epoch 58/10000 took 17.0278 seconds\n",
      "Epoch 59: Training Loss = 1.0361, Validation Loss = 1.0306, Validation Accuracy = 0.6412\n",
      "Epoch 59/10000 took 16.7469 seconds\n",
      "Epoch 60: Training Loss = 1.0372, Validation Loss = 1.0322, Validation Accuracy = 0.6450\n",
      "Epoch 60/10000 took 16.7089 seconds\n",
      "Epoch 61: Training Loss = 1.0379, Validation Loss = 1.0325, Validation Accuracy = 0.6438\n",
      "Epoch 61/10000 took 16.5905 seconds\n",
      "Current lr= 7.8125e-06 Updated lr= 3.90625e-06\n",
      "Epoch 62: Training Loss = 1.0384, Validation Loss = 1.0355, Validation Accuracy = 0.6460\n",
      "Epoch 62/10000 took 16.6665 seconds\n",
      "Epoch 63: Training Loss = 1.0362, Validation Loss = 1.0317, Validation Accuracy = 0.6452\n",
      "Epoch 63/10000 took 16.7948 seconds\n",
      "Epoch 64: Training Loss = 1.0375, Validation Loss = 1.0284, Validation Accuracy = 0.6442\n",
      "Epoch 64/10000 took 16.6161 seconds\n",
      "Epoch 65: Training Loss = 1.0299, Validation Loss = 1.0294, Validation Accuracy = 0.6438\n",
      "Epoch 65/10000 took 16.7388 seconds\n",
      "Epoch 66: Training Loss = 1.0376, Validation Loss = 1.0266, Validation Accuracy = 0.6454\n",
      "Epoch 66/10000 took 16.6967 seconds\n",
      "Epoch 67: Training Loss = 1.0319, Validation Loss = 1.0283, Validation Accuracy = 0.6478\n",
      "Epoch 67/10000 took 17.0910 seconds\n",
      "Epoch 68: Training Loss = 1.0313, Validation Loss = 1.0282, Validation Accuracy = 0.6406\n",
      "Epoch 68/10000 took 19.2226 seconds\n",
      "Current lr= 3.90625e-06 Updated lr= 1.953125e-06\n",
      "Epoch 69: Training Loss = 1.0343, Validation Loss = 1.0282, Validation Accuracy = 0.6428\n",
      "Epoch 69/10000 took 17.6424 seconds\n",
      "Epoch 70: Training Loss = 1.0278, Validation Loss = 1.0279, Validation Accuracy = 0.6454\n",
      "Epoch 70/10000 took 16.9611 seconds\n",
      "Epoch 71: Training Loss = 1.0325, Validation Loss = 1.0270, Validation Accuracy = 0.6460\n",
      "Epoch 71/10000 took 16.7950 seconds\n",
      "Epoch 72: Training Loss = 1.0303, Validation Loss = 1.0286, Validation Accuracy = 0.6456\n",
      "Epoch 72/10000 took 17.1866 seconds\n",
      "Epoch 73: Training Loss = 1.0337, Validation Loss = 1.0277, Validation Accuracy = 0.6438\n",
      "Epoch 73/10000 took 16.6769 seconds\n",
      "Current lr= 1.953125e-06 Updated lr= 9.765625e-07\n",
      "Epoch 74: Training Loss = 1.0269, Validation Loss = 1.0272, Validation Accuracy = 0.6474\n",
      "Epoch 74/10000 took 16.7249 seconds\n",
      "Epoch 75: Training Loss = 1.0281, Validation Loss = 1.0266, Validation Accuracy = 0.6438\n",
      "Epoch 75/10000 took 16.7244 seconds\n",
      "Epoch 76: Training Loss = 1.0260, Validation Loss = 1.0276, Validation Accuracy = 0.6468\n",
      "Epoch 76/10000 took 16.7108 seconds\n",
      "Epoch 77: Training Loss = 1.0319, Validation Loss = 1.0265, Validation Accuracy = 0.6456\n",
      "Epoch 77/10000 took 16.7384 seconds\n",
      "Epoch 78: Training Loss = 1.0404, Validation Loss = 1.0276, Validation Accuracy = 0.6468\n",
      "Epoch 78/10000 took 16.6650 seconds\n",
      "Epoch 79: Training Loss = 1.0253, Validation Loss = 1.0269, Validation Accuracy = 0.6458\n",
      "Epoch 79/10000 took 16.9281 seconds\n",
      "Epoch 80: Training Loss = 1.0283, Validation Loss = 1.0263, Validation Accuracy = 0.6458\n",
      "Epoch 80/10000 took 17.2345 seconds\n",
      "Epoch 81: Training Loss = 1.0296, Validation Loss = 1.0259, Validation Accuracy = 0.6470\n",
      "Epoch 81/10000 took 16.9441 seconds\n",
      "Epoch 82: Training Loss = 1.0251, Validation Loss = 1.0265, Validation Accuracy = 0.6460\n",
      "Epoch 82/10000 took 16.6900 seconds\n",
      "Epoch 83: Training Loss = 1.0314, Validation Loss = 1.0270, Validation Accuracy = 0.6450\n",
      "Epoch 83/10000 took 16.7678 seconds\n",
      "Current lr= 9.765625e-07 Updated lr= 4.882813e-07\n",
      "Epoch 84: Training Loss = 1.0312, Validation Loss = 1.0264, Validation Accuracy = 0.6440\n",
      "Epoch 84/10000 took 17.3947 seconds\n",
      "Epoch 85: Training Loss = 1.0261, Validation Loss = 1.0271, Validation Accuracy = 0.6478\n",
      "Epoch 85/10000 took 16.6914 seconds\n",
      "Epoch 86: Training Loss = 1.0368, Validation Loss = 1.0267, Validation Accuracy = 0.6452\n",
      "Epoch 86/10000 took 16.7823 seconds\n",
      "Epoch 87: Training Loss = 1.0322, Validation Loss = 1.0269, Validation Accuracy = 0.6452\n",
      "Epoch 87/10000 took 16.7366 seconds\n",
      "Epoch 88: Training Loss = 1.0348, Validation Loss = 1.0255, Validation Accuracy = 0.6448\n",
      "Epoch 88/10000 took 16.8037 seconds\n",
      "Epoch 89: Training Loss = 1.0385, Validation Loss = 1.0262, Validation Accuracy = 0.6464\n",
      "Epoch 89/10000 took 16.7591 seconds\n",
      "Epoch 90: Training Loss = 1.0290, Validation Loss = 1.0267, Validation Accuracy = 0.6438\n",
      "Epoch 90/10000 took 16.7061 seconds\n",
      "Current lr= 4.882813e-07 Updated lr= 2.4414064e-07\n",
      "Epoch 91: Training Loss = 1.0362, Validation Loss = 1.0258, Validation Accuracy = 0.6462\n",
      "Epoch 91/10000 took 16.8693 seconds\n",
      "Epoch 92: Training Loss = 1.0196, Validation Loss = 1.0258, Validation Accuracy = 0.6462\n",
      "Epoch 92/10000 took 16.7599 seconds\n",
      "Epoch 93: Training Loss = 1.0288, Validation Loss = 1.0257, Validation Accuracy = 0.6454\n",
      "Epoch 93/10000 took 16.8077 seconds\n",
      "Epoch 94: Training Loss = 1.0316, Validation Loss = 1.0262, Validation Accuracy = 0.6474\n",
      "Epoch 94/10000 took 16.7530 seconds\n",
      "Epoch 95: Training Loss = 1.0316, Validation Loss = 1.0259, Validation Accuracy = 0.6446\n",
      "Epoch 95/10000 took 16.8182 seconds\n",
      "Epoch 96: Training Loss = 1.0285, Validation Loss = 1.0258, Validation Accuracy = 0.6472\n",
      "Epoch 96/10000 took 16.7036 seconds\n",
      "Epoch 97: Training Loss = 1.0243, Validation Loss = 1.0260, Validation Accuracy = 0.6470\n",
      "Epoch 97/10000 took 16.9235 seconds\n",
      "Epoch 98: Training Loss = 1.0348, Validation Loss = 1.0258, Validation Accuracy = 0.6446\n",
      "Epoch 98/10000 took 16.7145 seconds\n",
      "Epoch 99: Training Loss = 1.0296, Validation Loss = 1.0255, Validation Accuracy = 0.6450\n",
      "Epoch 99/10000 took 16.8972 seconds\n",
      "Epoch 100: Training Loss = 1.0312, Validation Loss = 1.0265, Validation Accuracy = 0.6470\n",
      "Epoch 100/10000 took 16.8410 seconds\n",
      "Epoch 101: Training Loss = 1.0321, Validation Loss = 1.0258, Validation Accuracy = 0.6464\n",
      "Epoch 101/10000 took 17.0539 seconds\n",
      "Epoch 102: Training Loss = 1.0285, Validation Loss = 1.0256, Validation Accuracy = 0.6462\n",
      "Early stopping triggered at epoch 102\n",
      "Finished training after 102 epochs!\n",
      "Test acc: 0.6291065812110901\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model = ResNet8(10, (32,32,3), reg = 1.5)\n",
    "model.compile(optimizer='adamw')\n",
    "model.fit(x_train, y_train, x_val, y_val, val_every = 1, verbose = True, patience=15, lr_patience=4)\n",
    "print(f\"Test acc: {model.evaluate(x_test, y_test)[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7d. Train ResNet-8 on CIFAR-100\n",
    "\n",
    "Repeat what you did with CIFAR-10, but this time with CIFAR-100.\n",
    "\n",
    "The test accuracy that you achieve should be better than chance, but should NOT be satisfying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7e. Questions\n",
    "\n",
    "**Question 3:** Compare your ResNet-8 with Inception Net with respect to CIFAR-10 test accuracy, runtime (per epoch), and the train/val loss progression throughout training. \n",
    "\n",
    "**Question 4:** How did ResNet-8 do on at CIFAR-100 test set classification compared to Inception Net?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 3:**\n",
    "\n",
    "**Answer 4:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: ResNet-18\n",
    "\n",
    "ResNet is an incredibly flexible/extensible neural network architecture. To get a better sense of this, let's build a deeper ResNet then train it on CIFAR-100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8a. Stacking multiple Residual Blocks together in sequence\n",
    "\n",
    "In ResNet-8, the spatial resolution/number of filters changed in every residual block. In deeper ResNets, this is not usually the case — there is a \"string\"/sequence of Residual Blocks with the SAME resolution and filter count stacked together after the change occurs.\n",
    "\n",
    "To streamline the process of stacking multiple Residual Blocks with the same hyperparameters together, write the `stack_residualblocks` function in `resnets.py`. This should save you lots of copy-pasting and/or typing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnets import stack_residualblocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: `stack_residualblocks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    test_stack = stack_residualblocks('TestStack', 4, i+1, prev_layer_or_block=None, first_block_stride=1)\n",
    "    print(f'There are {len(test_stack)} blocks in the residual stack. There should be {i+1}.')\n",
    "\n",
    "strides_in_stack = [block.strides for block in test_stack]\n",
    "print(f'The strides in each block are: {strides_in_stack}. They should be [1, 1, 1, 1]')\n",
    "\n",
    "test_stack = stack_residualblocks('TestStack', 4, 3, prev_layer_or_block=None, first_block_stride=2)\n",
    "strides_in_stack = [block.strides for block in test_stack]\n",
    "print(f'The strides in each block are: {strides_in_stack}. They should be [2, 1, 1, 1]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The blocks are:')\n",
    "for block in test_stack:\n",
    "    print(block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above should print:\n",
    "\n",
    "```\n",
    "The blocks are:\n",
    "TestStack/block_1:\n",
    "\tConv2D layer output(TestStack/block_1/main_3x3conv_2) shape: None\n",
    "\tConv2D layer output(TestStack/block_1/main_3x3conv_1) shape: None\n",
    "\t-->Conv2D1x1 layer output(TestStack/block_1/skip_conv1x1) shape: None-->\n",
    "TestStack/block_2:\n",
    "\tConv2D layer output(TestStack/block_2/main_3x3conv_2) shape: None\n",
    "\tConv2D layer output(TestStack/block_2/main_3x3conv_1) shape: None\n",
    "TestStack/block_3:\n",
    "\tConv2D layer output(TestStack/block_3/main_3x3conv_2) shape: None\n",
    "\tConv2D layer output(TestStack/block_3/main_3x3conv_1) shape: None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8b. Build ResNet-18\n",
    "\n",
    "Implement the `ResNet18` class in `resnets.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnets import ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: `ResNet18`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res18 = ResNet18(C=4, input_feats_shape=(32, 32, 3))\n",
    "res18.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell should print:\n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "Dense layer output(Output) shape: [1, 4]\n",
    "Global Avg Pooling 2D layer output(GlobalAvgPool2D) shape: [1, 512]\n",
    "stack4/block_2:\n",
    "\tConv2D layer output(stack4/block_2/main_3x3conv_2) shape: [1, 4, 4, 512]\n",
    "\tConv2D layer output(stack4/block_2/main_3x3conv_1) shape: [1, 4, 4, 512]\n",
    "stack4/block_1:\n",
    "\tConv2D layer output(stack4/block_1/main_3x3conv_2) shape: [1, 4, 4, 512]\n",
    "\tConv2D layer output(stack4/block_1/main_3x3conv_1) shape: [1, 4, 4, 512]\n",
    "\t-->Conv2D1x1 layer output(stack4/block_1/skip_conv1x1) shape: [1, 4, 4, 512]-->\n",
    "stack3/block_2:\n",
    "\tConv2D layer output(stack3/block_2/main_3x3conv_2) shape: [1, 8, 8, 256]\n",
    "\tConv2D layer output(stack3/block_2/main_3x3conv_1) shape: [1, 8, 8, 256]\n",
    "stack3/block_1:\n",
    "\tConv2D layer output(stack3/block_1/main_3x3conv_2) shape: [1, 8, 8, 256]\n",
    "\tConv2D layer output(stack3/block_1/main_3x3conv_1) shape: [1, 8, 8, 256]\n",
    "\t-->Conv2D1x1 layer output(stack3/block_1/skip_conv1x1) shape: [1, 8, 8, 256]-->\n",
    "stack2/block_2:\n",
    "\tConv2D layer output(stack2/block_2/main_3x3conv_2) shape: [1, 16, 16, 128]\n",
    "\tConv2D layer output(stack2/block_2/main_3x3conv_1) shape: [1, 16, 16, 128]\n",
    "stack2/block_1:\n",
    "\tConv2D layer output(stack2/block_1/main_3x3conv_2) shape: [1, 16, 16, 128]\n",
    "\tConv2D layer output(stack2/block_1/main_3x3conv_1) shape: [1, 16, 16, 128]\n",
    "\t-->Conv2D1x1 layer output(stack2/block_1/skip_conv1x1) shape: [1, 16, 16, 128]-->\n",
    "stack1/block_2:\n",
    "\tConv2D layer output(stack1/block_2/main_3x3conv_2) shape: [1, 32, 32, 64]\n",
    "\tConv2D layer output(stack1/block_2/main_3x3conv_1) shape: [1, 32, 32, 64]\n",
    "stack1/block_1:\n",
    "\tConv2D layer output(stack1/block_1/main_3x3conv_2) shape: [1, 32, 32, 64]\n",
    "\tConv2D layer output(stack1/block_1/main_3x3conv_1) shape: [1, 32, 32, 64]\n",
    "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 64]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8c. Overfit ResNet-18 on CIFAR-100 dev set\n",
    "\n",
    "Perform the usual overfitting protocol to test out your ResNet-18. However, this time use the 1st 500 samples of CIFAR-100 rather than CIFAR-10 to conduct the test.\n",
    "\n",
    "In the cell below, import CIFAR-100 and reproduce our usual overfit protocol:\n",
    "1. Create a dev set from the 1st 500 training CIFAR-100 samples.\n",
    "2. Train your net on the dev set for `80` epochs (turn off early stopping for this test). *Do not use any regularization.* \n",
    "\n",
    "Your training loss should start out at ~4.7 after the first epoch and rapidly plummet to 0.01 or less after about 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8d. Train ResNet-18 on CIFAR-100\n",
    "\n",
    "In the cell below, train your ResNet-18 on CIFAR-100. Print out the test set after training concludes.\n",
    "\n",
    "Use regularization strength of `1.5`, a patience of `15`, learning rate patience of `4`, and keep the rest of the hyperparameters to their defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8e. Visualize the predictions made by ResNet-18 on the CIFAR-100 test set.\n",
    "\n",
    "In the cell below, use your trained ResNet-18 to get the predicted classes of thr 1st 225 test set images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to create a 15x15 grid of CIFAR-100 images with the true and predicted classes in the title. The predicted classes are color-coded  blue if they are correct, red if they are incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_,_, x100_test_vis, y100_test_vis, classnames = get_dataset('cifar100', standardize_ds=False)\n",
    "\n",
    "panel_sz = 4\n",
    "grid = 15\n",
    "fig, axes, = plt.subplots(nrows=grid, ncols=grid, figsize=(grid*panel_sz, grid*panel_sz))\n",
    "\n",
    "for r in range(grid):\n",
    "    for c in range(grid):\n",
    "        ind = grid*r + c\n",
    "        axes[r,c].imshow(x100_test_vis[ind])\n",
    "        axes[r,c].set_xticks([])\n",
    "        axes[r,c].set_yticks([])\n",
    "        title = f'{classnames[y100_test[ind]]}\\nPredicted: '\n",
    "        title += f'{classnames[y_pred[ind]]}'\n",
    "\n",
    "        color = 'blue'\n",
    "        if y100_test[ind] != y_pred[ind]:\n",
    "            color = 'red'\n",
    "\n",
    "        axes[r,c].set_title(title, color=color)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8f. Questions\n",
    "\n",
    "**Question 5:** Take a look at the above montage. Does the mistakes made by ResNet-18 seem reasonable? Provide some specific examples to support your conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 5:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "### General guidelines\n",
    "\n",
    "1. Never integrate extensions into your base project so that they change the expected behavior of core functions. If your extension changes the core design/behavior, no problem, duplicate your working base project and add features from there.\n",
    "2. Check the rubric to keep in mind how extensions on this project will be graded.\n",
    "3. While I may consult your code and \"written log\" of what you did, **I am grading your extensions based on what you present in your 3-5 min video.**\n",
    "3. I suggest documenting your explorations in a \"log\" or \"lab notebook\" style (i.e. documenting your thought/progression/discovery/learning process). I'm not grading your writing, so you can keep it succinct. **Whatever is most useful to you to remember what you did.** \n",
    "4. I suggest taking a hypothesis driven approach. For example \"I was curious about X so I explored Y. I found Z, which was not what I expected because..., so then tried A...\"\n",
    "5. Make plots to help showcase your results.\n",
    "6. **More is not necessarily better.** Generally, a small number of \"in-depth\" extensions count for more than many \"shallow\" extensions.\n",
    "\n",
    "### AI guidelines\n",
    "\n",
    "You may use AI in mostly any capacity for extensions. However, keep in mind:\n",
    "1. There is no need to use AI at all!\n",
    "2. You are welcome to use AI as a tool (e.g. automate something that is tedious, help you get unstuck, etc.). However, you should be coding, you should be thinking, you should be writing, you should be creating. If you are spending most (or even close to most) of your time typing into a chatbot and copy-pasting, you have probably gone too far with AI use.\n",
    "3. I don't find large volumes of AI generated code/text/plots to be particularly impressive and you risk losing my interest while grading. Remember: I'm grading your extensions based on your video presentation. **More is not necessarily better.**\n",
    "\n",
    "### Video guidelines\n",
    "\n",
    "1. Please try to keep your video to 5 minutes (*I have other projects to grade!*). If you turn in a longer video, I make no promise that I will watch more than 5 minutes.\n",
    "2. Your screen should be shared as you show me what you did. A live video of your face should also appear somewhere on the screen (e.g. picture-in-picture overlay / split screen).\n",
    "3. Your partner should join you for the video and take turns talking, but, if necessary, it is fine to have one team member present during the record the video.\n",
    "4. Do not simply read text from your notebook, do not read from a prepared script. I am not grading how polished your video presentation is (see extension grading criteria on rubric). \n",
    "5. I am looking for original and creative explorations sparked by your curiosity/interest/passion in a topic. This should be apparent in your video.\n",
    "6. Be natural,, don't feel the need to impress me with fancy language. If it is helpful, imagine that we are talking one-on-one about your extension. Tell me what you did :)\n",
    "\n",
    "### Extension ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. ResNet-34\n",
    "\n",
    "Create and train the well-known network of the ResNet family called ResNet-34. Here is a suggested network configuration to experiment with:\n",
    "\n",
    "```\n",
    "block_units = [64, 128, 256, 512]\n",
    "num_blocks = [3, 4, 6, 3]\n",
    "first_block_strides = [1, 2, 2, 2]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. ResNet-50\n",
    "\n",
    "Create and train the well-known network of the ResNet family called ResNet-50. Given its depth, it uses a \"Bottleneck block\" rather than a normal Residual Block, but the overall structure is very similar. Here is a suggested network configuration to experiment with:\n",
    "\n",
    "```\n",
    "block_units = [64, 128, 256, 512]\n",
    "num_blocks = [3, 4, 6, 3]\n",
    "first_block_strides = [1, 2, 2, 2]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. VGG networks on CIFAR-100\n",
    "\n",
    "How does one or more of your VGG networks do at classifying images in CIFAR-100?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Other ResNets on CIFAR-10\n",
    "\n",
    "How do the other ResNets do at classifying images in CIFAR-10?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Multi-network comparison\n",
    "\n",
    "Compare the accuracy, efficiency, etc of any number of networks from the VGG, Inception Net, and ResNet families."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Add support for saving/loading network weights\n",
    "\n",
    "A key limitation of your current deep learning library is that parameters that capture the learning in networks are completely reset/lost/wiped out when the notebook kernel is terminated. Add (and test!) support for saving network parameters to disk after (or periodically during) training. Add (and test!) support for loading network parameters back into the network from disk before training. \n",
    "\n",
    "Be careful to include the moving mean and standard deviation parameters in batch normalization layers otherwise the whole net will not work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Other image datasets\n",
    "\n",
    "Apply any of the three deep network families to another dataset of your choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Hyperparameter tuning\n",
    "\n",
    "Try and find hyperparameters that allow Inception Net and the ResNets to achieve better accuracy on CIFAR-10 and/or CIFAR-100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Build other Inception Nets\n",
    "\n",
    "We only built a single network, but just like VGG and ResNet, you can modify the network depth while following the computational motifs of the Inception Net architecture. Design and experiment with your own Inception Net!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Analyze errors made by one or more of the nets\n",
    "\n",
    "Make a confusion matrix for CIFAR-10 or CIFAR-100 (*a challenge to make it useful!*).\n",
    "\n",
    "Visualize the predictions made by Inception Net and/or a VGG net, perhaps similar what was done with the ResNet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs444",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
