{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a82d7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Trey Tuscai and Gordon Doore\n",
    "\n",
    "Spring 2025\n",
    "\n",
    "CS 444: Deep Learning\n",
    "\n",
    "Project 2: Branch Neural Networks\n",
    "\n",
    "#### Week 2: Residual networks\n",
    "\n",
    "The focus this week is on the ResNet architecture. You will build several neural networks in the ResNet family and and train them on CIFAR-10 and CIFAR-100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6381ec",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 16:58:57.263229: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-06 16:59:04.345661: I tensorflow/core/platform/cpu_feature_guard.cc:211] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=7)\n",
    "\n",
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051dd9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 6: The Residual Block\n",
    "\n",
    "This task focuses on implementing and testing the **Residual Block** in preparation of creating the first ResNet (**ResNet-8**). \n",
    "\n",
    "Much like how Inception Blocks represent the building blocks of Inception Net, stacks of Residual Blocks represent the basis of ResNet. Residual Blocks possess a simpler structure than Inception Blocks â€” they only contain two parallel branches with fewer layers. Here is a refresher on the structure of the branches:\n",
    "\n",
    "**Main branch:** sequence of two 2D convolutional layers.\n",
    "\n",
    "**Residual branch:** the input signal to the Residual Block passes through \"as-is\", without modification (usually).\n",
    "\n",
    "Like Inception Block, the output of both branches comes together at the end of the block. However, the branch outputs are SUMMED together rather than being concatenated.\n",
    "\n",
    "\n",
    "This is the story for most Residual Blocks, however, like most CNNs:\n",
    "1. the spatial resolution of the activations occasionally decreases\n",
    "2. the number of conv filters/neurons increases\n",
    "\n",
    "as we go deeper in a ResNet. Both of these factors tend to change *at the same time* in a small number of Residual Blocks located at various depths of the ResNet. Put another way, the spatial resolution and number of filters tends to remain constant across most successive Residual Blocks and they only changes in a few blocks throughout the net.\n",
    "1. The decrease in spatial resolution is implemented in these small number of Residual Blocks with a convolutional stride > 1.\n",
    "2. A 1x1 convolutional layer is needed as the \"special sauce\" along the residual branch to make the shapes of signals in both branches match (*otherwise they could not be summed!*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa14e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 6a. Implement and test the Residual Block\n",
    "\n",
    "The class is in `residual_block.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f6a6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from residual_block import ResidualBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b08c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `ResidualBlock` Stride 1 (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "205dc6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 17:00:12.147111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20601 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 17:00:17.751333: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 90400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestResidualBlock_S1:\n",
      "\tConv2D layer output(TestResidualBlock_S1/main_3x3conv_2) shape: [1, 4, 4, 7]\n",
      "\tConv2D layer output(TestResidualBlock_S1/main_3x3conv_1) shape: [1, 4, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "# Testing architecture and shapes\n",
    "# Stride 1\n",
    "tf.random.set_seed(0)\n",
    "res1 = ResidualBlock('TestResidualBlock_S1', 7, prev_layer_or_block=None, strides=1)\n",
    "res1(tf.ones([1, 4, 4, 7]))\n",
    "print(res1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f614",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The above cell should print:\n",
    "\n",
    "```\n",
    "TestResidualBlock_S1:\n",
    "\tConv2D layer output(TestResidualBlock_S1/main_3x3conv_2) shape: [1, 4, 4, 7]\n",
    "\tConv2D layer output(TestResidualBlock_S1/main_3x3conv_1) shape: [1, 4, 4, 7]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83efe8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the netAct output from the block is (2, 4, 4, 7) and should be (2, 4, 4, 7)\n",
      "The first few activations are:\n",
      "[[0.        0.5208229 0.1888617 0.       ]\n",
      " [0.        0.7621396 0.1734906 0.8486798]\n",
      " [0.        0.6156112 0.4272216 0.       ]\n",
      " [0.5561852 0.4888234 1.0138503 0.5533389]]\n",
      "and should be:\n",
      "[[0.        0.520823  0.1888617 0.       ]\n",
      " [0.        0.7621396 0.1734907 0.8486798]\n",
      " [0.        0.6156113 0.4272216 0.       ]\n",
      " [0.5561852 0.4888234 1.0138503 0.5533389]]\n"
     ]
    }
   ],
   "source": [
    "# Test activations\n",
    "tf.random.set_seed(0)\n",
    "net_acts1 = res1(tf.random.uniform([2, 4, 4, 7]))\n",
    "print(f'The shape of the netAct output from the block is {net_acts1.shape} and should be (2, 4, 4, 7)')\n",
    "print(f'The first few activations are:\\n{net_acts1[0,:,:, 0]}')\n",
    "print('and should be:')\n",
    "print('''[[0.        0.520823  0.1888617 0.       ]\n",
    " [0.        0.7621396 0.1734907 0.8486798]\n",
    " [0.        0.6156113 0.4272216 0.       ]\n",
    " [0.5561852 0.4888234 1.0138503 0.5533389]]''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eec95",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `ResidualBlock` Stride 2 (2/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a2d3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestResidualBlock_S2:\n",
      "\tConv2D layer output(TestResidualBlock_S2/main_3x3conv_2) shape: [1, 3, 3, 5]\n",
      "\tConv2D layer output(TestResidualBlock_S2/main_3x3conv_1) shape: [1, 3, 3, 5]\n",
      "\t-->Conv2D1x1 layer output(TestResidualBlock_S2/skip_conv1x1) shape: [1, 3, 3, 5]-->\n"
     ]
    }
   ],
   "source": [
    "# Testing architecture and shapes\n",
    "# Stride 2\n",
    "tf.random.set_seed(0)\n",
    "res2 = ResidualBlock('TestResidualBlock_S2', 5, prev_layer_or_block=None, strides=2)\n",
    "res2(tf.ones([1, 6, 6, 5]))\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05382",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The above cell should print:\n",
    "\n",
    "```\n",
    "TestResidualBlock_S2:\n",
    "\tConv2D layer output(TestResidualBlock_S2/main_3x3conv_2) shape: [1, 3, 3, 5]\n",
    "\tConv2D layer output(TestResidualBlock_S2/main_3x3conv_1) shape: [1, 3, 3, 5]\n",
    "\t-->Conv2D1x1 layer output(TestResidualBlock_S2/skip_conv1x1) shape: [1, 3, 3, 5]-->\n",
    "```\n",
    "\n",
    "*The layer with the --> is the residual branch.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "038d46",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the netAct output from the block is (3, 3, 3, 5) and should be (3, 3, 3, 5)\n",
      "The first few activations are:\n",
      "[[[0.2404822 0.        0.        0.2851935 0.       ]\n",
      "  [0.        0.        0.        0.1339087 0.6898913]\n",
      "  [0.        0.        0.        0.4596352 0.2781556]]\n",
      "\n",
      " [[0.        0.        0.        0.6591434 1.3703969]\n",
      "  [0.2665228 0.        0.        0.9614864 0.       ]\n",
      "  [0.        0.        0.        0.3844326 0.7111532]]\n",
      "\n",
      " [[0.0933783 0.        0.        0.1378801 0.3006182]\n",
      "  [0.1873689 0.        0.        0.4464225 1.106713 ]\n",
      "  [0.        0.        0.        0.7910072 0.345379 ]]]\n",
      "and should be:\n",
      "[[[0.2404823 0.        0.        0.2851936 0.       ]\n",
      "  [0.        0.        0.        0.1339086 0.6898913]\n",
      "  [0.        0.        0.        0.4596353 0.2781557]]\n",
      "\n",
      " [[0.        0.        0.        0.6591434 1.3703969]\n",
      "  [0.2665227 0.        0.        0.9614864 0.       ]\n",
      "  [0.        0.        0.        0.3844326 0.7111533]]\n",
      "\n",
      " [[0.0933782 0.        0.        0.1378801 0.3006183]\n",
      "  [0.1873689 0.        0.        0.4464224 1.1067129]\n",
      "  [0.        0.        0.        0.7910071 0.345379 ]]]\n"
     ]
    }
   ],
   "source": [
    "# Test activations\n",
    "tf.random.set_seed(0)\n",
    "net_acts2 = res2(tf.random.uniform([3, 6, 6, 5]))\n",
    "print(f'The shape of the netAct output from the block is {net_acts2.shape} and should be (3, 3, 3, 5)')\n",
    "print(f'The first few activations are:\\n{net_acts2[0,:,:, :]}')\n",
    "print('and should be:')\n",
    "print('''[[[0.2404823 0.        0.        0.2851936 0.       ]\n",
    "  [0.        0.        0.        0.1339086 0.6898913]\n",
    "  [0.        0.        0.        0.4596353 0.2781557]]\n",
    "\n",
    " [[0.        0.        0.        0.6591434 1.3703969]\n",
    "  [0.2665227 0.        0.        0.9614864 0.       ]\n",
    "  [0.        0.        0.        0.3844326 0.7111533]]\n",
    "\n",
    " [[0.0933782 0.        0.        0.1378801 0.3006183]\n",
    "  [0.1873689 0.        0.        0.4464224 1.1067129]\n",
    "  [0.        0.        0.        0.7910071 0.345379 ]]]''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f31db",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 7: ResNet-8\n",
    "\n",
    "Assemble the Residual Blocks and several other layers to build ResNet-8:\n",
    "\n",
    "Conv2D â†’ ResidualBlock â†’ ResidualBlock â†’ ResidualBlock â†’ GlobalAveragePooling2D â†’ Dense\n",
    "\n",
    "After an overfit test to help check whether the network is working, you will train the network on both CIFAR-10 and CIFAR-100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a891b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from resnets import ResNet8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba72f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 7a. Build ResNet-8\n",
    "\n",
    "Implement the following classes in `resnets.py`:\n",
    "1. `ResNet`: Parent class of all specific ResNets (e.g. ResNet-8, ResNet-18, etc.). Having this class helps reduce code size/duplication because the forward pass thru all ResNets is exactly the same!\n",
    "2. `ResNet8`: Assemble the first (*and smallest*) net in the family!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985ce5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `ResNet8` architecture and shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6b7bb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output) shape: [1, 3]\n",
      "Global Avg Pooling 2D layer output(GlobalAveragePool2D) shape: [1, 128]\n",
      "ResidualBlock_3:\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_2) shape: [1, 8, 8, 128]\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_1) shape: [1, 8, 8, 128]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_3/skip_conv1x1) shape: [1, 8, 8, 128]-->\n",
      "ResidualBlock_2:\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_2) shape: [1, 16, 16, 64]\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_1) shape: [1, 16, 16, 64]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_2/skip_conv1x1) shape: [1, 16, 16, 64]-->\n",
      "ResidualBlock_1:\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_2) shape: [1, 32, 32, 32]\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_1) shape: [1, 32, 32, 32]\n",
      "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 32]\n"
     ]
    }
   ],
   "source": [
    "res8 = ResNet8(C=3, input_feats_shape=(32, 32, 3))\n",
    "res8.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc65d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The above cell should print:\n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "Dense layer output(Output) shape: [1, 3]\n",
    "Global Avg Pooling 2D layer output(GlobalAvgPool2D) shape: [1, 128]\n",
    "ResidualBlock_3:\n",
    "\tConv2D layer output(ResidualBlock_3/main_3x3conv_2) shape: [1, 8, 8, 128]\n",
    "\tConv2D layer output(ResidualBlock_3/main_3x3conv_1) shape: [1, 8, 8, 128]\n",
    "\t-->Conv2D1x1 layer output(ResidualBlock_3/skip_conv1x1) shape: [1, 8, 8, 128]-->\n",
    "ResidualBlock_2:\n",
    "\tConv2D layer output(ResidualBlock_2/main_3x3conv_2) shape: [1, 16, 16, 64]\n",
    "\tConv2D layer output(ResidualBlock_2/main_3x3conv_1) shape: [1, 16, 16, 64]\n",
    "\t-->Conv2D1x1 layer output(ResidualBlock_2/skip_conv1x1) shape: [1, 16, 16, 64]-->\n",
    "ResidualBlock_1:\n",
    "\tConv2D layer output(ResidualBlock_1/main_3x3conv_2) shape: [1, 32, 32, 32]\n",
    "\tConv2D layer output(ResidualBlock_1/main_3x3conv_1) shape: [1, 32, 32, 32]\n",
    "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 32]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49772",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 7b. CIFAR-10 overfit test\n",
    "\n",
    "In the cell below, import CIFAR-10 and reproduce our usual overfit protocol:\n",
    "1. Create a dev set from the 1st 500 training CIFAR-10 samples.\n",
    "2. Train your net on the dev set for `80` epochs (turn off early stopping for this test). *Do not use any regularization.* \n",
    "\n",
    "Your training loss should start out at ~2.3 after the first epoch and rapidly plummet to 0.01 or less by about 70 epochs.\n",
    "\n",
    "**Note:** If you coded `fit` to assume there will always be a validation set present, no problem, just plug in the dev set for both the train and val sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7e0bc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datasets import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cd4e2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test, classnames = get_dataset('cifar10')\n",
    "x_dev = x_train[:500]\n",
    "y_dev = y_train[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9e98",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output) shape: [1, 10]\n",
      "Global Avg Pooling 2D layer output(GlobalAveragePool2D) shape: [1, 128]\n",
      "ResidualBlock_3:\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_2) shape: [1, 8, 8, 128]\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_1) shape: [1, 8, 8, 128]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_3/skip_conv1x1) shape: [1, 8, 8, 128]-->\n",
      "ResidualBlock_2:\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_2) shape: [1, 16, 16, 64]\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_1) shape: [1, 16, 16, 64]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_2/skip_conv1x1) shape: [1, 16, 16, 64]-->\n",
      "ResidualBlock_1:\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_2) shape: [1, 32, 32, 32]\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_1) shape: [1, 32, 32, 32]\n",
      "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743958870.215802     584 service.cc:145] XLA service 0x799e0e54e640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743958870.215851     584 service.cc:153]   StreamExecutor device (0): NVIDIA L4, Compute Capability 8.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 17:01:10.628313: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743958871.801254     584 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss = 2.5854, Validation Loss = 2.3263, Validation Accuracy = 0.1473\n",
      "Epoch 1/80 took 13.3567 seconds\n",
      "Epoch 2: Training Loss = 2.2497, Validation Loss = 2.1903, Validation Accuracy = 0.1920\n",
      "Epoch 2/80 took 0.1009 seconds\n",
      "Epoch 3: Training Loss = 2.1547, Validation Loss = 2.1454, Validation Accuracy = 0.2188\n",
      "Epoch 3/80 took 0.0528 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Training Loss = 2.1165, Validation Loss = 2.0979, Validation Accuracy = 0.2031\n",
      "Epoch 4/80 took 0.0546 seconds\n",
      "Epoch 5: Training Loss = 2.0975, Validation Loss = 2.0723, Validation Accuracy = 0.2299\n",
      "Epoch 5/80 took 0.0524 seconds\n",
      "Epoch 6: Training Loss = 2.0260, Validation Loss = 2.0176, Validation Accuracy = 0.2388\n",
      "Epoch 6/80 took 0.0517 seconds\n",
      "Epoch 7: Training Loss = 2.0233, Validation Loss = 2.0264, Validation Accuracy = 0.2277\n",
      "Epoch 7/80 took 0.0515 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Training Loss = 2.0125, Validation Loss = 1.9709, Validation Accuracy = 0.2946\n",
      "Epoch 8/80 took 0.0540 seconds\n",
      "Epoch 9: Training Loss = 1.9300, Validation Loss = 1.9440, Validation Accuracy = 0.2701\n",
      "Epoch 9/80 took 0.0575 seconds\n",
      "Epoch 10: Training Loss = 1.9202, Validation Loss = 1.8925, Validation Accuracy = 0.2701\n",
      "Epoch 10/80 took 0.0519 seconds\n",
      "Epoch 11: Training Loss = 1.8509, Validation Loss = 1.8679, Validation Accuracy = 0.2946\n",
      "Epoch 11/80 took 0.0522 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Training Loss = 1.8899, Validation Loss = 1.8093, Validation Accuracy = 0.3661\n",
      "Epoch 12/80 took 0.0550 seconds\n",
      "Epoch 13: Training Loss = 1.8793, Validation Loss = 1.8117, Validation Accuracy = 0.3013\n",
      "Epoch 13/80 took 0.0515 seconds\n",
      "Epoch 14: Training Loss = 1.7787, Validation Loss = 1.7602, Validation Accuracy = 0.3214\n",
      "Epoch 14/80 took 0.0514 seconds\n",
      "Epoch 15: Training Loss = 1.7517, Validation Loss = 1.7021, Validation Accuracy = 0.3884\n",
      "Epoch 15/80 took 0.0523 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Training Loss = 1.7173, Validation Loss = 1.7423, Validation Accuracy = 0.3348\n",
      "Epoch 16/80 took 0.0522 seconds\n",
      "Epoch 17: Training Loss = 1.6980, Validation Loss = 1.6522, Validation Accuracy = 0.3817\n",
      "Epoch 17/80 took 0.0516 seconds\n",
      "Epoch 18: Training Loss = 1.5991, Validation Loss = 1.6928, Validation Accuracy = 0.3906\n",
      "Epoch 18/80 took 0.0516 seconds\n",
      "Epoch 19: Training Loss = 1.5919, Validation Loss = 1.5886, Validation Accuracy = 0.4330\n",
      "Epoch 19/80 took 0.0521 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Training Loss = 1.6312, Validation Loss = 1.6474, Validation Accuracy = 0.3929\n",
      "Epoch 20/80 took 0.0538 seconds\n",
      "Epoch 21: Training Loss = 1.6032, Validation Loss = 1.5041, Validation Accuracy = 0.4754\n",
      "Epoch 21/80 took 0.0515 seconds\n",
      "Epoch 22: Training Loss = 1.5456, Validation Loss = 1.5439, Validation Accuracy = 0.4286\n",
      "Epoch 22/80 took 0.0529 seconds\n",
      "Epoch 23: Training Loss = 1.5534, Validation Loss = 1.3962, Validation Accuracy = 0.5446\n",
      "Epoch 23/80 took 0.0515 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Training Loss = 1.4298, Validation Loss = 1.4104, Validation Accuracy = 0.5134\n",
      "Epoch 24/80 took 0.0531 seconds\n",
      "Epoch 25: Training Loss = 1.4482, Validation Loss = 1.4102, Validation Accuracy = 0.4888\n",
      "Epoch 25/80 took 0.0519 seconds\n",
      "Epoch 26: Training Loss = 1.3011, Validation Loss = 1.3455, Validation Accuracy = 0.5223\n",
      "Epoch 26/80 took 0.0522 seconds\n",
      "Epoch 27: Training Loss = 1.2721, Validation Loss = 1.3218, Validation Accuracy = 0.5156\n",
      "Epoch 27/80 took 0.0518 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Training Loss = 1.3519, Validation Loss = 1.2503, Validation Accuracy = 0.5446\n",
      "Epoch 28/80 took 0.0522 seconds\n",
      "Epoch 29: Training Loss = 1.1772, Validation Loss = 1.1688, Validation Accuracy = 0.6049\n",
      "Epoch 29/80 took 0.0516 seconds\n",
      "Epoch 30: Training Loss = 1.1537, Validation Loss = 1.1478, Validation Accuracy = 0.5982\n",
      "Epoch 30/80 took 0.0521 seconds\n",
      "Epoch 31: Training Loss = 1.1815, Validation Loss = 1.1110, Validation Accuracy = 0.6004\n",
      "Epoch 31/80 took 0.0525 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Training Loss = 1.1633, Validation Loss = 1.1085, Validation Accuracy = 0.6116\n",
      "Epoch 32/80 took 0.0547 seconds\n",
      "Epoch 33: Training Loss = 1.0988, Validation Loss = 1.1109, Validation Accuracy = 0.6161\n",
      "Epoch 33/80 took 0.0517 seconds\n",
      "Epoch 34: Training Loss = 1.0707, Validation Loss = 1.0710, Validation Accuracy = 0.6116\n",
      "Epoch 34/80 took 0.0524 seconds\n",
      "Epoch 35: Training Loss = 0.9533, Validation Loss = 0.9490, Validation Accuracy = 0.7054\n",
      "Epoch 35/80 took 0.0520 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Training Loss = 1.0494, Validation Loss = 1.1507, Validation Accuracy = 0.5625\n",
      "Epoch 36/80 took 0.0547 seconds\n",
      "Epoch 37: Training Loss = 1.0818, Validation Loss = 0.9885, Validation Accuracy = 0.6674\n",
      "Epoch 37/80 took 0.0524 seconds\n",
      "Epoch 38: Training Loss = 0.9804, Validation Loss = 1.0272, Validation Accuracy = 0.6250\n",
      "Epoch 38/80 took 0.0518 seconds\n",
      "Epoch 39: Training Loss = 0.9783, Validation Loss = 0.9010, Validation Accuracy = 0.6920\n",
      "Epoch 39/80 took 0.0515 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Training Loss = 0.9178, Validation Loss = 0.8643, Validation Accuracy = 0.7098\n",
      "Epoch 40/80 took 0.0530 seconds\n",
      "Epoch 41: Training Loss = 0.8779, Validation Loss = 0.9718, Validation Accuracy = 0.6897\n",
      "Epoch 41/80 took 0.0516 seconds\n",
      "Epoch 42: Training Loss = 0.9576, Validation Loss = 0.7852, Validation Accuracy = 0.7232\n",
      "Epoch 42/80 took 0.0519 seconds\n",
      "Epoch 43: Training Loss = 0.7696, Validation Loss = 0.8293, Validation Accuracy = 0.7121\n",
      "Epoch 43/80 took 0.0516 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Training Loss = 0.8142, Validation Loss = 0.7174, Validation Accuracy = 0.7768\n",
      "Epoch 44/80 took 0.0522 seconds\n",
      "Epoch 45: Training Loss = 0.6934, Validation Loss = 0.6895, Validation Accuracy = 0.7679\n",
      "Epoch 45/80 took 0.0518 seconds\n",
      "Epoch 46: Training Loss = 0.6646, Validation Loss = 0.7909, Validation Accuracy = 0.7076\n",
      "Epoch 46/80 took 0.0519 seconds\n",
      "Epoch 47: Training Loss = 0.7035, Validation Loss = 0.7284, Validation Accuracy = 0.7545\n",
      "Epoch 47/80 took 0.0521 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Training Loss = 0.7651, Validation Loss = 0.7334, Validation Accuracy = 0.7210\n",
      "Epoch 48/80 took 0.0527 seconds\n",
      "Epoch 49: Training Loss = 0.8158, Validation Loss = 0.7277, Validation Accuracy = 0.7567\n",
      "Epoch 49/80 took 0.0521 seconds\n",
      "Epoch 50: Training Loss = 0.7384, Validation Loss = 0.8172, Validation Accuracy = 0.7076\n",
      "Epoch 50/80 took 0.0520 seconds\n",
      "Epoch 51: Training Loss = 0.7698, Validation Loss = 0.8071, Validation Accuracy = 0.7321\n",
      "Epoch 51/80 took 0.0516 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Training Loss = 0.7460, Validation Loss = 0.7683, Validation Accuracy = 0.7500\n",
      "Epoch 52/80 took 0.0529 seconds\n",
      "Epoch 53: Training Loss = 0.6499, Validation Loss = 0.6927, Validation Accuracy = 0.7500\n",
      "Epoch 53/80 took 0.0522 seconds\n",
      "Epoch 54: Training Loss = 0.6052, Validation Loss = 0.6268, Validation Accuracy = 0.7790\n",
      "Epoch 54/80 took 0.0518 seconds\n",
      "Epoch 55: Training Loss = 0.6178, Validation Loss = 0.5428, Validation Accuracy = 0.8259\n",
      "Epoch 55/80 took 0.0521 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Training Loss = 0.5608, Validation Loss = 0.5425, Validation Accuracy = 0.8326\n",
      "Epoch 56/80 took 0.0543 seconds\n",
      "Epoch 57: Training Loss = 0.5394, Validation Loss = 0.4458, Validation Accuracy = 0.8571\n",
      "Epoch 57/80 took 0.0519 seconds\n",
      "Epoch 58: Training Loss = 0.5119, Validation Loss = 0.4871, Validation Accuracy = 0.8371\n",
      "Epoch 58/80 took 0.0669 seconds\n",
      "Epoch 59: Training Loss = 0.4394, Validation Loss = 0.4280, Validation Accuracy = 0.8705\n",
      "Epoch 59/80 took 0.0521 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Training Loss = 0.3429, Validation Loss = 0.4125, Validation Accuracy = 0.8728\n",
      "Epoch 60/80 took 0.0534 seconds\n",
      "Epoch 61: Training Loss = 0.3609, Validation Loss = 0.2834, Validation Accuracy = 0.9353\n",
      "Epoch 61/80 took 0.0517 seconds\n",
      "Epoch 62: Training Loss = 0.3262, Validation Loss = 0.3017, Validation Accuracy = 0.9085\n",
      "Epoch 62/80 took 0.0519 seconds\n",
      "Epoch 63: Training Loss = 0.2894, Validation Loss = 0.2906, Validation Accuracy = 0.9040\n",
      "Epoch 63/80 took 0.0520 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: Training Loss = 0.2480, Validation Loss = 0.2902, Validation Accuracy = 0.9107\n",
      "Epoch 64/80 took 0.0528 seconds\n",
      "Epoch 65: Training Loss = 0.2477, Validation Loss = 0.2212, Validation Accuracy = 0.9420\n",
      "Epoch 65/80 took 0.0517 seconds\n",
      "Epoch 66: Training Loss = 0.1816, Validation Loss = 0.2300, Validation Accuracy = 0.9420\n",
      "Epoch 66/80 took 0.0516 seconds\n",
      "Epoch 67: Training Loss = 0.2251, Validation Loss = 0.1557, Validation Accuracy = 0.9754\n",
      "Epoch 67/80 took 0.0518 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: Training Loss = 0.1607, Validation Loss = 0.1625, Validation Accuracy = 0.9621\n",
      "Epoch 68/80 took 0.0529 seconds\n",
      "Epoch 69: Training Loss = 0.1851, Validation Loss = 0.1756, Validation Accuracy = 0.9598\n",
      "Epoch 69/80 took 0.0518 seconds\n",
      "Epoch 70: Training Loss = 0.1694, Validation Loss = 0.2109, Validation Accuracy = 0.9308\n",
      "Epoch 70/80 took 0.0522 seconds\n",
      "Epoch 71: Training Loss = 0.1941, Validation Loss = 0.1960, Validation Accuracy = 0.9464\n",
      "Epoch 71/80 took 0.0520 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: Training Loss = 0.1501, Validation Loss = 0.1372, Validation Accuracy = 0.9732\n",
      "Epoch 72/80 took 0.0525 seconds\n",
      "Epoch 73: Training Loss = 0.1382, Validation Loss = 0.1261, Validation Accuracy = 0.9754\n",
      "Epoch 73/80 took 0.0515 seconds\n",
      "Epoch 74: Training Loss = 0.1231, Validation Loss = 0.1195, Validation Accuracy = 0.9732\n",
      "Epoch 74/80 took 0.0521 seconds\n",
      "Epoch 75: Training Loss = 0.1503, Validation Loss = 0.1631, Validation Accuracy = 0.9487\n",
      "Epoch 75/80 took 0.0520 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: Training Loss = 0.1663, Validation Loss = 0.1322, Validation Accuracy = 0.9754\n",
      "Epoch 76/80 took 0.0541 seconds\n",
      "Epoch 77: Training Loss = 0.1120, Validation Loss = 0.1144, Validation Accuracy = 0.9777\n",
      "Epoch 77/80 took 0.0519 seconds\n",
      "Epoch 78: Training Loss = 0.1122, Validation Loss = 0.0961, Validation Accuracy = 0.9888\n",
      "Epoch 78/80 took 0.0517 seconds\n",
      "Epoch 79: Training Loss = 0.0958, Validation Loss = 0.0852, Validation Accuracy = 0.9844\n",
      "Epoch 79/80 took 0.0515 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: Training Loss = 0.0722, Validation Loss = 0.0679, Validation Accuracy = 0.9933\n",
      "Epoch 80/80 took 0.0529 seconds\n",
      "Finished training after 80 epochs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2.5854297,\n",
       "  2.2497468,\n",
       "  2.1547399,\n",
       "  2.1165285,\n",
       "  2.0975192,\n",
       "  2.0260031,\n",
       "  2.0233045,\n",
       "  2.0125296,\n",
       "  1.93002,\n",
       "  1.9201531,\n",
       "  1.8509347,\n",
       "  1.889932,\n",
       "  1.8792644,\n",
       "  1.7786869,\n",
       "  1.7516723,\n",
       "  1.7173429,\n",
       "  1.697966,\n",
       "  1.5990942,\n",
       "  1.5918684,\n",
       "  1.6312492,\n",
       "  1.6032494,\n",
       "  1.545558,\n",
       "  1.5533642,\n",
       "  1.4297822,\n",
       "  1.4482217,\n",
       "  1.301119,\n",
       "  1.2720656,\n",
       "  1.3518972,\n",
       "  1.1772319,\n",
       "  1.1537479,\n",
       "  1.1814579,\n",
       "  1.1633275,\n",
       "  1.098788,\n",
       "  1.0707209,\n",
       "  0.95325476,\n",
       "  1.0494305,\n",
       "  1.0817847,\n",
       "  0.98039925,\n",
       "  0.9782729,\n",
       "  0.9178203,\n",
       "  0.87792253,\n",
       "  0.95758,\n",
       "  0.76955914,\n",
       "  0.8141868,\n",
       "  0.69339216,\n",
       "  0.6646242,\n",
       "  0.7035171,\n",
       "  0.7651026,\n",
       "  0.8157638,\n",
       "  0.7384411,\n",
       "  0.7697588,\n",
       "  0.74597955,\n",
       "  0.6499058,\n",
       "  0.6051854,\n",
       "  0.61780906,\n",
       "  0.56082433,\n",
       "  0.53941995,\n",
       "  0.5118757,\n",
       "  0.43944666,\n",
       "  0.3429498,\n",
       "  0.3608862,\n",
       "  0.32623875,\n",
       "  0.28941652,\n",
       "  0.24795817,\n",
       "  0.24768978,\n",
       "  0.1816405,\n",
       "  0.22513843,\n",
       "  0.16066617,\n",
       "  0.185137,\n",
       "  0.16936228,\n",
       "  0.19414638,\n",
       "  0.15012631,\n",
       "  0.1381653,\n",
       "  0.12310675,\n",
       "  0.15025103,\n",
       "  0.16629529,\n",
       "  0.11202556,\n",
       "  0.11215307,\n",
       "  0.09577742,\n",
       "  0.07224955],\n",
       " [2.3263412,\n",
       "  2.1903217,\n",
       "  2.1454298,\n",
       "  2.097936,\n",
       "  2.0722785,\n",
       "  2.0176456,\n",
       "  2.026427,\n",
       "  1.9709436,\n",
       "  1.9439955,\n",
       "  1.8925234,\n",
       "  1.8679421,\n",
       "  1.8092663,\n",
       "  1.8117275,\n",
       "  1.7601978,\n",
       "  1.7021434,\n",
       "  1.7422774,\n",
       "  1.6522208,\n",
       "  1.6927973,\n",
       "  1.5886105,\n",
       "  1.6474141,\n",
       "  1.5041031,\n",
       "  1.5439138,\n",
       "  1.3962096,\n",
       "  1.410425,\n",
       "  1.4102246,\n",
       "  1.345521,\n",
       "  1.3217894,\n",
       "  1.2503194,\n",
       "  1.1688378,\n",
       "  1.1478032,\n",
       "  1.1109521,\n",
       "  1.1084989,\n",
       "  1.11088,\n",
       "  1.0710433,\n",
       "  0.9489695,\n",
       "  1.1506708,\n",
       "  0.9884831,\n",
       "  1.02721,\n",
       "  0.90101355,\n",
       "  0.8643016,\n",
       "  0.9718357,\n",
       "  0.78519535,\n",
       "  0.8292659,\n",
       "  0.717416,\n",
       "  0.689535,\n",
       "  0.7908986,\n",
       "  0.72842544,\n",
       "  0.7334419,\n",
       "  0.72771984,\n",
       "  0.8171522,\n",
       "  0.8070806,\n",
       "  0.76830626,\n",
       "  0.69273365,\n",
       "  0.62680244,\n",
       "  0.54283375,\n",
       "  0.5424834,\n",
       "  0.4458262,\n",
       "  0.48705295,\n",
       "  0.4279978,\n",
       "  0.41250756,\n",
       "  0.2834334,\n",
       "  0.3016911,\n",
       "  0.29063302,\n",
       "  0.29016072,\n",
       "  0.22121589,\n",
       "  0.22995345,\n",
       "  0.15567884,\n",
       "  0.16249199,\n",
       "  0.17560911,\n",
       "  0.21090987,\n",
       "  0.19596808,\n",
       "  0.13721056,\n",
       "  0.12612839,\n",
       "  0.11946124,\n",
       "  0.16313677,\n",
       "  0.1321732,\n",
       "  0.11444882,\n",
       "  0.096068226,\n",
       "  0.085170515,\n",
       "  0.067856714],\n",
       " [0.14732143,\n",
       "  0.19196428,\n",
       "  0.21875,\n",
       "  0.203125,\n",
       "  0.22991072,\n",
       "  0.23883928,\n",
       "  0.22767857,\n",
       "  0.29464287,\n",
       "  0.2700893,\n",
       "  0.2700893,\n",
       "  0.29464287,\n",
       "  0.36607143,\n",
       "  0.3013393,\n",
       "  0.32142857,\n",
       "  0.38839287,\n",
       "  0.33482143,\n",
       "  0.38169643,\n",
       "  0.390625,\n",
       "  0.4330357,\n",
       "  0.39285713,\n",
       "  0.47544643,\n",
       "  0.42857143,\n",
       "  0.54464287,\n",
       "  0.51339287,\n",
       "  0.4888393,\n",
       "  0.5223214,\n",
       "  0.515625,\n",
       "  0.54464287,\n",
       "  0.60491073,\n",
       "  0.59821427,\n",
       "  0.6004464,\n",
       "  0.61160713,\n",
       "  0.6160714,\n",
       "  0.61160713,\n",
       "  0.70535713,\n",
       "  0.5625,\n",
       "  0.66741073,\n",
       "  0.625,\n",
       "  0.69196427,\n",
       "  0.7098214,\n",
       "  0.68973213,\n",
       "  0.72321427,\n",
       "  0.7120536,\n",
       "  0.77678573,\n",
       "  0.76785713,\n",
       "  0.70758927,\n",
       "  0.75446427,\n",
       "  0.72098213,\n",
       "  0.7566964,\n",
       "  0.70758927,\n",
       "  0.73214287,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.77901787,\n",
       "  0.82589287,\n",
       "  0.83258927,\n",
       "  0.85714287,\n",
       "  0.8370536,\n",
       "  0.87053573,\n",
       "  0.87276787,\n",
       "  0.93526787,\n",
       "  0.90848213,\n",
       "  0.90401787,\n",
       "  0.91071427,\n",
       "  0.94196427,\n",
       "  0.94196427,\n",
       "  0.9754464,\n",
       "  0.9620536,\n",
       "  0.9598214,\n",
       "  0.9308036,\n",
       "  0.9464286,\n",
       "  0.97321427,\n",
       "  0.9754464,\n",
       "  0.97321427,\n",
       "  0.94866073,\n",
       "  0.9754464,\n",
       "  0.9776786,\n",
       "  0.98883927,\n",
       "  0.984375,\n",
       "  0.9933036],\n",
       " 80)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model = ResNet8(10, (32,32,3), reg = 0)\n",
    "model.compile(optimizer='adamw')\n",
    "model.fit(x_dev, y_dev, x_dev, y_dev, max_epochs = 80, val_every = 1, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66117",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 7c. Train ResNet-8 on CIFAR-10\n",
    "\n",
    "Repeat our usual training and evaluation protocol:\n",
    "1. Train ResNet-8 on CIFAR-10. Use regularization strength of `1.5`, a patience of `15`, learning rate patience of `4`, and keep the rest of the hyperparameters to their defaults.\n",
    "2. Print the test accuracy.\n",
    "\n",
    "If everything is working as expected, you should get a test accuracy in the 80s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7efc9b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output) shape: [1, 10]\n",
      "Global Avg Pooling 2D layer output(GlobalAveragePool2D) shape: [1, 128]\n",
      "ResidualBlock_3:\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_2) shape: [1, 8, 8, 128]\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_1) shape: [1, 8, 8, 128]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_3/skip_conv1x1) shape: [1, 8, 8, 128]-->\n",
      "ResidualBlock_2:\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_2) shape: [1, 16, 16, 64]\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_1) shape: [1, 16, 16, 64]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_2/skip_conv1x1) shape: [1, 16, 16, 64]-->\n",
      "ResidualBlock_1:\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_2) shape: [1, 32, 32, 32]\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_1) shape: [1, 32, 32, 32]\n",
      "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss = 1.7492, Validation Loss = 1.5184, Validation Accuracy = 0.4453\n",
      "Epoch 1/10000 took 6.6293 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Training Loss = 1.4277, Validation Loss = 1.3107, Validation Accuracy = 0.5226\n",
      "Epoch 2/10000 took 3.1285 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Training Loss = 1.3299, Validation Loss = 1.2617, Validation Accuracy = 0.5461\n",
      "Epoch 3/10000 took 3.1370 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Training Loss = 1.2878, Validation Loss = 1.1990, Validation Accuracy = 0.5723\n",
      "Epoch 4/10000 took 3.1521 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Training Loss = 1.2960, Validation Loss = 1.2461, Validation Accuracy = 0.5501\n",
      "Epoch 5/10000 took 3.2221 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Training Loss = 1.2777, Validation Loss = 1.2594, Validation Accuracy = 0.5535\n",
      "Epoch 6/10000 took 3.1624 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Training Loss = 1.2627, Validation Loss = 1.1886, Validation Accuracy = 0.5831\n",
      "Epoch 7/10000 took 3.1776 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Training Loss = 1.2336, Validation Loss = 1.1834, Validation Accuracy = 0.5815\n",
      "Epoch 8/10000 took 3.1750 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Training Loss = 1.2484, Validation Loss = 1.1796, Validation Accuracy = 0.5857\n",
      "Epoch 9/10000 took 3.1867 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Training Loss = 1.2276, Validation Loss = 1.2603, Validation Accuracy = 0.5505\n",
      "Epoch 10/10000 took 3.2105 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Training Loss = 1.2297, Validation Loss = 1.1390, Validation Accuracy = 0.5859\n",
      "Epoch 11/10000 took 3.2149 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Training Loss = 1.2252, Validation Loss = 1.2287, Validation Accuracy = 0.5601\n",
      "Epoch 12/10000 took 3.2049 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Training Loss = 1.2241, Validation Loss = 1.2764, Validation Accuracy = 0.5611\n",
      "Epoch 13/10000 took 3.2073 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 0.001 Updated lr= 0.0005\n",
      "Epoch 14: Training Loss = 1.2332, Validation Loss = 1.2713, Validation Accuracy = 0.5513\n",
      "Epoch 14/10000 took 3.2331 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Training Loss = 1.1729, Validation Loss = 1.1867, Validation Accuracy = 0.5677\n",
      "Epoch 15/10000 took 3.2256 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Training Loss = 1.1565, Validation Loss = 1.1570, Validation Accuracy = 0.5988\n",
      "Epoch 16/10000 took 3.2314 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Training Loss = 1.1674, Validation Loss = 1.2069, Validation Accuracy = 0.5689\n",
      "Epoch 17/10000 took 3.2467 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Training Loss = 1.1725, Validation Loss = 1.1347, Validation Accuracy = 0.5960\n",
      "Epoch 18/10000 took 3.2366 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Training Loss = 1.1752, Validation Loss = 1.1831, Validation Accuracy = 0.5697\n",
      "Epoch 19/10000 took 3.2346 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Training Loss = 1.1776, Validation Loss = 1.1544, Validation Accuracy = 0.5917\n",
      "Epoch 20/10000 took 3.2369 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 0.0005 Updated lr= 0.00025\n",
      "Epoch 21: Training Loss = 1.1681, Validation Loss = 1.2113, Validation Accuracy = 0.5659\n",
      "Epoch 21/10000 took 3.2365 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Training Loss = 1.1304, Validation Loss = 1.1113, Validation Accuracy = 0.6114\n",
      "Epoch 22/10000 took 3.2264 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Training Loss = 1.1412, Validation Loss = 1.1097, Validation Accuracy = 0.6070\n",
      "Epoch 23/10000 took 3.2285 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Training Loss = 1.1295, Validation Loss = 1.1107, Validation Accuracy = 0.6142\n",
      "Epoch 24/10000 took 3.2474 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Training Loss = 1.1200, Validation Loss = 1.1513, Validation Accuracy = 0.5791\n",
      "Epoch 25/10000 took 3.2386 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Training Loss = 1.1178, Validation Loss = 1.0878, Validation Accuracy = 0.6238\n",
      "Epoch 26/10000 took 3.2272 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Training Loss = 1.1254, Validation Loss = 1.0905, Validation Accuracy = 0.6204\n",
      "Epoch 27/10000 took 3.2170 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Training Loss = 1.1198, Validation Loss = 1.1413, Validation Accuracy = 0.6012\n",
      "Epoch 28/10000 took 3.2156 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 0.00025 Updated lr= 0.000125\n",
      "Epoch 29: Training Loss = 1.1397, Validation Loss = 1.1166, Validation Accuracy = 0.6088\n",
      "Epoch 29/10000 took 3.2225 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Training Loss = 1.0867, Validation Loss = 1.0618, Validation Accuracy = 0.6298\n",
      "Epoch 30/10000 took 3.2261 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Training Loss = 1.0909, Validation Loss = 1.0827, Validation Accuracy = 0.6162\n",
      "Epoch 31/10000 took 3.2175 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Training Loss = 1.0929, Validation Loss = 1.0738, Validation Accuracy = 0.6234\n",
      "Epoch 32/10000 took 3.2021 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Training Loss = 1.1016, Validation Loss = 1.0840, Validation Accuracy = 0.6186\n",
      "Epoch 33/10000 took 3.2372 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Training Loss = 1.0965, Validation Loss = 1.0726, Validation Accuracy = 0.6336\n",
      "Epoch 34/10000 took 3.2140 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Training Loss = 1.0947, Validation Loss = 1.0890, Validation Accuracy = 0.6192\n",
      "Epoch 35/10000 took 3.2231 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Training Loss = 1.1007, Validation Loss = 1.0872, Validation Accuracy = 0.6204\n",
      "Epoch 36/10000 took 3.2124 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Training Loss = 1.0958, Validation Loss = 1.0597, Validation Accuracy = 0.6312\n",
      "Epoch 37/10000 took 3.2140 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Training Loss = 1.0964, Validation Loss = 1.0909, Validation Accuracy = 0.6230\n",
      "Epoch 38/10000 took 3.2418 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Training Loss = 1.0947, Validation Loss = 1.0756, Validation Accuracy = 0.6262\n",
      "Epoch 39/10000 took 3.2152 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 0.000125 Updated lr= 6.25e-05\n",
      "Epoch 40: Training Loss = 1.0961, Validation Loss = 1.0785, Validation Accuracy = 0.6264\n",
      "Epoch 40/10000 took 3.2212 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Training Loss = 1.0791, Validation Loss = 1.0546, Validation Accuracy = 0.6348\n",
      "Epoch 41/10000 took 3.2188 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Training Loss = 1.0777, Validation Loss = 1.0730, Validation Accuracy = 0.6228\n",
      "Epoch 42/10000 took 3.2185 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Training Loss = 1.0730, Validation Loss = 1.0727, Validation Accuracy = 0.6264\n",
      "Epoch 43/10000 took 3.2187 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Training Loss = 1.0814, Validation Loss = 1.0580, Validation Accuracy = 0.6356\n",
      "Epoch 44/10000 took 3.2230 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Training Loss = 1.0641, Validation Loss = 1.0590, Validation Accuracy = 0.6342\n",
      "Epoch 45/10000 took 3.2132 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Training Loss = 1.0727, Validation Loss = 1.0573, Validation Accuracy = 0.6284\n",
      "Epoch 46/10000 took 3.2159 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Training Loss = 1.0786, Validation Loss = 1.0612, Validation Accuracy = 0.6304\n",
      "Epoch 47/10000 took 3.2223 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Training Loss = 1.0791, Validation Loss = 1.0647, Validation Accuracy = 0.6264\n",
      "Epoch 48/10000 took 3.2221 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 6.25e-05 Updated lr= 3.125e-05\n",
      "Epoch 49: Training Loss = 1.0721, Validation Loss = 1.0833, Validation Accuracy = 0.6182\n",
      "Epoch 49/10000 took 3.2165 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Training Loss = 1.0576, Validation Loss = 1.0592, Validation Accuracy = 0.6294\n",
      "Epoch 50/10000 took 3.2159 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Training Loss = 1.0612, Validation Loss = 1.0441, Validation Accuracy = 0.6400\n",
      "Epoch 51/10000 took 3.2148 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Training Loss = 1.0626, Validation Loss = 1.0661, Validation Accuracy = 0.6248\n",
      "Epoch 52/10000 took 3.2474 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: Training Loss = 1.0562, Validation Loss = 1.0397, Validation Accuracy = 0.6404\n",
      "Epoch 53/10000 took 3.2129 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Training Loss = 1.0576, Validation Loss = 1.0464, Validation Accuracy = 0.6348\n",
      "Epoch 54/10000 took 3.2155 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Training Loss = 1.0483, Validation Loss = 1.0608, Validation Accuracy = 0.6318\n",
      "Epoch 55/10000 took 3.2127 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 3.125e-05 Updated lr= 1.5625e-05\n",
      "Epoch 56: Training Loss = 1.0493, Validation Loss = 1.0526, Validation Accuracy = 0.6352\n",
      "Epoch 56/10000 took 3.2199 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Training Loss = 1.0492, Validation Loss = 1.0408, Validation Accuracy = 0.6390\n",
      "Epoch 57/10000 took 3.2108 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Training Loss = 1.0485, Validation Loss = 1.0425, Validation Accuracy = 0.6390\n",
      "Epoch 58/10000 took 3.2155 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Training Loss = 1.0485, Validation Loss = 1.0396, Validation Accuracy = 0.6356\n",
      "Epoch 59/10000 took 3.2323 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Training Loss = 1.0494, Validation Loss = 1.0426, Validation Accuracy = 0.6374\n",
      "Epoch 60/10000 took 3.2128 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: Training Loss = 1.0501, Validation Loss = 1.0429, Validation Accuracy = 0.6394\n",
      "Epoch 61/10000 took 3.2189 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 1.5625e-05 Updated lr= 7.8125e-06\n",
      "Epoch 62: Training Loss = 1.0506, Validation Loss = 1.0463, Validation Accuracy = 0.6388\n",
      "Epoch 62/10000 took 3.2114 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: Training Loss = 1.0471, Validation Loss = 1.0399, Validation Accuracy = 0.6380\n",
      "Epoch 63/10000 took 3.2149 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: Training Loss = 1.0486, Validation Loss = 1.0373, Validation Accuracy = 0.6414\n",
      "Epoch 64/10000 took 3.2161 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: Training Loss = 1.0401, Validation Loss = 1.0346, Validation Accuracy = 0.6384\n",
      "Epoch 65/10000 took 3.2205 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: Training Loss = 1.0482, Validation Loss = 1.0333, Validation Accuracy = 0.6416\n",
      "Epoch 66/10000 took 3.2465 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: Training Loss = 1.0421, Validation Loss = 1.0326, Validation Accuracy = 0.6420\n",
      "Epoch 67/10000 took 3.2209 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: Training Loss = 1.0409, Validation Loss = 1.0326, Validation Accuracy = 0.6412\n",
      "Epoch 68/10000 took 3.2178 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: Training Loss = 1.0433, Validation Loss = 1.0352, Validation Accuracy = 0.6412\n",
      "Epoch 69/10000 took 3.2266 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 7.8125e-06 Updated lr= 3.90625e-06\n",
      "Epoch 70: Training Loss = 1.0379, Validation Loss = 1.0412, Validation Accuracy = 0.6394\n",
      "Epoch 70/10000 took 3.2248 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: Training Loss = 1.0422, Validation Loss = 1.0324, Validation Accuracy = 0.6392\n",
      "Epoch 71/10000 took 3.2115 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: Training Loss = 1.0394, Validation Loss = 1.0326, Validation Accuracy = 0.6390\n",
      "Epoch 72/10000 took 3.2131 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: Training Loss = 1.0415, Validation Loss = 1.0322, Validation Accuracy = 0.6394\n",
      "Epoch 73/10000 took 3.2155 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: Training Loss = 1.0357, Validation Loss = 1.0314, Validation Accuracy = 0.6398\n",
      "Epoch 74/10000 took 3.2258 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: Training Loss = 1.0368, Validation Loss = 1.0322, Validation Accuracy = 0.6424\n",
      "Epoch 75/10000 took 3.2165 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: Training Loss = 1.0352, Validation Loss = 1.0329, Validation Accuracy = 0.6438\n",
      "Epoch 76/10000 took 3.2131 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: Training Loss = 1.0405, Validation Loss = 1.0303, Validation Accuracy = 0.6420\n",
      "Epoch 77/10000 took 3.2196 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: Training Loss = 1.0496, Validation Loss = 1.0347, Validation Accuracy = 0.6394\n",
      "Epoch 78/10000 took 3.2165 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79: Training Loss = 1.0343, Validation Loss = 1.0323, Validation Accuracy = 0.6424\n",
      "Epoch 79/10000 took 3.2120 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 3.90625e-06 Updated lr= 1.953125e-06\n",
      "Epoch 80: Training Loss = 1.0360, Validation Loss = 1.0319, Validation Accuracy = 0.6440\n",
      "Epoch 80/10000 took 3.2439 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: Training Loss = 1.0366, Validation Loss = 1.0299, Validation Accuracy = 0.6434\n",
      "Epoch 81/10000 took 3.2066 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: Training Loss = 1.0324, Validation Loss = 1.0305, Validation Accuracy = 0.6426\n",
      "Epoch 82/10000 took 3.2159 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83: Training Loss = 1.0383, Validation Loss = 1.0311, Validation Accuracy = 0.6396\n",
      "Epoch 83/10000 took 3.2135 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84: Training Loss = 1.0393, Validation Loss = 1.0305, Validation Accuracy = 0.6396\n",
      "Epoch 84/10000 took 3.2189 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: Training Loss = 1.0333, Validation Loss = 1.0299, Validation Accuracy = 0.6430\n",
      "Epoch 85/10000 took 3.2131 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86: Training Loss = 1.0444, Validation Loss = 1.0310, Validation Accuracy = 0.6412\n",
      "Epoch 86/10000 took 3.2119 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: Training Loss = 1.0403, Validation Loss = 1.0303, Validation Accuracy = 0.6424\n",
      "Epoch 87/10000 took 3.2203 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: Training Loss = 1.0427, Validation Loss = 1.0285, Validation Accuracy = 0.6414\n",
      "Epoch 88/10000 took 3.2100 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: Training Loss = 1.0438, Validation Loss = 1.0306, Validation Accuracy = 0.6446\n",
      "Epoch 89/10000 took 3.2382 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Training Loss = 1.0367, Validation Loss = 1.0316, Validation Accuracy = 0.6406\n",
      "Epoch 90/10000 took 3.2214 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 1.953125e-06 Updated lr= 9.765625e-07\n",
      "Epoch 91: Training Loss = 1.0432, Validation Loss = 1.0296, Validation Accuracy = 0.6436\n",
      "Epoch 91/10000 took 3.2137 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: Training Loss = 1.0272, Validation Loss = 1.0294, Validation Accuracy = 0.6418\n",
      "Epoch 92/10000 took 3.2105 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: Training Loss = 1.0356, Validation Loss = 1.0288, Validation Accuracy = 0.6426\n",
      "Epoch 93/10000 took 3.2243 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: Training Loss = 1.0383, Validation Loss = 1.0304, Validation Accuracy = 0.6432\n",
      "Epoch 94/10000 took 3.2329 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95: Training Loss = 1.0382, Validation Loss = 1.0293, Validation Accuracy = 0.6414\n",
      "Epoch 95/10000 took 3.2246 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 9.765625e-07 Updated lr= 4.882813e-07\n",
      "Epoch 96: Training Loss = 1.0352, Validation Loss = 1.0295, Validation Accuracy = 0.6412\n",
      "Epoch 96/10000 took 3.2248 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97: Training Loss = 1.0314, Validation Loss = 1.0296, Validation Accuracy = 0.6422\n",
      "Epoch 97/10000 took 3.2129 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98: Training Loss = 1.0409, Validation Loss = 1.0290, Validation Accuracy = 0.6408\n",
      "Epoch 98/10000 took 3.2202 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Training Loss = 1.0364, Validation Loss = 1.0288, Validation Accuracy = 0.6410\n",
      "Epoch 99/10000 took 3.2124 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Training Loss = 1.0368, Validation Loss = 1.0300, Validation Accuracy = 0.6420\n",
      "Epoch 100/10000 took 3.2166 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101: Training Loss = 1.0380, Validation Loss = 1.0294, Validation Accuracy = 0.6420\n",
      "Epoch 101/10000 took 3.2096 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 4.882813e-07 Updated lr= 2.4414064e-07\n",
      "Epoch 102: Training Loss = 1.0346, Validation Loss = 1.0290, Validation Accuracy = 0.6410\n",
      "Early stopping triggered at epoch 102\n",
      "Finished training after 102 epochs!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.6266025900840759\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model = ResNet8(10, (32,32,3), reg = 1.5)\n",
    "model.compile(optimizer='adamw')\n",
    "model.fit(x_train, y_train, x_val, y_val, val_every = 1, verbose = True, patience=15, lr_patience=4)\n",
    "print(f\"Test acc: {model.evaluate(x_test, y_test)[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6defd8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 7d. Train ResNet-8 on CIFAR-100\n",
    "\n",
    "Repeat what you did with CIFAR-10, but this time with CIFAR-100.\n",
    "\n",
    "The test accuracy that you achieve should be better than chance, but should NOT be satisfying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1df220",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r     8192/169001437 [..............................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   122880/169001437 [..............................] - ETA: 1:09"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   630784/169001437 [..............................] - ETA: 26s "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  2285568/169001437 [..............................] - ETA: 11s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  5193728/169001437 [..............................] - ETA: 6s "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  8126464/169001437 [>.............................] - ETA: 4s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 11001856/169001437 [>.............................] - ETA: 4s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 13910016/169001437 [=>............................] - ETA: 3s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 16826368/169001437 [=>............................] - ETA: 3s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 19750912/169001437 [==>...........................] - ETA: 3s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 22626304/169001437 [===>..........................] - ETA: 3s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 25534464/169001437 [===>..........................] - ETA: 3s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 28442624/169001437 [====>.........................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 31350784/169001437 [====>.........................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 34283520/169001437 [=====>........................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 37167104/169001437 [=====>........................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 40067072/169001437 [======>.......................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 42983424/169001437 [======>.......................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 45883392/169001437 [=======>......................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 48848896/169001437 [=======>......................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 51732480/169001437 [========>.....................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 54640640/169001437 [========>.....................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 57540608/169001437 [=========>....................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 61325312/169001437 [=========>....................] - ETA: 2s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 67534848/169001437 [==========>...................] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 73285632/169001437 [============>.................] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 79085568/169001437 [=============>................] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 84918272/169001437 [==============>...............] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 90284032/169001437 [===============>..............] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 94658560/169001437 [===============>..............] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 99434496/169001437 [================>.............] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r104398848/169001437 [=================>............] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r111017984/169001437 [==================>...........] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r116162560/169001437 [===================>..........] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121331712/169001437 [====================>.........] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r126861312/169001437 [=====================>........] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r131506176/169001437 [======================>.......] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r136740864/169001437 [=======================>......] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r143859712/169001437 [========================>.....] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r149446656/169001437 [=========================>....] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r152993792/169001437 [==========================>...] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r159072256/169001437 [===========================>..] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r163438592/169001437 [============================>.] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r168255488/169001437 [============================>.] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169001437/169001437 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output) shape: [1, 100]\n",
      "Global Avg Pooling 2D layer output(GlobalAveragePool2D) shape: [1, 128]\n",
      "ResidualBlock_3:\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_2) shape: [1, 8, 8, 128]\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_1) shape: [1, 8, 8, 128]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_3/skip_conv1x1) shape: [1, 8, 8, 128]-->\n",
      "ResidualBlock_2:\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_2) shape: [1, 16, 16, 64]\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_1) shape: [1, 16, 16, 64]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_2/skip_conv1x1) shape: [1, 16, 16, 64]-->\n",
      "ResidualBlock_1:\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_2) shape: [1, 32, 32, 32]\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_1) shape: [1, 32, 32, 32]\n",
      "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss = 4.0777, Validation Loss = 3.8198, Validation Accuracy = 0.1138\n",
      "Epoch 1/10000 took 6.8931 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Training Loss = 3.5954, Validation Loss = 3.5259, Validation Accuracy = 0.1611\n",
      "Epoch 2/10000 took 3.2170 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Training Loss = 3.3591, Validation Loss = 3.4013, Validation Accuracy = 0.1843\n",
      "Epoch 3/10000 took 3.2229 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Training Loss = 3.2372, Validation Loss = 3.2863, Validation Accuracy = 0.1957\n",
      "Epoch 4/10000 took 3.2675 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Training Loss = 3.1385, Validation Loss = 3.2131, Validation Accuracy = 0.2169\n",
      "Epoch 5/10000 took 3.2474 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Training Loss = 3.0977, Validation Loss = 3.1697, Validation Accuracy = 0.2226\n",
      "Epoch 6/10000 took 3.2627 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Training Loss = 3.0435, Validation Loss = 3.1140, Validation Accuracy = 0.2382\n",
      "Epoch 7/10000 took 3.2644 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Training Loss = 3.0060, Validation Loss = 3.0404, Validation Accuracy = 0.2522\n",
      "Epoch 8/10000 took 3.2504 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Training Loss = 2.9963, Validation Loss = 3.1313, Validation Accuracy = 0.2414\n",
      "Epoch 9/10000 took 3.2402 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Training Loss = 2.9722, Validation Loss = 3.0262, Validation Accuracy = 0.2588\n",
      "Epoch 10/10000 took 3.2358 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Training Loss = 2.9763, Validation Loss = 3.0136, Validation Accuracy = 0.2596\n",
      "Epoch 11/10000 took 3.2295 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Training Loss = 2.9703, Validation Loss = 3.0335, Validation Accuracy = 0.2572\n",
      "Epoch 12/10000 took 3.2299 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Training Loss = 2.9459, Validation Loss = 3.0852, Validation Accuracy = 0.2518\n",
      "Epoch 13/10000 took 3.2312 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 0.001 Updated lr= 0.0005\n",
      "Epoch 14: Training Loss = 2.9322, Validation Loss = 3.0826, Validation Accuracy = 0.2466\n",
      "Epoch 14/10000 took 3.2271 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Training Loss = 2.7682, Validation Loss = 2.8718, Validation Accuracy = 0.2895\n",
      "Epoch 15/10000 took 3.2186 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Training Loss = 2.7297, Validation Loss = 2.9567, Validation Accuracy = 0.2698\n",
      "Epoch 16/10000 took 3.2175 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Training Loss = 2.7366, Validation Loss = 2.8812, Validation Accuracy = 0.2790\n",
      "Epoch 17/10000 took 3.2144 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Training Loss = 2.7248, Validation Loss = 2.8225, Validation Accuracy = 0.2963\n",
      "Epoch 18/10000 took 3.2146 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Training Loss = 2.7305, Validation Loss = 2.8197, Validation Accuracy = 0.2987\n",
      "Epoch 19/10000 took 3.2227 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Training Loss = 2.7191, Validation Loss = 2.8531, Validation Accuracy = 0.2975\n",
      "Epoch 20/10000 took 3.2299 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Training Loss = 2.7084, Validation Loss = 2.8706, Validation Accuracy = 0.2845\n",
      "Epoch 21/10000 took 3.2214 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Training Loss = 2.7331, Validation Loss = 2.8014, Validation Accuracy = 0.3075\n",
      "Epoch 22/10000 took 3.1989 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Training Loss = 2.7222, Validation Loss = 2.8485, Validation Accuracy = 0.2983\n",
      "Epoch 23/10000 took 3.2011 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Training Loss = 2.7385, Validation Loss = 2.8615, Validation Accuracy = 0.2959\n",
      "Epoch 24/10000 took 3.1969 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 0.0005 Updated lr= 0.00025\n",
      "Epoch 25: Training Loss = 2.7344, Validation Loss = 2.8503, Validation Accuracy = 0.2957\n",
      "Epoch 25/10000 took 3.1992 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Training Loss = 2.5950, Validation Loss = 2.7369, Validation Accuracy = 0.3211\n",
      "Epoch 26/10000 took 3.2123 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Training Loss = 2.5790, Validation Loss = 2.7756, Validation Accuracy = 0.3171\n",
      "Epoch 27/10000 took 3.2069 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Training Loss = 2.5636, Validation Loss = 2.7076, Validation Accuracy = 0.3131\n",
      "Epoch 28/10000 took 3.2107 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Training Loss = 2.5831, Validation Loss = 2.7093, Validation Accuracy = 0.3235\n",
      "Epoch 29/10000 took 3.2222 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Training Loss = 2.5894, Validation Loss = 2.7103, Validation Accuracy = 0.3207\n",
      "Epoch 30/10000 took 3.2149 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 0.00025 Updated lr= 0.000125\n",
      "Epoch 31: Training Loss = 2.5756, Validation Loss = 2.7540, Validation Accuracy = 0.3169\n",
      "Epoch 31/10000 took 3.2202 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Training Loss = 2.4789, Validation Loss = 2.6383, Validation Accuracy = 0.3403\n",
      "Epoch 32/10000 took 3.2181 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Training Loss = 2.4627, Validation Loss = 2.6625, Validation Accuracy = 0.3323\n",
      "Epoch 33/10000 took 3.2274 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Training Loss = 2.4710, Validation Loss = 2.6230, Validation Accuracy = 0.3397\n",
      "Epoch 34/10000 took 3.2438 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Training Loss = 2.4769, Validation Loss = 2.6326, Validation Accuracy = 0.3403\n",
      "Epoch 35/10000 took 3.2325 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Training Loss = 2.4597, Validation Loss = 2.6549, Validation Accuracy = 0.3393\n",
      "Epoch 36/10000 took 3.2247 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 0.000125 Updated lr= 6.25e-05\n",
      "Epoch 37: Training Loss = 2.4661, Validation Loss = 2.6266, Validation Accuracy = 0.3472\n",
      "Epoch 37/10000 took 3.2311 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Training Loss = 2.3962, Validation Loss = 2.5987, Validation Accuracy = 0.3466\n",
      "Epoch 38/10000 took 3.2326 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Training Loss = 2.4017, Validation Loss = 2.5965, Validation Accuracy = 0.3492\n",
      "Epoch 39/10000 took 3.2258 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Training Loss = 2.3947, Validation Loss = 2.6127, Validation Accuracy = 0.3417\n",
      "Epoch 40/10000 took 3.2329 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Training Loss = 2.3854, Validation Loss = 2.5735, Validation Accuracy = 0.3508\n",
      "Epoch 41/10000 took 3.2383 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Training Loss = 2.3933, Validation Loss = 2.5874, Validation Accuracy = 0.3498\n",
      "Epoch 42/10000 took 3.2300 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Training Loss = 2.3834, Validation Loss = 2.5593, Validation Accuracy = 0.3548\n",
      "Epoch 43/10000 took 3.2275 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Training Loss = 2.3804, Validation Loss = 2.5902, Validation Accuracy = 0.3506\n",
      "Epoch 44/10000 took 3.2286 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Training Loss = 2.3803, Validation Loss = 2.5757, Validation Accuracy = 0.3534\n",
      "Epoch 45/10000 took 3.2291 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 6.25e-05 Updated lr= 3.125e-05\n",
      "Epoch 46: Training Loss = 2.3848, Validation Loss = 2.5765, Validation Accuracy = 0.3488\n",
      "Epoch 46/10000 took 3.2347 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Training Loss = 2.3441, Validation Loss = 2.5482, Validation Accuracy = 0.3560\n",
      "Epoch 47/10000 took 3.2278 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Training Loss = 2.3479, Validation Loss = 2.5438, Validation Accuracy = 0.3594\n",
      "Epoch 48/10000 took 3.2419 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Training Loss = 2.3352, Validation Loss = 2.5322, Validation Accuracy = 0.3584\n",
      "Epoch 49/10000 took 3.2178 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Training Loss = 2.3388, Validation Loss = 2.5394, Validation Accuracy = 0.3592\n",
      "Epoch 50/10000 took 3.2308 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Training Loss = 2.3329, Validation Loss = 2.5356, Validation Accuracy = 0.3630\n",
      "Epoch 51/10000 took 3.2138 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 3.125e-05 Updated lr= 1.5625e-05\n",
      "Epoch 52: Training Loss = 2.3291, Validation Loss = 2.5452, Validation Accuracy = 0.3558\n",
      "Epoch 52/10000 took 3.2171 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: Training Loss = 2.3197, Validation Loss = 2.5225, Validation Accuracy = 0.3640\n",
      "Epoch 53/10000 took 3.2152 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Training Loss = 2.3160, Validation Loss = 2.5255, Validation Accuracy = 0.3628\n",
      "Epoch 54/10000 took 3.2131 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Training Loss = 2.3116, Validation Loss = 2.5188, Validation Accuracy = 0.3644\n",
      "Epoch 55/10000 took 3.2239 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Training Loss = 2.3171, Validation Loss = 2.5214, Validation Accuracy = 0.3612\n",
      "Epoch 56/10000 took 3.2175 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Training Loss = 2.3156, Validation Loss = 2.5218, Validation Accuracy = 0.3634\n",
      "Epoch 57/10000 took 3.2181 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Training Loss = 2.3241, Validation Loss = 2.5161, Validation Accuracy = 0.3634\n",
      "Epoch 58/10000 took 3.2187 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Training Loss = 2.3177, Validation Loss = 2.5197, Validation Accuracy = 0.3628\n",
      "Epoch 59/10000 took 3.2443 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Training Loss = 2.3081, Validation Loss = 2.5294, Validation Accuracy = 0.3596\n",
      "Epoch 60/10000 took 3.2264 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 1.5625e-05 Updated lr= 7.8125e-06\n",
      "Epoch 61: Training Loss = 2.3038, Validation Loss = 2.5246, Validation Accuracy = 0.3624\n",
      "Epoch 61/10000 took 3.2252 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: Training Loss = 2.2906, Validation Loss = 2.5194, Validation Accuracy = 0.3666\n",
      "Epoch 62/10000 took 3.2430 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: Training Loss = 2.3128, Validation Loss = 2.5058, Validation Accuracy = 0.3654\n",
      "Epoch 63/10000 took 3.2524 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: Training Loss = 2.2976, Validation Loss = 2.5126, Validation Accuracy = 0.3684\n",
      "Epoch 64/10000 took 3.2276 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: Training Loss = 2.3004, Validation Loss = 2.5141, Validation Accuracy = 0.3678\n",
      "Epoch 65/10000 took 3.2286 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 7.8125e-06 Updated lr= 3.90625e-06\n",
      "Epoch 66: Training Loss = 2.2916, Validation Loss = 2.5090, Validation Accuracy = 0.3680\n",
      "Epoch 66/10000 took 3.2271 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: Training Loss = 2.2767, Validation Loss = 2.5035, Validation Accuracy = 0.3660\n",
      "Epoch 67/10000 took 3.2229 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: Training Loss = 2.3021, Validation Loss = 2.5013, Validation Accuracy = 0.3692\n",
      "Epoch 68/10000 took 3.2232 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: Training Loss = 2.2806, Validation Loss = 2.5027, Validation Accuracy = 0.3684\n",
      "Epoch 69/10000 took 3.2263 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: Training Loss = 2.2866, Validation Loss = 2.5005, Validation Accuracy = 0.3688\n",
      "Epoch 70/10000 took 3.2238 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: Training Loss = 2.2851, Validation Loss = 2.4989, Validation Accuracy = 0.3658\n",
      "Epoch 71/10000 took 3.2257 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: Training Loss = 2.2905, Validation Loss = 2.4986, Validation Accuracy = 0.3656\n",
      "Epoch 72/10000 took 3.2223 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: Training Loss = 2.2860, Validation Loss = 2.5001, Validation Accuracy = 0.3672\n",
      "Epoch 73/10000 took 3.2261 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: Training Loss = 2.2881, Validation Loss = 2.5017, Validation Accuracy = 0.3650\n",
      "Epoch 74/10000 took 3.2302 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 3.90625e-06 Updated lr= 1.953125e-06\n",
      "Epoch 75: Training Loss = 2.2826, Validation Loss = 2.4989, Validation Accuracy = 0.3678\n",
      "Epoch 75/10000 took 3.2555 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: Training Loss = 2.2818, Validation Loss = 2.4969, Validation Accuracy = 0.3666\n",
      "Epoch 76/10000 took 3.2565 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: Training Loss = 2.2816, Validation Loss = 2.4990, Validation Accuracy = 0.3648\n",
      "Epoch 77/10000 took 3.2387 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: Training Loss = 2.2906, Validation Loss = 2.4986, Validation Accuracy = 0.3658\n",
      "Epoch 78/10000 took 3.2422 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79: Training Loss = 2.2782, Validation Loss = 2.4985, Validation Accuracy = 0.3642\n",
      "Epoch 79/10000 took 3.2288 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: Training Loss = 2.2831, Validation Loss = 2.4978, Validation Accuracy = 0.3658\n",
      "Epoch 80/10000 took 3.2262 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: Training Loss = 2.2689, Validation Loss = 2.4980, Validation Accuracy = 0.3666\n",
      "Epoch 81/10000 took 3.2257 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: Training Loss = 2.2847, Validation Loss = 2.4965, Validation Accuracy = 0.3652\n",
      "Epoch 82/10000 took 3.2258 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83: Training Loss = 2.2774, Validation Loss = 2.4953, Validation Accuracy = 0.3670\n",
      "Epoch 83/10000 took 3.2357 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84: Training Loss = 2.2774, Validation Loss = 2.4987, Validation Accuracy = 0.3686\n",
      "Epoch 84/10000 took 3.2308 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: Training Loss = 2.2637, Validation Loss = 2.4969, Validation Accuracy = 0.3694\n",
      "Epoch 85/10000 took 3.2237 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 1.953125e-06 Updated lr= 9.765625e-07\n",
      "Epoch 86: Training Loss = 2.2731, Validation Loss = 2.4985, Validation Accuracy = 0.3658\n",
      "Epoch 86/10000 took 3.2259 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: Training Loss = 2.2750, Validation Loss = 2.4960, Validation Accuracy = 0.3664\n",
      "Epoch 87/10000 took 3.2414 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: Training Loss = 2.2737, Validation Loss = 2.4964, Validation Accuracy = 0.3670\n",
      "Epoch 88/10000 took 3.2214 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: Training Loss = 2.2746, Validation Loss = 2.4960, Validation Accuracy = 0.3668\n",
      "Epoch 89/10000 took 3.2400 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Training Loss = 2.2881, Validation Loss = 2.4953, Validation Accuracy = 0.3664\n",
      "Epoch 90/10000 took 3.2520 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: Training Loss = 2.2849, Validation Loss = 2.4960, Validation Accuracy = 0.3650\n",
      "Epoch 91/10000 took 3.2300 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: Training Loss = 2.2603, Validation Loss = 2.4952, Validation Accuracy = 0.3664\n",
      "Epoch 92/10000 took 3.2202 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: Training Loss = 2.2688, Validation Loss = 2.4955, Validation Accuracy = 0.3654\n",
      "Epoch 93/10000 took 3.2300 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: Training Loss = 2.2768, Validation Loss = 2.4954, Validation Accuracy = 0.3662\n",
      "Epoch 94/10000 took 3.2229 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95: Training Loss = 2.2810, Validation Loss = 2.4951, Validation Accuracy = 0.3646\n",
      "Epoch 95/10000 took 3.2289 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96: Training Loss = 2.2734, Validation Loss = 2.4943, Validation Accuracy = 0.3660\n",
      "Epoch 96/10000 took 3.2239 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97: Training Loss = 2.2770, Validation Loss = 2.4960, Validation Accuracy = 0.3678\n",
      "Epoch 97/10000 took 3.2406 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98: Training Loss = 2.2863, Validation Loss = 2.4945, Validation Accuracy = 0.3648\n",
      "Epoch 98/10000 took 3.2249 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 9.765625e-07 Updated lr= 4.882813e-07\n",
      "Epoch 99: Training Loss = 2.2831, Validation Loss = 2.4950, Validation Accuracy = 0.3656\n",
      "Epoch 99/10000 took 3.2343 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Training Loss = 2.2720, Validation Loss = 2.4953, Validation Accuracy = 0.3664\n",
      "Epoch 100/10000 took 3.2193 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101: Training Loss = 2.2789, Validation Loss = 2.4942, Validation Accuracy = 0.3666\n",
      "Epoch 101/10000 took 3.2203 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102: Training Loss = 2.2769, Validation Loss = 2.4946, Validation Accuracy = 0.3658\n",
      "Epoch 102/10000 took 3.2288 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103: Training Loss = 2.2782, Validation Loss = 2.4953, Validation Accuracy = 0.3664\n",
      "Epoch 103/10000 took 3.2258 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 4.882813e-07 Updated lr= 2.4414064e-07\n",
      "Epoch 104: Training Loss = 2.2848, Validation Loss = 2.4950, Validation Accuracy = 0.3666\n",
      "Epoch 104/10000 took 3.2492 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105: Training Loss = 2.2772, Validation Loss = 2.4950, Validation Accuracy = 0.3656\n",
      "Epoch 105/10000 took 3.2259 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106: Training Loss = 2.2708, Validation Loss = 2.4955, Validation Accuracy = 0.3650\n",
      "Epoch 106/10000 took 3.2442 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107: Training Loss = 2.2654, Validation Loss = 2.4950, Validation Accuracy = 0.3664\n",
      "Epoch 107/10000 took 3.2307 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108: Training Loss = 2.2816, Validation Loss = 2.4947, Validation Accuracy = 0.3652\n",
      "Epoch 108/10000 took 3.2230 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109: Training Loss = 2.2753, Validation Loss = 2.4945, Validation Accuracy = 0.3654\n",
      "Epoch 109/10000 took 3.2328 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110: Training Loss = 2.2762, Validation Loss = 2.4945, Validation Accuracy = 0.3680\n",
      "Epoch 110/10000 took 3.2321 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111: Training Loss = 2.2695, Validation Loss = 2.4942, Validation Accuracy = 0.3674\n",
      "Epoch 111/10000 took 3.2250 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112: Training Loss = 2.2708, Validation Loss = 2.4940, Validation Accuracy = 0.3664\n",
      "Epoch 112/10000 took 3.2256 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113: Training Loss = 2.2853, Validation Loss = 2.4943, Validation Accuracy = 0.3670\n",
      "Epoch 113/10000 took 3.2275 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114: Training Loss = 2.2884, Validation Loss = 2.4944, Validation Accuracy = 0.3660\n",
      "Epoch 114/10000 took 3.2253 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115: Training Loss = 2.2744, Validation Loss = 2.4942, Validation Accuracy = 0.3664\n",
      "Epoch 115/10000 took 3.2416 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116: Training Loss = 2.2715, Validation Loss = 2.4944, Validation Accuracy = 0.3652\n",
      "Epoch 116/10000 took 3.2303 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117: Training Loss = 2.2748, Validation Loss = 2.4944, Validation Accuracy = 0.3652\n",
      "Epoch 117/10000 took 3.2296 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118: Training Loss = 2.2595, Validation Loss = 2.4937, Validation Accuracy = 0.3664\n",
      "Epoch 118/10000 took 3.2287 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: Training Loss = 2.2657, Validation Loss = 2.4940, Validation Accuracy = 0.3662\n",
      "Epoch 119/10000 took 3.2343 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120: Training Loss = 2.2744, Validation Loss = 2.4934, Validation Accuracy = 0.3652\n",
      "Epoch 120/10000 took 3.2341 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121: Training Loss = 2.2671, Validation Loss = 2.4941, Validation Accuracy = 0.3662\n",
      "Epoch 121/10000 took 3.2429 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122: Training Loss = 2.2732, Validation Loss = 2.4940, Validation Accuracy = 0.3654\n",
      "Epoch 122/10000 took 3.2273 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123: Training Loss = 2.2643, Validation Loss = 2.4940, Validation Accuracy = 0.3670\n",
      "Epoch 123/10000 took 3.2309 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124: Training Loss = 2.2803, Validation Loss = 2.4943, Validation Accuracy = 0.3664\n",
      "Epoch 124/10000 took 3.2176 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125: Training Loss = 2.2752, Validation Loss = 2.4942, Validation Accuracy = 0.3662\n",
      "Epoch 125/10000 took 3.2359 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126: Training Loss = 2.2773, Validation Loss = 2.4946, Validation Accuracy = 0.3668\n",
      "Epoch 126/10000 took 3.2318 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127: Training Loss = 2.2633, Validation Loss = 2.4937, Validation Accuracy = 0.3650\n",
      "Epoch 127/10000 took 3.2305 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128: Training Loss = 2.2684, Validation Loss = 2.4944, Validation Accuracy = 0.3654\n",
      "Epoch 128/10000 took 3.2141 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129: Training Loss = 2.2678, Validation Loss = 2.4945, Validation Accuracy = 0.3662\n",
      "Epoch 129/10000 took 3.2352 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130: Training Loss = 2.2693, Validation Loss = 2.4948, Validation Accuracy = 0.3670\n",
      "Epoch 130/10000 took 3.2401 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131: Training Loss = 2.2871, Validation Loss = 2.4948, Validation Accuracy = 0.3650\n",
      "Epoch 131/10000 took 3.2474 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132: Training Loss = 2.2738, Validation Loss = 2.4945, Validation Accuracy = 0.3666\n",
      "Epoch 132/10000 took 3.2417 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133: Training Loss = 2.2795, Validation Loss = 2.4944, Validation Accuracy = 0.3656\n",
      "Epoch 133/10000 took 3.2235 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134: Training Loss = 2.2715, Validation Loss = 2.4938, Validation Accuracy = 0.3654\n",
      "Early stopping triggered at epoch 134\n",
      "Finished training after 134 epochs!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.010016025975346565\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "x100_train, y100_train, x100_val, y100_val, x100_test, y100_test, classnames = get_dataset('cifar100')\n",
    "\n",
    "model = ResNet8(100, (32,32,3), reg = 1.5)\n",
    "model.compile(optimizer='adamw')\n",
    "model.fit(x100_train, y100_train, x100_val, y100_val, val_every = 1, verbose = True, patience=15, lr_patience=4)\n",
    "print(f\"Test acc: {model.evaluate(x_test, y_test)[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8b5f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 7e. Questions\n",
    "\n",
    "**Question 3:** Compare your ResNet-8 with Inception Net with respect to CIFAR-10 test accuracy, runtime (per epoch), and the train/val loss progression throughout training. \n",
    "\n",
    "**Question 4:** How did ResNet-8 do on at CIFAR-100 test set classification compared to Inception Net?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad97c0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Answer 3:**\n",
    "\n",
    "**Answer 4:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f329f6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 8: ResNet-18\n",
    "\n",
    "ResNet is an incredibly flexible/extensible neural network architecture. To get a better sense of this, let's build a deeper ResNet then train it on CIFAR-100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0d66",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 8a. Stacking multiple Residual Blocks together in sequence\n",
    "\n",
    "In ResNet-8, the spatial resolution/number of filters changed in every residual block. In deeper ResNets, this is not usually the case â€” there is a \"string\"/sequence of Residual Blocks with the SAME resolution and filter count stacked together after the change occurs.\n",
    "\n",
    "To streamline the process of stacking multiple Residual Blocks with the same hyperparameters together, write the `stack_residualblocks` function in `resnets.py`. This should save you lots of copy-pasting and/or typing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32a0bb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from resnets import stack_residualblocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2350e5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `stack_residualblocks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc561c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 blocks in the residual stack. There should be 1.\n",
      "There are 2 blocks in the residual stack. There should be 2.\n",
      "There are 3 blocks in the residual stack. There should be 3.\n",
      "There are 4 blocks in the residual stack. There should be 4.\n",
      "The strides in each block are: [1, 1, 1, 1]. They should be [1, 1, 1, 1]\n",
      "The strides in each block are: [2, 1, 1]. They should be [2, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    test_stack = stack_residualblocks('TestStack', 4, i+1, prev_layer_or_block=None, first_block_stride=1)\n",
    "    print(f'There are {len(test_stack)} blocks in the residual stack. There should be {i+1}.')\n",
    "\n",
    "strides_in_stack = [block.strides for block in test_stack]\n",
    "print(f'The strides in each block are: {strides_in_stack}. They should be [1, 1, 1, 1]')\n",
    "\n",
    "test_stack = stack_residualblocks('TestStack', 4, 3, prev_layer_or_block=None, first_block_stride=2)\n",
    "strides_in_stack = [block.strides for block in test_stack]\n",
    "print(f'The strides in each block are: {strides_in_stack}. They should be [2, 1, 1, 1]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8aef6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The blocks are:\n",
      "TestStack/block_1:\n",
      "\tConv2D layer output(TestStack/block_1/main_3x3conv_2) shape: None\n",
      "\tConv2D layer output(TestStack/block_1/main_3x3conv_1) shape: None\n",
      "\t-->Conv2D1x1 layer output(TestStack/block_1/skip_conv1x1) shape: None-->\n",
      "TestStack/block_2:\n",
      "\tConv2D layer output(TestStack/block_2/main_3x3conv_2) shape: None\n",
      "\tConv2D layer output(TestStack/block_2/main_3x3conv_1) shape: None\n",
      "TestStack/block_3:\n",
      "\tConv2D layer output(TestStack/block_3/main_3x3conv_2) shape: None\n",
      "\tConv2D layer output(TestStack/block_3/main_3x3conv_1) shape: None\n"
     ]
    }
   ],
   "source": [
    "print('The blocks are:')\n",
    "for block in test_stack:\n",
    "    print(block)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6494",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The above should print:\n",
    "\n",
    "```\n",
    "The blocks are:\n",
    "TestStack/block_1:\n",
    "\tConv2D layer output(TestStack/block_1/main_3x3conv_2) shape: None\n",
    "\tConv2D layer output(TestStack/block_1/main_3x3conv_1) shape: None\n",
    "\t-->Conv2D1x1 layer output(TestStack/block_1/skip_conv1x1) shape: None-->\n",
    "TestStack/block_2:\n",
    "\tConv2D layer output(TestStack/block_2/main_3x3conv_2) shape: None\n",
    "\tConv2D layer output(TestStack/block_2/main_3x3conv_1) shape: None\n",
    "TestStack/block_3:\n",
    "\tConv2D layer output(TestStack/block_3/main_3x3conv_2) shape: None\n",
    "\tConv2D layer output(TestStack/block_3/main_3x3conv_1) shape: None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b8c4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 8b. Build ResNet-18\n",
    "\n",
    "Implement the `ResNet18` class in `resnets.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "12aa87",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from resnets import ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2444eb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `ResNet18`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "19674f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output) shape: [1, 4]\n",
      "Global Avg Pooling 2D layer output(GlobalAveragePool2D) shape: [1, 512]\n",
      "stack_4/block_2:\n",
      "\tConv2D layer output(stack_4/block_2/main_3x3conv_2) shape: [1, 4, 4, 512]\n",
      "\tConv2D layer output(stack_4/block_2/main_3x3conv_1) shape: [1, 4, 4, 512]\n",
      "stack_4/block_1:\n",
      "\tConv2D layer output(stack_4/block_1/main_3x3conv_2) shape: [1, 4, 4, 512]\n",
      "\tConv2D layer output(stack_4/block_1/main_3x3conv_1) shape: [1, 4, 4, 512]\n",
      "\t-->Conv2D1x1 layer output(stack_4/block_1/skip_conv1x1) shape: [1, 4, 4, 512]-->\n",
      "stack_3/block_2:\n",
      "\tConv2D layer output(stack_3/block_2/main_3x3conv_2) shape: [1, 8, 8, 256]\n",
      "\tConv2D layer output(stack_3/block_2/main_3x3conv_1) shape: [1, 8, 8, 256]\n",
      "stack_3/block_1:\n",
      "\tConv2D layer output(stack_3/block_1/main_3x3conv_2) shape: [1, 8, 8, 256]\n",
      "\tConv2D layer output(stack_3/block_1/main_3x3conv_1) shape: [1, 8, 8, 256]\n",
      "\t-->Conv2D1x1 layer output(stack_3/block_1/skip_conv1x1) shape: [1, 8, 8, 256]-->\n",
      "stack_2/block_2:\n",
      "\tConv2D layer output(stack_2/block_2/main_3x3conv_2) shape: [1, 16, 16, 128]\n",
      "\tConv2D layer output(stack_2/block_2/main_3x3conv_1) shape: [1, 16, 16, 128]\n",
      "stack_2/block_1:\n",
      "\tConv2D layer output(stack_2/block_1/main_3x3conv_2) shape: [1, 16, 16, 128]\n",
      "\tConv2D layer output(stack_2/block_1/main_3x3conv_1) shape: [1, 16, 16, 128]\n",
      "\t-->Conv2D1x1 layer output(stack_2/block_1/skip_conv1x1) shape: [1, 16, 16, 128]-->\n",
      "stack_1/block_2:\n",
      "\tConv2D layer output(stack_1/block_2/main_3x3conv_2) shape: [1, 32, 32, 64]\n",
      "\tConv2D layer output(stack_1/block_2/main_3x3conv_1) shape: [1, 32, 32, 64]\n",
      "stack_1/block_1:\n",
      "\tConv2D layer output(stack_1/block_1/main_3x3conv_2) shape: [1, 32, 32, 64]\n",
      "\tConv2D layer output(stack_1/block_1/main_3x3conv_1) shape: [1, 32, 32, 64]\n",
      "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 64]\n"
     ]
    }
   ],
   "source": [
    "res18 = ResNet18(C=4, input_feats_shape=(32, 32, 3))\n",
    "res18.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da095",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The above cell should print:\n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "Dense layer output(Output) shape: [1, 4]\n",
    "Global Avg Pooling 2D layer output(GlobalAvgPool2D) shape: [1, 512]\n",
    "stack4/block_2:\n",
    "\tConv2D layer output(stack4/block_2/main_3x3conv_2) shape: [1, 4, 4, 512]\n",
    "\tConv2D layer output(stack4/block_2/main_3x3conv_1) shape: [1, 4, 4, 512]\n",
    "stack4/block_1:\n",
    "\tConv2D layer output(stack4/block_1/main_3x3conv_2) shape: [1, 4, 4, 512]\n",
    "\tConv2D layer output(stack4/block_1/main_3x3conv_1) shape: [1, 4, 4, 512]\n",
    "\t-->Conv2D1x1 layer output(stack4/block_1/skip_conv1x1) shape: [1, 4, 4, 512]-->\n",
    "stack3/block_2:\n",
    "\tConv2D layer output(stack3/block_2/main_3x3conv_2) shape: [1, 8, 8, 256]\n",
    "\tConv2D layer output(stack3/block_2/main_3x3conv_1) shape: [1, 8, 8, 256]\n",
    "stack3/block_1:\n",
    "\tConv2D layer output(stack3/block_1/main_3x3conv_2) shape: [1, 8, 8, 256]\n",
    "\tConv2D layer output(stack3/block_1/main_3x3conv_1) shape: [1, 8, 8, 256]\n",
    "\t-->Conv2D1x1 layer output(stack3/block_1/skip_conv1x1) shape: [1, 8, 8, 256]-->\n",
    "stack2/block_2:\n",
    "\tConv2D layer output(stack2/block_2/main_3x3conv_2) shape: [1, 16, 16, 128]\n",
    "\tConv2D layer output(stack2/block_2/main_3x3conv_1) shape: [1, 16, 16, 128]\n",
    "stack2/block_1:\n",
    "\tConv2D layer output(stack2/block_1/main_3x3conv_2) shape: [1, 16, 16, 128]\n",
    "\tConv2D layer output(stack2/block_1/main_3x3conv_1) shape: [1, 16, 16, 128]\n",
    "\t-->Conv2D1x1 layer output(stack2/block_1/skip_conv1x1) shape: [1, 16, 16, 128]-->\n",
    "stack1/block_2:\n",
    "\tConv2D layer output(stack1/block_2/main_3x3conv_2) shape: [1, 32, 32, 64]\n",
    "\tConv2D layer output(stack1/block_2/main_3x3conv_1) shape: [1, 32, 32, 64]\n",
    "stack1/block_1:\n",
    "\tConv2D layer output(stack1/block_1/main_3x3conv_2) shape: [1, 32, 32, 64]\n",
    "\tConv2D layer output(stack1/block_1/main_3x3conv_1) shape: [1, 32, 32, 64]\n",
    "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 64]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756e3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 8c. Overfit ResNet-18 on CIFAR-100 dev set\n",
    "\n",
    "Perform the usual overfitting protocol to test out your ResNet-18. However, this time use the 1st 500 samples of CIFAR-100 rather than CIFAR-10 to conduct the test.\n",
    "\n",
    "In the cell below, import CIFAR-100 and reproduce our usual overfit protocol:\n",
    "1. Create a dev set from the 1st 500 training CIFAR-100 samples.\n",
    "2. Train your net on the dev set for `80` epochs (turn off early stopping for this test). *Do not use any regularization.* \n",
    "\n",
    "Your training loss should start out at ~4.7 after the first epoch and rapidly plummet to 0.01 or less after about 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1efeba",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x100_train, y100_train, x100_val, y100_val, x100_test, y100_test, classnames100 = get_dataset('cifar10')\n",
    "x100_dev = x100_train[:500]\n",
    "y100_dev = y100_train[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bd66c9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output) shape: [1, 100]\n",
      "Global Avg Pooling 2D layer output(GlobalAveragePool2D) shape: [1, 512]\n",
      "stack_4/block_2:\n",
      "\tConv2D layer output(stack_4/block_2/main_3x3conv_2) shape: [1, 4, 4, 512]\n",
      "\tConv2D layer output(stack_4/block_2/main_3x3conv_1) shape: [1, 4, 4, 512]\n",
      "stack_4/block_1:\n",
      "\tConv2D layer output(stack_4/block_1/main_3x3conv_2) shape: [1, 4, 4, 512]\n",
      "\tConv2D layer output(stack_4/block_1/main_3x3conv_1) shape: [1, 4, 4, 512]\n",
      "\t-->Conv2D1x1 layer output(stack_4/block_1/skip_conv1x1) shape: [1, 4, 4, 512]-->\n",
      "stack_3/block_2:\n",
      "\tConv2D layer output(stack_3/block_2/main_3x3conv_2) shape: [1, 8, 8, 256]\n",
      "\tConv2D layer output(stack_3/block_2/main_3x3conv_1) shape: [1, 8, 8, 256]\n",
      "stack_3/block_1:\n",
      "\tConv2D layer output(stack_3/block_1/main_3x3conv_2) shape: [1, 8, 8, 256]\n",
      "\tConv2D layer output(stack_3/block_1/main_3x3conv_1) shape: [1, 8, 8, 256]\n",
      "\t-->Conv2D1x1 layer output(stack_3/block_1/skip_conv1x1) shape: [1, 8, 8, 256]-->\n",
      "stack_2/block_2:\n",
      "\tConv2D layer output(stack_2/block_2/main_3x3conv_2) shape: [1, 16, 16, 128]\n",
      "\tConv2D layer output(stack_2/block_2/main_3x3conv_1) shape: [1, 16, 16, 128]\n",
      "stack_2/block_1:\n",
      "\tConv2D layer output(stack_2/block_1/main_3x3conv_2) shape: [1, 16, 16, 128]\n",
      "\tConv2D layer output(stack_2/block_1/main_3x3conv_1) shape: [1, 16, 16, 128]\n",
      "\t-->Conv2D1x1 layer output(stack_2/block_1/skip_conv1x1) shape: [1, 16, 16, 128]-->\n",
      "stack_1/block_2:\n",
      "\tConv2D layer output(stack_1/block_2/main_3x3conv_2) shape: [1, 32, 32, 64]\n",
      "\tConv2D layer output(stack_1/block_2/main_3x3conv_1) shape: [1, 32, 32, 64]\n",
      "stack_1/block_1:\n",
      "\tConv2D layer output(stack_1/block_1/main_3x3conv_2) shape: [1, 32, 32, 64]\n",
      "\tConv2D layer output(stack_1/block_1/main_3x3conv_1) shape: [1, 32, 32, 64]\n",
      "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 64]\n",
      "Epoch 1: Training Loss = 9.0906, Validation Loss = 3.8579, Validation Accuracy = 0.0871\n",
      "Epoch 1/80 took 9.0898 seconds\n",
      "Epoch 2: Training Loss = 3.7235, Validation Loss = 3.5901, Validation Accuracy = 0.1027\n",
      "Epoch 2/80 took 1.5754 seconds\n",
      "Epoch 3: Training Loss = 3.4706, Validation Loss = 3.1984, Validation Accuracy = 0.0982\n",
      "Epoch 3/80 took 1.5739 seconds\n",
      "Epoch 4: Training Loss = 3.1564, Validation Loss = 2.9609, Validation Accuracy = 0.1004\n",
      "Epoch 4/80 took 1.5853 seconds\n",
      "Epoch 5: Training Loss = 2.8881, Validation Loss = 2.8187, Validation Accuracy = 0.1295\n",
      "Epoch 5/80 took 1.6205 seconds\n",
      "Epoch 6: Training Loss = 2.7616, Validation Loss = 2.6249, Validation Accuracy = 0.1295\n",
      "Epoch 6/80 took 1.5701 seconds\n",
      "Epoch 7: Training Loss = 2.5382, Validation Loss = 2.4004, Validation Accuracy = 0.1071\n",
      "Epoch 7/80 took 1.6267 seconds\n",
      "Epoch 8: Training Loss = 2.3497, Validation Loss = 2.3910, Validation Accuracy = 0.1183\n",
      "Epoch 8/80 took 1.5436 seconds\n",
      "Epoch 9: Training Loss = 2.3408, Validation Loss = 2.3275, Validation Accuracy = 0.1295\n",
      "Epoch 9/80 took 1.6557 seconds\n",
      "Epoch 10: Training Loss = 2.2965, Validation Loss = 2.3634, Validation Accuracy = 0.1295\n",
      "Epoch 10/80 took 1.4988 seconds\n",
      "Epoch 11: Training Loss = 2.3274, Validation Loss = 2.3223, Validation Accuracy = 0.1295\n",
      "Epoch 11/80 took 1.6202 seconds\n",
      "Epoch 12: Training Loss = 2.3135, Validation Loss = 2.2946, Validation Accuracy = 0.1451\n",
      "Epoch 12/80 took 1.5496 seconds\n",
      "Epoch 13: Training Loss = 2.2856, Validation Loss = 2.2889, Validation Accuracy = 0.1696\n",
      "Epoch 13/80 took 1.5610 seconds\n",
      "Epoch 14: Training Loss = 2.2746, Validation Loss = 2.2688, Validation Accuracy = 0.1295\n",
      "Epoch 14/80 took 1.5797 seconds\n",
      "Epoch 15: Training Loss = 2.2715, Validation Loss = 2.2145, Validation Accuracy = 0.1674\n",
      "Epoch 15/80 took 1.6375 seconds\n",
      "Epoch 16: Training Loss = 2.1923, Validation Loss = 2.1936, Validation Accuracy = 0.1540\n",
      "Epoch 16/80 took 1.5287 seconds\n",
      "Epoch 17: Training Loss = 2.1550, Validation Loss = 2.0753, Validation Accuracy = 0.2076\n",
      "Epoch 17/80 took 1.6237 seconds\n",
      "Epoch 18: Training Loss = 2.1270, Validation Loss = 2.1298, Validation Accuracy = 0.1897\n",
      "Epoch 18/80 took 1.5996 seconds\n",
      "Epoch 19: Training Loss = 2.1231, Validation Loss = 2.0640, Validation Accuracy = 0.2344\n",
      "Epoch 19/80 took 1.5322 seconds\n",
      "Epoch 20: Training Loss = 2.0798, Validation Loss = 2.0630, Validation Accuracy = 0.2031\n",
      "Epoch 20/80 took 1.5813 seconds\n",
      "Epoch 21: Training Loss = 2.0611, Validation Loss = 2.0127, Validation Accuracy = 0.2366\n",
      "Epoch 21/80 took 1.5337 seconds\n",
      "Epoch 22: Training Loss = 1.9823, Validation Loss = 1.9926, Validation Accuracy = 0.2478\n",
      "Epoch 22/80 took 1.5717 seconds\n",
      "Epoch 23: Training Loss = 1.9691, Validation Loss = 2.0598, Validation Accuracy = 0.2545\n",
      "Epoch 23/80 took 1.6144 seconds\n",
      "Epoch 24: Training Loss = 1.9480, Validation Loss = 1.9445, Validation Accuracy = 0.2656\n",
      "Epoch 24/80 took 1.5252 seconds\n",
      "Epoch 25: Training Loss = 1.9123, Validation Loss = 1.8542, Validation Accuracy = 0.2656\n",
      "Epoch 25/80 took 1.5903 seconds\n",
      "Epoch 26: Training Loss = 1.8219, Validation Loss = 1.8207, Validation Accuracy = 0.3058\n",
      "Epoch 26/80 took 1.4932 seconds\n",
      "Epoch 27: Training Loss = 1.9092, Validation Loss = 1.8427, Validation Accuracy = 0.2746\n",
      "Epoch 27/80 took 1.5983 seconds\n",
      "Epoch 28: Training Loss = 1.8851, Validation Loss = 1.8309, Validation Accuracy = 0.3013\n",
      "Epoch 28/80 took 1.4986 seconds\n",
      "Epoch 29: Training Loss = 1.7660, Validation Loss = 1.8025, Validation Accuracy = 0.3170\n",
      "Epoch 29/80 took 1.5861 seconds\n",
      "Epoch 30: Training Loss = 1.7674, Validation Loss = 1.7361, Validation Accuracy = 0.3348\n",
      "Epoch 30/80 took 1.5543 seconds\n",
      "Epoch 31: Training Loss = 1.6691, Validation Loss = 1.6058, Validation Accuracy = 0.3750\n",
      "Epoch 31/80 took 1.6477 seconds\n",
      "Epoch 32: Training Loss = 1.5586, Validation Loss = 1.6112, Validation Accuracy = 0.3661\n",
      "Epoch 32/80 took 1.6026 seconds\n",
      "Epoch 33: Training Loss = 1.5413, Validation Loss = 1.4437, Validation Accuracy = 0.4464\n",
      "Epoch 33/80 took 1.6348 seconds\n",
      "Epoch 34: Training Loss = 1.4325, Validation Loss = 1.5782, Validation Accuracy = 0.3951\n",
      "Epoch 34/80 took 1.5854 seconds\n",
      "Epoch 35: Training Loss = 1.4775, Validation Loss = 1.4786, Validation Accuracy = 0.4598\n",
      "Epoch 35/80 took 1.5891 seconds\n",
      "Epoch 36: Training Loss = 1.5018, Validation Loss = 1.4038, Validation Accuracy = 0.4576\n",
      "Epoch 36/80 took 1.5786 seconds\n",
      "Epoch 37: Training Loss = 1.3097, Validation Loss = 1.2317, Validation Accuracy = 0.5312\n",
      "Epoch 37/80 took 1.6067 seconds\n",
      "Epoch 38: Training Loss = 1.1934, Validation Loss = 1.1185, Validation Accuracy = 0.5781\n",
      "Epoch 38/80 took 1.5550 seconds\n",
      "Epoch 39: Training Loss = 1.1151, Validation Loss = 1.0065, Validation Accuracy = 0.6116\n",
      "Epoch 39/80 took 1.6181 seconds\n",
      "Epoch 40: Training Loss = 0.8963, Validation Loss = 0.8236, Validation Accuracy = 0.6763\n",
      "Epoch 40/80 took 1.5466 seconds\n",
      "Epoch 41: Training Loss = 0.7793, Validation Loss = 0.8000, Validation Accuracy = 0.7121\n",
      "Epoch 41/80 took 1.6076 seconds\n",
      "Epoch 42: Training Loss = 0.8227, Validation Loss = 0.6060, Validation Accuracy = 0.7701\n",
      "Epoch 42/80 took 1.5537 seconds\n",
      "Epoch 43: Training Loss = 0.5462, Validation Loss = 0.6290, Validation Accuracy = 0.7835\n",
      "Epoch 43/80 took 1.5992 seconds\n",
      "Epoch 44: Training Loss = 0.5877, Validation Loss = 0.5264, Validation Accuracy = 0.7946\n",
      "Epoch 44/80 took 1.5439 seconds\n",
      "Epoch 45: Training Loss = 0.4838, Validation Loss = 0.4092, Validation Accuracy = 0.8683\n",
      "Epoch 45/80 took 1.6133 seconds\n",
      "Epoch 46: Training Loss = 0.5349, Validation Loss = 0.7420, Validation Accuracy = 0.7411\n",
      "Epoch 46/80 took 1.5711 seconds\n",
      "Epoch 47: Training Loss = 0.5986, Validation Loss = 0.4343, Validation Accuracy = 0.8371\n",
      "Epoch 47/80 took 1.5636 seconds\n",
      "Epoch 48: Training Loss = 0.4322, Validation Loss = 0.4050, Validation Accuracy = 0.8438\n",
      "Epoch 48/80 took 1.5432 seconds\n",
      "Epoch 49: Training Loss = 0.3610, Validation Loss = 0.2370, Validation Accuracy = 0.9107\n",
      "Epoch 49/80 took 1.5706 seconds\n",
      "Epoch 50: Training Loss = 0.2035, Validation Loss = 0.1665, Validation Accuracy = 0.9442\n",
      "Epoch 50/80 took 1.5544 seconds\n",
      "Epoch 51: Training Loss = 0.2106, Validation Loss = 0.1544, Validation Accuracy = 0.9442\n",
      "Epoch 51/80 took 1.5716 seconds\n",
      "Epoch 52: Training Loss = 0.1216, Validation Loss = 0.1234, Validation Accuracy = 0.9665\n",
      "Epoch 52/80 took 1.5500 seconds\n",
      "Epoch 53: Training Loss = 0.1438, Validation Loss = 0.0767, Validation Accuracy = 0.9777\n",
      "Epoch 53/80 took 1.5784 seconds\n",
      "Epoch 54: Training Loss = 0.0615, Validation Loss = 0.0820, Validation Accuracy = 0.9777\n",
      "Epoch 54/80 took 1.5608 seconds\n",
      "Epoch 55: Training Loss = 0.0973, Validation Loss = 0.0639, Validation Accuracy = 0.9844\n",
      "Epoch 55/80 took 1.6288 seconds\n",
      "Epoch 56: Training Loss = 0.1240, Validation Loss = 0.0702, Validation Accuracy = 0.9732\n",
      "Epoch 56/80 took 1.5558 seconds\n",
      "Epoch 57: Training Loss = 0.1320, Validation Loss = 0.3071, Validation Accuracy = 0.9196\n",
      "Epoch 57/80 took 1.5197 seconds\n",
      "Epoch 58: Training Loss = 0.1948, Validation Loss = 0.0660, Validation Accuracy = 0.9821\n",
      "Epoch 58/80 took 1.5157 seconds\n",
      "Epoch 59: Training Loss = 0.0825, Validation Loss = 0.0746, Validation Accuracy = 0.9754\n",
      "Epoch 59/80 took 1.6356 seconds\n",
      "Epoch 60: Training Loss = 0.0573, Validation Loss = 0.0447, Validation Accuracy = 0.9844\n",
      "Epoch 60/80 took 1.5065 seconds\n",
      "Epoch 61: Training Loss = 0.0451, Validation Loss = 0.0630, Validation Accuracy = 0.9799\n",
      "Epoch 61/80 took 1.6423 seconds\n",
      "Epoch 62: Training Loss = 0.0588, Validation Loss = 0.0601, Validation Accuracy = 0.9799\n",
      "Epoch 62/80 took 1.6125 seconds\n",
      "Epoch 63: Training Loss = 0.0365, Validation Loss = 0.0765, Validation Accuracy = 0.9665\n",
      "Epoch 63/80 took 1.5905 seconds\n",
      "Epoch 64: Training Loss = 0.0337, Validation Loss = 0.0490, Validation Accuracy = 0.9799\n",
      "Epoch 64/80 took 1.4999 seconds\n",
      "Epoch 65: Training Loss = 0.0491, Validation Loss = 0.0921, Validation Accuracy = 0.9710\n",
      "Epoch 65/80 took 1.6121 seconds\n",
      "Epoch 66: Training Loss = 0.0388, Validation Loss = 0.0696, Validation Accuracy = 0.9688\n",
      "Epoch 66/80 took 1.5393 seconds\n",
      "Epoch 67: Training Loss = 0.0759, Validation Loss = 0.1177, Validation Accuracy = 0.9665\n",
      "Epoch 67/80 took 1.5900 seconds\n",
      "Epoch 68: Training Loss = 0.2050, Validation Loss = 0.0504, Validation Accuracy = 0.9844\n",
      "Epoch 68/80 took 1.5346 seconds\n",
      "Epoch 69: Training Loss = 0.1678, Validation Loss = 0.2774, Validation Accuracy = 0.8839\n",
      "Epoch 69/80 took 1.5528 seconds\n",
      "Epoch 70: Training Loss = 0.1664, Validation Loss = 0.2225, Validation Accuracy = 0.9129\n",
      "Epoch 70/80 took 1.5617 seconds\n",
      "Epoch 71: Training Loss = 0.1399, Validation Loss = 0.0695, Validation Accuracy = 0.9777\n",
      "Epoch 71/80 took 1.5444 seconds\n",
      "Epoch 72: Training Loss = 0.0813, Validation Loss = 0.0407, Validation Accuracy = 0.9866\n",
      "Epoch 72/80 took 1.5647 seconds\n",
      "Epoch 73: Training Loss = 0.0463, Validation Loss = 0.0193, Validation Accuracy = 1.0000\n",
      "Epoch 73/80 took 1.5780 seconds\n",
      "Epoch 74: Training Loss = 0.0209, Validation Loss = 0.0325, Validation Accuracy = 0.9911\n",
      "Epoch 74/80 took 1.5823 seconds\n",
      "Epoch 75: Training Loss = 0.0215, Validation Loss = 0.0150, Validation Accuracy = 0.9978\n",
      "Epoch 75/80 took 1.6034 seconds\n",
      "Epoch 76: Training Loss = 0.0081, Validation Loss = 0.0383, Validation Accuracy = 0.9933\n",
      "Epoch 76/80 took 1.5265 seconds\n",
      "Epoch 77: Training Loss = 0.0299, Validation Loss = 0.0491, Validation Accuracy = 0.9799\n",
      "Epoch 77/80 took 1.5985 seconds\n",
      "Epoch 78: Training Loss = 0.0301, Validation Loss = 0.0088, Validation Accuracy = 1.0000\n",
      "Epoch 78/80 took 1.5460 seconds\n",
      "Epoch 79: Training Loss = 0.0128, Validation Loss = 0.0080, Validation Accuracy = 1.0000\n",
      "Epoch 79/80 took 1.5470 seconds\n",
      "Epoch 80: Training Loss = 0.0114, Validation Loss = 0.0135, Validation Accuracy = 0.9955\n",
      "Epoch 80/80 took 1.5787 seconds\n",
      "Finished training after 80 epochs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([9.090593,\n",
       "  3.7235336,\n",
       "  3.4705682,\n",
       "  3.1563995,\n",
       "  2.8880653,\n",
       "  2.7615976,\n",
       "  2.5381956,\n",
       "  2.3496616,\n",
       "  2.3408196,\n",
       "  2.2965195,\n",
       "  2.327388,\n",
       "  2.3135433,\n",
       "  2.28564,\n",
       "  2.2746449,\n",
       "  2.2715006,\n",
       "  2.192308,\n",
       "  2.155007,\n",
       "  2.126965,\n",
       "  2.1231234,\n",
       "  2.0798275,\n",
       "  2.0611181,\n",
       "  1.9823172,\n",
       "  1.9691477,\n",
       "  1.9479959,\n",
       "  1.9123169,\n",
       "  1.821917,\n",
       "  1.9092288,\n",
       "  1.885099,\n",
       "  1.7659696,\n",
       "  1.767422,\n",
       "  1.6690844,\n",
       "  1.5585985,\n",
       "  1.5412904,\n",
       "  1.432499,\n",
       "  1.4774876,\n",
       "  1.5017985,\n",
       "  1.3096576,\n",
       "  1.1933943,\n",
       "  1.1150746,\n",
       "  0.8963085,\n",
       "  0.7793431,\n",
       "  0.82272464,\n",
       "  0.5462443,\n",
       "  0.58766615,\n",
       "  0.48381257,\n",
       "  0.5348976,\n",
       "  0.59862524,\n",
       "  0.43222013,\n",
       "  0.36099023,\n",
       "  0.20350632,\n",
       "  0.2105668,\n",
       "  0.121621594,\n",
       "  0.1438151,\n",
       "  0.06145041,\n",
       "  0.09728874,\n",
       "  0.124000885,\n",
       "  0.13201112,\n",
       "  0.19484606,\n",
       "  0.082511134,\n",
       "  0.057344172,\n",
       "  0.045132745,\n",
       "  0.058786523,\n",
       "  0.03651157,\n",
       "  0.033744987,\n",
       "  0.049093366,\n",
       "  0.03879678,\n",
       "  0.07588796,\n",
       "  0.20495546,\n",
       "  0.16777228,\n",
       "  0.16636345,\n",
       "  0.1398708,\n",
       "  0.08132751,\n",
       "  0.04630975,\n",
       "  0.020889256,\n",
       "  0.021530168,\n",
       "  0.008075427,\n",
       "  0.029873848,\n",
       "  0.030116238,\n",
       "  0.012826571,\n",
       "  0.011374269],\n",
       " [3.8578799,\n",
       "  3.590103,\n",
       "  3.1984172,\n",
       "  2.9608753,\n",
       "  2.8187146,\n",
       "  2.6249294,\n",
       "  2.4004076,\n",
       "  2.3909786,\n",
       "  2.3274562,\n",
       "  2.3634403,\n",
       "  2.322313,\n",
       "  2.2946167,\n",
       "  2.288857,\n",
       "  2.2688305,\n",
       "  2.2145374,\n",
       "  2.193616,\n",
       "  2.0752661,\n",
       "  2.129751,\n",
       "  2.0639834,\n",
       "  2.0630126,\n",
       "  2.0127206,\n",
       "  1.9926218,\n",
       "  2.0597653,\n",
       "  1.9445277,\n",
       "  1.8541977,\n",
       "  1.8206915,\n",
       "  1.8426822,\n",
       "  1.8309059,\n",
       "  1.8025104,\n",
       "  1.7360771,\n",
       "  1.6057869,\n",
       "  1.6112124,\n",
       "  1.4436973,\n",
       "  1.5782119,\n",
       "  1.4786328,\n",
       "  1.403753,\n",
       "  1.2317208,\n",
       "  1.1185434,\n",
       "  1.0064561,\n",
       "  0.82364076,\n",
       "  0.8000081,\n",
       "  0.6060042,\n",
       "  0.6290162,\n",
       "  0.5264344,\n",
       "  0.40922454,\n",
       "  0.74197036,\n",
       "  0.43429285,\n",
       "  0.40498453,\n",
       "  0.23702037,\n",
       "  0.16646494,\n",
       "  0.15442912,\n",
       "  0.123417005,\n",
       "  0.07672153,\n",
       "  0.08199791,\n",
       "  0.06388293,\n",
       "  0.07018997,\n",
       "  0.30707422,\n",
       "  0.06602429,\n",
       "  0.074621506,\n",
       "  0.044694923,\n",
       "  0.06299512,\n",
       "  0.06006229,\n",
       "  0.07649614,\n",
       "  0.049036074,\n",
       "  0.09208037,\n",
       "  0.069605,\n",
       "  0.11771839,\n",
       "  0.050417095,\n",
       "  0.27738184,\n",
       "  0.22251418,\n",
       "  0.06950655,\n",
       "  0.040719073,\n",
       "  0.019342331,\n",
       "  0.03253175,\n",
       "  0.015038962,\n",
       "  0.03829192,\n",
       "  0.04913766,\n",
       "  0.008842675,\n",
       "  0.007968644,\n",
       "  0.013451108],\n",
       " [0.087053575,\n",
       "  0.102678575,\n",
       "  0.09821428,\n",
       "  0.100446425,\n",
       "  0.12946428,\n",
       "  0.12946428,\n",
       "  0.10714286,\n",
       "  0.118303575,\n",
       "  0.12946428,\n",
       "  0.12946428,\n",
       "  0.12946428,\n",
       "  0.14508928,\n",
       "  0.16964285,\n",
       "  0.12946428,\n",
       "  0.16741072,\n",
       "  0.15401785,\n",
       "  0.20758928,\n",
       "  0.18973215,\n",
       "  0.234375,\n",
       "  0.203125,\n",
       "  0.23660715,\n",
       "  0.24776785,\n",
       "  0.2544643,\n",
       "  0.265625,\n",
       "  0.265625,\n",
       "  0.30580357,\n",
       "  0.27455357,\n",
       "  0.3013393,\n",
       "  0.3169643,\n",
       "  0.33482143,\n",
       "  0.375,\n",
       "  0.36607143,\n",
       "  0.44642857,\n",
       "  0.3950893,\n",
       "  0.45982143,\n",
       "  0.4575893,\n",
       "  0.53125,\n",
       "  0.578125,\n",
       "  0.61160713,\n",
       "  0.67633927,\n",
       "  0.7120536,\n",
       "  0.77008927,\n",
       "  0.78348213,\n",
       "  0.79464287,\n",
       "  0.8683036,\n",
       "  0.7410714,\n",
       "  0.8370536,\n",
       "  0.84375,\n",
       "  0.91071427,\n",
       "  0.9441964,\n",
       "  0.9441964,\n",
       "  0.96651787,\n",
       "  0.9776786,\n",
       "  0.9776786,\n",
       "  0.984375,\n",
       "  0.97321427,\n",
       "  0.91964287,\n",
       "  0.98214287,\n",
       "  0.9754464,\n",
       "  0.984375,\n",
       "  0.97991073,\n",
       "  0.97991073,\n",
       "  0.96651787,\n",
       "  0.97991073,\n",
       "  0.97098213,\n",
       "  0.96875,\n",
       "  0.96651787,\n",
       "  0.984375,\n",
       "  0.8839286,\n",
       "  0.9129464,\n",
       "  0.9776786,\n",
       "  0.98660713,\n",
       "  1.0,\n",
       "  0.9910714,\n",
       "  0.99776787,\n",
       "  0.9933036,\n",
       "  0.97991073,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.99553573],\n",
       " 80)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model = ResNet18(100, (32,32,3), reg = 0)\n",
    "model.compile(optimizer='adamw')\n",
    "model.fit(x100_dev, y100_dev, x100_dev, y100_dev, max_epochs = 80, val_every = 1, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4733a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 8d. Train ResNet-18 on CIFAR-100\n",
    "\n",
    "In the cell below, train your ResNet-18 on CIFAR-100. Print out the test set after training concludes.\n",
    "\n",
    "Use regularization strength of `1.5`, a patience of `15`, learning rate patience of `4`, and keep the rest of the hyperparameters to their defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "02bb64",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "model = ResNet18(100, (32,32,3), reg = 0)\n",
    "model.compile(optimizer='adamw')\n",
    "model.fit(x100_train, y100_train, x100_val, y100_val, max_epochs = 80, val_every = 1, verbose = True)\n",
    "print(f\"Test acc: {model.evaluate(x_test, y_test)[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09f13",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 8e. Visualize the predictions made by ResNet-18 on the CIFAR-100 test set.\n",
    "\n",
    "In the cell below, use your trained ResNet-18 to get the predicted classes of thr 1st 225 test set images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "519f31",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae12fe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Run the code below to create a 15x15 grid of CIFAR-100 images with the true and predicted classes in the title. The predicted classes are color-coded  blue if they are correct, red if they are incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "d31257",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_,_,_,_, x100_test_vis, y100_test_vis, classnames = get_dataset('cifar100', standardize_ds=False)\n",
    "\n",
    "panel_sz = 4\n",
    "grid = 15\n",
    "fig, axes, = plt.subplots(nrows=grid, ncols=grid, figsize=(grid*panel_sz, grid*panel_sz))\n",
    "\n",
    "for r in range(grid):\n",
    "    for c in range(grid):\n",
    "        ind = grid*r + c\n",
    "        axes[r,c].imshow(x100_test_vis[ind])\n",
    "        axes[r,c].set_xticks([])\n",
    "        axes[r,c].set_yticks([])\n",
    "        title = f'{classnames[y100_test[ind]]}\\nPredicted: '\n",
    "        title += f'{classnames[y_pred[ind]]}'\n",
    "\n",
    "        color = 'blue'\n",
    "        if y100_test[ind] != y_pred[ind]:\n",
    "            color = 'red'\n",
    "\n",
    "        axes[r,c].set_title(title, color=color)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52896a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 8f. Questions\n",
    "\n",
    "**Question 5:** Take a look at the above montage. Does the mistakes made by ResNet-18 seem reasonable? Provide some specific examples to support your conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5d3c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Answer 5:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35002",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Extensions\n",
    "\n",
    "### General guidelines\n",
    "\n",
    "1. Never integrate extensions into your base project so that they change the expected behavior of core functions. If your extension changes the core design/behavior, no problem, duplicate your working base project and add features from there.\n",
    "2. Check the rubric to keep in mind how extensions on this project will be graded.\n",
    "3. While I may consult your code and \"written log\" of what you did, **I am grading your extensions based on what you present in your 3-5 min video.**\n",
    "3. I suggest documenting your explorations in a \"log\" or \"lab notebook\" style (i.e. documenting your thought/progression/discovery/learning process). I'm not grading your writing, so you can keep it succinct. **Whatever is most useful to you to remember what you did.** \n",
    "4. I suggest taking a hypothesis driven approach. For example \"I was curious about X so I explored Y. I found Z, which was not what I expected because..., so then tried A...\"\n",
    "5. Make plots to help showcase your results.\n",
    "6. **More is not necessarily better.** Generally, a small number of \"in-depth\" extensions count for more than many \"shallow\" extensions.\n",
    "\n",
    "### AI guidelines\n",
    "\n",
    "You may use AI in mostly any capacity for extensions. However, keep in mind:\n",
    "1. There is no need to use AI at all!\n",
    "2. You are welcome to use AI as a tool (e.g. automate something that is tedious, help you get unstuck, etc.). However, you should be coding, you should be thinking, you should be writing, you should be creating. If you are spending most (or even close to most) of your time typing into a chatbot and copy-pasting, you have probably gone too far with AI use.\n",
    "3. I don't find large volumes of AI generated code/text/plots to be particularly impressive and you risk losing my interest while grading. Remember: I'm grading your extensions based on your video presentation. **More is not necessarily better.**\n",
    "\n",
    "### Video guidelines\n",
    "\n",
    "1. Please try to keep your video to 5 minutes (*I have other projects to grade!*). If you turn in a longer video, I make no promise that I will watch more than 5 minutes.\n",
    "2. Your screen should be shared as you show me what you did. A live video of your face should also appear somewhere on the screen (e.g. picture-in-picture overlay / split screen).\n",
    "3. Your partner should join you for the video and take turns talking, but, if necessary, it is fine to have one team member present during the record the video.\n",
    "4. Do not simply read text from your notebook, do not read from a prepared script. I am not grading how polished your video presentation is (see extension grading criteria on rubric). \n",
    "5. I am looking for original and creative explorations sparked by your curiosity/interest/passion in a topic. This should be apparent in your video.\n",
    "6. Be natural,, don't feel the need to impress me with fancy language. If it is helpful, imagine that we are talking one-on-one about your extension. Tell me what you did :)\n",
    "\n",
    "### Extension ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5341",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1. ResNet-34\n",
    "\n",
    "Create and train the well-known network of the ResNet family called ResNet-34. Here is a suggested network configuration to experiment with:\n",
    "\n",
    "```\n",
    "block_units = [64, 128, 256, 512]\n",
    "num_blocks = [3, 4, 6, 3]\n",
    "first_block_strides = [1, 2, 2, 2]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764354",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2. ResNet-50\n",
    "\n",
    "Create and train the well-known network of the ResNet family called ResNet-50. Given its depth, it uses a \"Bottleneck block\" rather than a normal Residual Block, but the overall structure is very similar. Here is a suggested network configuration to experiment with:\n",
    "\n",
    "```\n",
    "block_units = [64, 128, 256, 512]\n",
    "num_blocks = [3, 4, 6, 3]\n",
    "first_block_strides = [1, 2, 2, 2]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc0b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 3. VGG networks on CIFAR-100\n",
    "\n",
    "How does one or more of your VGG networks do at classifying images in CIFAR-100?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de648",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 4. Other ResNets on CIFAR-10\n",
    "\n",
    "How do the other ResNets do at classifying images in CIFAR-10?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc06f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 5. Multi-network comparison\n",
    "\n",
    "Compare the accuracy, efficiency, etc of any number of networks from the VGG, Inception Net, and ResNet families."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bc08",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 6. Add support for saving/loading network weights\n",
    "\n",
    "A key limitation of your current deep learning library is that parameters that capture the learning in networks are completely reset/lost/wiped out when the notebook kernel is terminated. Add (and test!) support for saving network parameters to disk after (or periodically during) training. Add (and test!) support for loading network parameters back into the network from disk before training. \n",
    "\n",
    "Be careful to include the moving mean and standard deviation parameters in batch normalization layers otherwise the whole net will not work!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216e3a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 7. Other image datasets\n",
    "\n",
    "Apply any of the three deep network families to another dataset of your choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1707f2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 8. Hyperparameter tuning\n",
    "\n",
    "Try and find hyperparameters that allow Inception Net and the ResNets to achieve better accuracy on CIFAR-10 and/or CIFAR-100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704954",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 9. Build other Inception Nets\n",
    "\n",
    "We only built a single network, but just like VGG and ResNet, you can modify the network depth while following the computational motifs of the Inception Net architecture. Design and experiment with your own Inception Net!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0ede",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 10. Analyze errors made by one or more of the nets\n",
    "\n",
    "Make a confusion matrix for CIFAR-10 or CIFAR-100 (*a challenge to make it useful!*).\n",
    "\n",
    "Visualize the predictions made by Inception Net and/or a VGG net, perhaps similar what was done with the ResNet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel",
    "--HistoryManager.enabled=False",
    "--matplotlib=inline",
    "-c",
    "%config InlineBackend.figure_formats = set(['retina'])\nimport matplotlib; matplotlib.rcParams['figure.figsize'] = (12, 7)",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (system-wide)",
   "env": {},
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
