{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trey Tuscai and Gordon Doore\n",
    "\n",
    "Spring 2025\n",
    "\n",
    "CS 444: Deep Learning\n",
    "\n",
    "Project 2: Branch Neural Networks\n",
    "\n",
    "#### Week 2: Residual networks\n",
    "\n",
    "The focus this week is on the ResNet architecture. You will build several neural networks in the ResNet family and and train them on CIFAR-10 and CIFAR-100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=7)\n",
    "\n",
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: The Residual Block\n",
    "\n",
    "This task focuses on implementing and testing the **Residual Block** in preparation of creating the first ResNet (**ResNet-8**). \n",
    "\n",
    "Much like how Inception Blocks represent the building blocks of Inception Net, stacks of Residual Blocks represent the basis of ResNet. Residual Blocks possess a simpler structure than Inception Blocks — they only contain two parallel branches with fewer layers. Here is a refresher on the structure of the branches:\n",
    "\n",
    "**Main branch:** sequence of two 2D convolutional layers.\n",
    "\n",
    "**Residual branch:** the input signal to the Residual Block passes through \"as-is\", without modification (usually).\n",
    "\n",
    "Like Inception Block, the output of both branches comes together at the end of the block. However, the branch outputs are SUMMED together rather than being concatenated.\n",
    "\n",
    "\n",
    "This is the story for most Residual Blocks, however, like most CNNs:\n",
    "1. the spatial resolution of the activations occasionally decreases\n",
    "2. the number of conv filters/neurons increases\n",
    "\n",
    "as we go deeper in a ResNet. Both of these factors tend to change *at the same time* in a small number of Residual Blocks located at various depths of the ResNet. Put another way, the spatial resolution and number of filters tends to remain constant across most successive Residual Blocks and they only changes in a few blocks throughout the net.\n",
    "1. The decrease in spatial resolution is implemented in these small number of Residual Blocks with a convolutional stride > 1.\n",
    "2. A 1x1 convolutional layer is needed as the \"special sauce\" along the residual branch to make the shapes of signals in both branches match (*otherwise they could not be summed!*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a. Implement and test the Residual Block\n",
    "\n",
    "The class is in `residual_block.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from residual_block import ResidualBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: `ResidualBlock` Stride 1 (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestResidualBlock_S1:\n",
      "\tConv2D layer output(TestResidualBlock_S1/main_3x3conv_2) shape: [1, 4, 4, 7]\n",
      "\tConv2D layer output(TestResidualBlock_S1/main_3x3conv_1) shape: [1, 4, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "# Testing architecture and shapes\n",
    "# Stride 1\n",
    "tf.random.set_seed(0)\n",
    "res1 = ResidualBlock('TestResidualBlock_S1', 7, prev_layer_or_block=None, strides=1)\n",
    "res1(tf.ones([1, 4, 4, 7]))\n",
    "print(res1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell should print:\n",
    "\n",
    "```\n",
    "TestResidualBlock_S1:\n",
    "\tConv2D layer output(TestResidualBlock_S1/main_3x3conv_2) shape: [1, 4, 4, 7]\n",
    "\tConv2D layer output(TestResidualBlock_S1/main_3x3conv_1) shape: [1, 4, 4, 7]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the netAct output from the block is (2, 4, 4, 7) and should be (2, 4, 4, 7)\n",
      "The first few activations are:\n",
      "[[0.        0.5208229 0.1888617 0.       ]\n",
      " [0.        0.7621396 0.1734907 0.8486799]\n",
      " [0.        0.6156112 0.4272217 0.       ]\n",
      " [0.5561852 0.4888234 1.0138505 0.5533389]]\n",
      "and should be:\n",
      "[[0.        0.520823  0.1888617 0.       ]\n",
      " [0.        0.7621396 0.1734907 0.8486798]\n",
      " [0.        0.6156113 0.4272216 0.       ]\n",
      " [0.5561852 0.4888234 1.0138503 0.5533389]]\n"
     ]
    }
   ],
   "source": [
    "# Test activations\n",
    "tf.random.set_seed(0)\n",
    "net_acts1 = res1(tf.random.uniform([2, 4, 4, 7]))\n",
    "print(f'The shape of the netAct output from the block is {net_acts1.shape} and should be (2, 4, 4, 7)')\n",
    "print(f'The first few activations are:\\n{net_acts1[0,:,:, 0]}')\n",
    "print('and should be:')\n",
    "print('''[[0.        0.520823  0.1888617 0.       ]\n",
    " [0.        0.7621396 0.1734907 0.8486798]\n",
    " [0.        0.6156113 0.4272216 0.       ]\n",
    " [0.5561852 0.4888234 1.0138503 0.5533389]]''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: `ResidualBlock` Stride 2 (2/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestResidualBlock_S2:\n",
      "\tConv2D layer output(TestResidualBlock_S2/main_3x3conv_2) shape: [1, 3, 3, 5]\n",
      "\tConv2D layer output(TestResidualBlock_S2/main_3x3conv_1) shape: [1, 3, 3, 5]\n",
      "\t-->Conv2D1x1 layer output(TestResidualBlock_S2/skip_conv1x1) shape: [1, 3, 3, 5]-->\n"
     ]
    }
   ],
   "source": [
    "# Testing architecture and shapes\n",
    "# Stride 2\n",
    "tf.random.set_seed(0)\n",
    "res2 = ResidualBlock('TestResidualBlock_S2', 5, prev_layer_or_block=None, strides=2)\n",
    "res2(tf.ones([1, 6, 6, 5]))\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell should print:\n",
    "\n",
    "```\n",
    "TestResidualBlock_S2:\n",
    "\tConv2D layer output(TestResidualBlock_S2/main_3x3conv_2) shape: [1, 3, 3, 5]\n",
    "\tConv2D layer output(TestResidualBlock_S2/main_3x3conv_1) shape: [1, 3, 3, 5]\n",
    "\t-->Conv2D1x1 layer output(TestResidualBlock_S2/skip_conv1x1) shape: [1, 3, 3, 5]-->\n",
    "```\n",
    "\n",
    "*The layer with the --> is the residual branch.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the netAct output from the block is (2, 4, 4, 7) and should be (3, 3, 3, 5)\n",
      "The first few activations are:\n",
      "[[[0.2403671 0.        0.        0.2852962 0.       ]\n",
      "  [0.        0.        0.        0.1339119 0.6897169]\n",
      "  [0.        0.        0.        0.4595791 0.2781491]]\n",
      "\n",
      " [[0.        0.        0.        0.6591121 1.3700994]\n",
      "  [0.2664362 0.        0.        0.9615825 0.       ]\n",
      "  [0.        0.        0.        0.3844296 0.7109971]]\n",
      "\n",
      " [[0.0933685 0.        0.        0.1379156 0.3004903]\n",
      "  [0.1871759 0.        0.        0.4464865 1.1061924]\n",
      "  [0.        0.        0.        0.7911265 0.3450609]]]\n",
      "and should be:\n",
      "[[[0.2404823 0.        0.        0.2851936 0.       ]\n",
      "  [0.        0.        0.        0.1339086 0.6898913]\n",
      "  [0.        0.        0.        0.4596353 0.2781557]]\n",
      "\n",
      " [[0.        0.        0.        0.6591434 1.3703969]\n",
      "  [0.2665227 0.        0.        0.9614864 0.       ]\n",
      "  [0.        0.        0.        0.3844326 0.7111533]]\n",
      "\n",
      " [[0.0933782 0.        0.        0.1378801 0.3006183]\n",
      "  [0.1873689 0.        0.        0.4464224 1.1067129]\n",
      "  [0.        0.        0.        0.7910071 0.345379 ]]]\n"
     ]
    }
   ],
   "source": [
    "# Test activations\n",
    "tf.random.set_seed(0)\n",
    "net_acts2 = res2(tf.random.uniform([3, 6, 6, 5]))\n",
    "print(f'The shape of the netAct output from the block is {net_acts1.shape} and should be (3, 3, 3, 5)')\n",
    "print(f'The first few activations are:\\n{net_acts2[0,:,:, :]}')\n",
    "print('and should be:')\n",
    "print('''[[[0.2404823 0.        0.        0.2851936 0.       ]\n",
    "  [0.        0.        0.        0.1339086 0.6898913]\n",
    "  [0.        0.        0.        0.4596353 0.2781557]]\n",
    "\n",
    " [[0.        0.        0.        0.6591434 1.3703969]\n",
    "  [0.2665227 0.        0.        0.9614864 0.       ]\n",
    "  [0.        0.        0.        0.3844326 0.7111533]]\n",
    "\n",
    " [[0.0933782 0.        0.        0.1378801 0.3006183]\n",
    "  [0.1873689 0.        0.        0.4464224 1.1067129]\n",
    "  [0.        0.        0.        0.7910071 0.345379 ]]]''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: ResNet-8\n",
    "\n",
    "Assemble the Residual Blocks and several other layers to build ResNet-8:\n",
    "\n",
    "Conv2D → ResidualBlock → ResidualBlock → ResidualBlock → GlobalAveragePooling2D → Dense\n",
    "\n",
    "After an overfit test to help check whether the network is working, you will train the network on both CIFAR-10 and CIFAR-100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnets import ResNet8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7a. Build ResNet-8\n",
    "\n",
    "Implement the following classes in `resnets.py`:\n",
    "1. `ResNet`: Parent class of all specific ResNets (e.g. ResNet-8, ResNet-18, etc.). Having this class helps reduce code size/duplication because the forward pass thru all ResNets is exactly the same!\n",
    "2. `ResNet8`: Assemble the first (*and smallest*) net in the family!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: `ResNet8` architecture and shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res8 = ResNet8(C=3, input_feats_shape=(32, 32, 3))\n",
    "res8.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell should print:\n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "Dense layer output(Output) shape: [1, 3]\n",
    "Global Avg Pooling 2D layer output(GlobalAvgPool2D) shape: [1, 128]\n",
    "ResidualBlock_3:\n",
    "\tConv2D layer output(ResidualBlock_3/main_3x3conv_2) shape: [1, 8, 8, 128]\n",
    "\tConv2D layer output(ResidualBlock_3/main_3x3conv_1) shape: [1, 8, 8, 128]\n",
    "\t-->Conv2D1x1 layer output(ResidualBlock_3/skip_conv1x1) shape: [1, 8, 8, 128]-->\n",
    "ResidualBlock_2:\n",
    "\tConv2D layer output(ResidualBlock_2/main_3x3conv_2) shape: [1, 16, 16, 64]\n",
    "\tConv2D layer output(ResidualBlock_2/main_3x3conv_1) shape: [1, 16, 16, 64]\n",
    "\t-->Conv2D1x1 layer output(ResidualBlock_2/skip_conv1x1) shape: [1, 16, 16, 64]-->\n",
    "ResidualBlock_1:\n",
    "\tConv2D layer output(ResidualBlock_1/main_3x3conv_2) shape: [1, 32, 32, 32]\n",
    "\tConv2D layer output(ResidualBlock_1/main_3x3conv_1) shape: [1, 32, 32, 32]\n",
    "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 32]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7b. CIFAR-10 overfit test\n",
    "\n",
    "In the cell below, import CIFAR-10 and reproduce our usual overfit protocol:\n",
    "1. Create a dev set from the 1st 500 training CIFAR-10 samples.\n",
    "2. Train your net on the dev set for `80` epochs (turn off early stopping for this test). *Do not use any regularization.* \n",
    "\n",
    "Your training loss should start out at ~2.3 after the first epoch and rapidly plummet to 0.01 or less by about 70 epochs.\n",
    "\n",
    "**Note:** If you coded `fit` to assume there will always be a validation set present, no problem, just plug in the dev set for both the train and val sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7c. Train ResNet-8 on CIFAR-10\n",
    "\n",
    "Repeat our usual training and evaluation protocol:\n",
    "1. Train ResNet-8 on CIFAR-10. Use regularization strength of `1.5`, a patience of `15`, learning rate patience of `4`, and keep the rest of the hyperparameters to their defaults.\n",
    "2. Print the test accuracy.\n",
    "\n",
    "If everything is working as expected, you should get a test accuracy in the 80s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7d. Train ResNet-8 on CIFAR-100\n",
    "\n",
    "Repeat what you did with CIFAR-10, but this time with CIFAR-100.\n",
    "\n",
    "The test accuracy that you achieve should be better than chance, but should NOT be satisfying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7e. Questions\n",
    "\n",
    "**Question 3:** Compare your ResNet-8 with Inception Net with respect to CIFAR-10 test accuracy, runtime (per epoch), and the train/val loss progression throughout training. \n",
    "\n",
    "**Question 4:** How did ResNet-8 do on at CIFAR-100 test set classification compared to Inception Net?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 3:**\n",
    "\n",
    "**Answer 4:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: ResNet-18\n",
    "\n",
    "ResNet is an incredibly flexible/extensible neural network architecture. To get a better sense of this, let's build a deeper ResNet then train it on CIFAR-100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8a. Stacking multiple Residual Blocks together in sequence\n",
    "\n",
    "In ResNet-8, the spatial resolution/number of filters changed in every residual block. In deeper ResNets, this is not usually the case — there is a \"string\"/sequence of Residual Blocks with the SAME resolution and filter count stacked together after the change occurs.\n",
    "\n",
    "To streamline the process of stacking multiple Residual Blocks with the same hyperparameters together, write the `stack_residualblocks` function in `resnets.py`. This should save you lots of copy-pasting and/or typing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnets import stack_residualblocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: `stack_residualblocks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    test_stack = stack_residualblocks('TestStack', 4, i+1, prev_layer_or_block=None, first_block_stride=1)\n",
    "    print(f'There are {len(test_stack)} blocks in the residual stack. There should be {i+1}.')\n",
    "\n",
    "strides_in_stack = [block.strides for block in test_stack]\n",
    "print(f'The strides in each block are: {strides_in_stack}. They should be [1, 1, 1, 1]')\n",
    "\n",
    "test_stack = stack_residualblocks('TestStack', 4, 3, prev_layer_or_block=None, first_block_stride=2)\n",
    "strides_in_stack = [block.strides for block in test_stack]\n",
    "print(f'The strides in each block are: {strides_in_stack}. They should be [2, 1, 1, 1]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The blocks are:')\n",
    "for block in test_stack:\n",
    "    print(block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above should print:\n",
    "\n",
    "```\n",
    "The blocks are:\n",
    "TestStack/block_1:\n",
    "\tConv2D layer output(TestStack/block_1/main_3x3conv_2) shape: None\n",
    "\tConv2D layer output(TestStack/block_1/main_3x3conv_1) shape: None\n",
    "\t-->Conv2D1x1 layer output(TestStack/block_1/skip_conv1x1) shape: None-->\n",
    "TestStack/block_2:\n",
    "\tConv2D layer output(TestStack/block_2/main_3x3conv_2) shape: None\n",
    "\tConv2D layer output(TestStack/block_2/main_3x3conv_1) shape: None\n",
    "TestStack/block_3:\n",
    "\tConv2D layer output(TestStack/block_3/main_3x3conv_2) shape: None\n",
    "\tConv2D layer output(TestStack/block_3/main_3x3conv_1) shape: None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8b. Build ResNet-18\n",
    "\n",
    "Implement the `ResNet18` class in `resnets.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnets import ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: `ResNet18`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res18 = ResNet18(C=4, input_feats_shape=(32, 32, 3))\n",
    "res18.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell should print:\n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "Dense layer output(Output) shape: [1, 4]\n",
    "Global Avg Pooling 2D layer output(GlobalAvgPool2D) shape: [1, 512]\n",
    "stack4/block_2:\n",
    "\tConv2D layer output(stack4/block_2/main_3x3conv_2) shape: [1, 4, 4, 512]\n",
    "\tConv2D layer output(stack4/block_2/main_3x3conv_1) shape: [1, 4, 4, 512]\n",
    "stack4/block_1:\n",
    "\tConv2D layer output(stack4/block_1/main_3x3conv_2) shape: [1, 4, 4, 512]\n",
    "\tConv2D layer output(stack4/block_1/main_3x3conv_1) shape: [1, 4, 4, 512]\n",
    "\t-->Conv2D1x1 layer output(stack4/block_1/skip_conv1x1) shape: [1, 4, 4, 512]-->\n",
    "stack3/block_2:\n",
    "\tConv2D layer output(stack3/block_2/main_3x3conv_2) shape: [1, 8, 8, 256]\n",
    "\tConv2D layer output(stack3/block_2/main_3x3conv_1) shape: [1, 8, 8, 256]\n",
    "stack3/block_1:\n",
    "\tConv2D layer output(stack3/block_1/main_3x3conv_2) shape: [1, 8, 8, 256]\n",
    "\tConv2D layer output(stack3/block_1/main_3x3conv_1) shape: [1, 8, 8, 256]\n",
    "\t-->Conv2D1x1 layer output(stack3/block_1/skip_conv1x1) shape: [1, 8, 8, 256]-->\n",
    "stack2/block_2:\n",
    "\tConv2D layer output(stack2/block_2/main_3x3conv_2) shape: [1, 16, 16, 128]\n",
    "\tConv2D layer output(stack2/block_2/main_3x3conv_1) shape: [1, 16, 16, 128]\n",
    "stack2/block_1:\n",
    "\tConv2D layer output(stack2/block_1/main_3x3conv_2) shape: [1, 16, 16, 128]\n",
    "\tConv2D layer output(stack2/block_1/main_3x3conv_1) shape: [1, 16, 16, 128]\n",
    "\t-->Conv2D1x1 layer output(stack2/block_1/skip_conv1x1) shape: [1, 16, 16, 128]-->\n",
    "stack1/block_2:\n",
    "\tConv2D layer output(stack1/block_2/main_3x3conv_2) shape: [1, 32, 32, 64]\n",
    "\tConv2D layer output(stack1/block_2/main_3x3conv_1) shape: [1, 32, 32, 64]\n",
    "stack1/block_1:\n",
    "\tConv2D layer output(stack1/block_1/main_3x3conv_2) shape: [1, 32, 32, 64]\n",
    "\tConv2D layer output(stack1/block_1/main_3x3conv_1) shape: [1, 32, 32, 64]\n",
    "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 64]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8c. Overfit ResNet-18 on CIFAR-100 dev set\n",
    "\n",
    "Perform the usual overfitting protocol to test out your ResNet-18. However, this time use the 1st 500 samples of CIFAR-100 rather than CIFAR-10 to conduct the test.\n",
    "\n",
    "In the cell below, import CIFAR-100 and reproduce our usual overfit protocol:\n",
    "1. Create a dev set from the 1st 500 training CIFAR-100 samples.\n",
    "2. Train your net on the dev set for `80` epochs (turn off early stopping for this test). *Do not use any regularization.* \n",
    "\n",
    "Your training loss should start out at ~4.7 after the first epoch and rapidly plummet to 0.01 or less after about 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8d. Train ResNet-18 on CIFAR-100\n",
    "\n",
    "In the cell below, train your ResNet-18 on CIFAR-100. Print out the test set after training concludes.\n",
    "\n",
    "Use regularization strength of `1.5`, a patience of `15`, learning rate patience of `4`, and keep the rest of the hyperparameters to their defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8e. Visualize the predictions made by ResNet-18 on the CIFAR-100 test set.\n",
    "\n",
    "In the cell below, use your trained ResNet-18 to get the predicted classes of thr 1st 225 test set images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to create a 15x15 grid of CIFAR-100 images with the true and predicted classes in the title. The predicted classes are color-coded  blue if they are correct, red if they are incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_,_, x100_test_vis, y100_test_vis, classnames = get_dataset('cifar100', standardize_ds=False)\n",
    "\n",
    "panel_sz = 4\n",
    "grid = 15\n",
    "fig, axes, = plt.subplots(nrows=grid, ncols=grid, figsize=(grid*panel_sz, grid*panel_sz))\n",
    "\n",
    "for r in range(grid):\n",
    "    for c in range(grid):\n",
    "        ind = grid*r + c\n",
    "        axes[r,c].imshow(x100_test_vis[ind])\n",
    "        axes[r,c].set_xticks([])\n",
    "        axes[r,c].set_yticks([])\n",
    "        title = f'{classnames[y100_test[ind]]}\\nPredicted: '\n",
    "        title += f'{classnames[y_pred[ind]]}'\n",
    "\n",
    "        color = 'blue'\n",
    "        if y100_test[ind] != y_pred[ind]:\n",
    "            color = 'red'\n",
    "\n",
    "        axes[r,c].set_title(title, color=color)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8f. Questions\n",
    "\n",
    "**Question 5:** Take a look at the above montage. Does the mistakes made by ResNet-18 seem reasonable? Provide some specific examples to support your conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 5:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "### General guidelines\n",
    "\n",
    "1. Never integrate extensions into your base project so that they change the expected behavior of core functions. If your extension changes the core design/behavior, no problem, duplicate your working base project and add features from there.\n",
    "2. Check the rubric to keep in mind how extensions on this project will be graded.\n",
    "3. While I may consult your code and \"written log\" of what you did, **I am grading your extensions based on what you present in your 3-5 min video.**\n",
    "3. I suggest documenting your explorations in a \"log\" or \"lab notebook\" style (i.e. documenting your thought/progression/discovery/learning process). I'm not grading your writing, so you can keep it succinct. **Whatever is most useful to you to remember what you did.** \n",
    "4. I suggest taking a hypothesis driven approach. For example \"I was curious about X so I explored Y. I found Z, which was not what I expected because..., so then tried A...\"\n",
    "5. Make plots to help showcase your results.\n",
    "6. **More is not necessarily better.** Generally, a small number of \"in-depth\" extensions count for more than many \"shallow\" extensions.\n",
    "\n",
    "### AI guidelines\n",
    "\n",
    "You may use AI in mostly any capacity for extensions. However, keep in mind:\n",
    "1. There is no need to use AI at all!\n",
    "2. You are welcome to use AI as a tool (e.g. automate something that is tedious, help you get unstuck, etc.). However, you should be coding, you should be thinking, you should be writing, you should be creating. If you are spending most (or even close to most) of your time typing into a chatbot and copy-pasting, you have probably gone too far with AI use.\n",
    "3. I don't find large volumes of AI generated code/text/plots to be particularly impressive and you risk losing my interest while grading. Remember: I'm grading your extensions based on your video presentation. **More is not necessarily better.**\n",
    "\n",
    "### Video guidelines\n",
    "\n",
    "1. Please try to keep your video to 5 minutes (*I have other projects to grade!*). If you turn in a longer video, I make no promise that I will watch more than 5 minutes.\n",
    "2. Your screen should be shared as you show me what you did. A live video of your face should also appear somewhere on the screen (e.g. picture-in-picture overlay / split screen).\n",
    "3. Your partner should join you for the video and take turns talking, but, if necessary, it is fine to have one team member present during the record the video.\n",
    "4. Do not simply read text from your notebook, do not read from a prepared script. I am not grading how polished your video presentation is (see extension grading criteria on rubric). \n",
    "5. I am looking for original and creative explorations sparked by your curiosity/interest/passion in a topic. This should be apparent in your video.\n",
    "6. Be natural,, don't feel the need to impress me with fancy language. If it is helpful, imagine that we are talking one-on-one about your extension. Tell me what you did :)\n",
    "\n",
    "### Extension ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. ResNet-34\n",
    "\n",
    "Create and train the well-known network of the ResNet family called ResNet-34. Here is a suggested network configuration to experiment with:\n",
    "\n",
    "```\n",
    "block_units = [64, 128, 256, 512]\n",
    "num_blocks = [3, 4, 6, 3]\n",
    "first_block_strides = [1, 2, 2, 2]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. ResNet-50\n",
    "\n",
    "Create and train the well-known network of the ResNet family called ResNet-50. Given its depth, it uses a \"Bottleneck block\" rather than a normal Residual Block, but the overall structure is very similar. Here is a suggested network configuration to experiment with:\n",
    "\n",
    "```\n",
    "block_units = [64, 128, 256, 512]\n",
    "num_blocks = [3, 4, 6, 3]\n",
    "first_block_strides = [1, 2, 2, 2]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. VGG networks on CIFAR-100\n",
    "\n",
    "How does one or more of your VGG networks do at classifying images in CIFAR-100?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Other ResNets on CIFAR-10\n",
    "\n",
    "How do the other ResNets do at classifying images in CIFAR-10?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Multi-network comparison\n",
    "\n",
    "Compare the accuracy, efficiency, etc of any number of networks from the VGG, Inception Net, and ResNet families."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Add support for saving/loading network weights\n",
    "\n",
    "A key limitation of your current deep learning library is that parameters that capture the learning in networks are completely reset/lost/wiped out when the notebook kernel is terminated. Add (and test!) support for saving network parameters to disk after (or periodically during) training. Add (and test!) support for loading network parameters back into the network from disk before training. \n",
    "\n",
    "Be careful to include the moving mean and standard deviation parameters in batch normalization layers otherwise the whole net will not work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Other image datasets\n",
    "\n",
    "Apply any of the three deep network families to another dataset of your choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Hyperparameter tuning\n",
    "\n",
    "Try and find hyperparameters that allow Inception Net and the ResNets to achieve better accuracy on CIFAR-10 and/or CIFAR-100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Build other Inception Nets\n",
    "\n",
    "We only built a single network, but just like VGG and ResNet, you can modify the network depth while following the computational motifs of the Inception Net architecture. Design and experiment with your own Inception Net!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Analyze errors made by one or more of the nets\n",
    "\n",
    "Make a confusion matrix for CIFAR-10 or CIFAR-100 (*a challenge to make it useful!*).\n",
    "\n",
    "Visualize the predictions made by Inception Net and/or a VGG net, perhaps similar what was done with the ResNet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs444",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
