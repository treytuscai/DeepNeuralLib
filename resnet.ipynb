{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a82d7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Trey Tuscai and Gordon Doore\n",
    "\n",
    "Spring 2025\n",
    "\n",
    "CS 444: Deep Learning\n",
    "\n",
    "Project 2: Branch Neural Networks\n",
    "\n",
    "#### Week 2: Residual networks\n",
    "\n",
    "The focus this week is on the ResNet architecture. You will build several neural networks in the ResNet family and and train them on CIFAR-10 and CIFAR-100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6381ec",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 16:58:57.263229: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-06 16:59:04.345661: I tensorflow/core/platform/cpu_feature_guard.cc:211] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=7)\n",
    "\n",
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051dd9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 6: The Residual Block\n",
    "\n",
    "This task focuses on implementing and testing the **Residual Block** in preparation of creating the first ResNet (**ResNet-8**). \n",
    "\n",
    "Much like how Inception Blocks represent the building blocks of Inception Net, stacks of Residual Blocks represent the basis of ResNet. Residual Blocks possess a simpler structure than Inception Blocks — they only contain two parallel branches with fewer layers. Here is a refresher on the structure of the branches:\n",
    "\n",
    "**Main branch:** sequence of two 2D convolutional layers.\n",
    "\n",
    "**Residual branch:** the input signal to the Residual Block passes through \"as-is\", without modification (usually).\n",
    "\n",
    "Like Inception Block, the output of both branches comes together at the end of the block. However, the branch outputs are SUMMED together rather than being concatenated.\n",
    "\n",
    "\n",
    "This is the story for most Residual Blocks, however, like most CNNs:\n",
    "1. the spatial resolution of the activations occasionally decreases\n",
    "2. the number of conv filters/neurons increases\n",
    "\n",
    "as we go deeper in a ResNet. Both of these factors tend to change *at the same time* in a small number of Residual Blocks located at various depths of the ResNet. Put another way, the spatial resolution and number of filters tends to remain constant across most successive Residual Blocks and they only changes in a few blocks throughout the net.\n",
    "1. The decrease in spatial resolution is implemented in these small number of Residual Blocks with a convolutional stride > 1.\n",
    "2. A 1x1 convolutional layer is needed as the \"special sauce\" along the residual branch to make the shapes of signals in both branches match (*otherwise they could not be summed!*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa14e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 6a. Implement and test the Residual Block\n",
    "\n",
    "The class is in `residual_block.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f6a6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from residual_block import ResidualBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b08c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `ResidualBlock` Stride 1 (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "205dc6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 17:00:12.147111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20601 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 17:00:17.751333: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 90400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestResidualBlock_S1:\n",
      "\tConv2D layer output(TestResidualBlock_S1/main_3x3conv_2) shape: [1, 4, 4, 7]\n",
      "\tConv2D layer output(TestResidualBlock_S1/main_3x3conv_1) shape: [1, 4, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "# Testing architecture and shapes\n",
    "# Stride 1\n",
    "tf.random.set_seed(0)\n",
    "res1 = ResidualBlock('TestResidualBlock_S1', 7, prev_layer_or_block=None, strides=1)\n",
    "res1(tf.ones([1, 4, 4, 7]))\n",
    "print(res1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f614",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The above cell should print:\n",
    "\n",
    "```\n",
    "TestResidualBlock_S1:\n",
    "\tConv2D layer output(TestResidualBlock_S1/main_3x3conv_2) shape: [1, 4, 4, 7]\n",
    "\tConv2D layer output(TestResidualBlock_S1/main_3x3conv_1) shape: [1, 4, 4, 7]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83efe8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the netAct output from the block is (2, 4, 4, 7) and should be (2, 4, 4, 7)\n",
      "The first few activations are:\n",
      "[[0.        0.5208229 0.1888617 0.       ]\n",
      " [0.        0.7621396 0.1734906 0.8486798]\n",
      " [0.        0.6156112 0.4272216 0.       ]\n",
      " [0.5561852 0.4888234 1.0138503 0.5533389]]\n",
      "and should be:\n",
      "[[0.        0.520823  0.1888617 0.       ]\n",
      " [0.        0.7621396 0.1734907 0.8486798]\n",
      " [0.        0.6156113 0.4272216 0.       ]\n",
      " [0.5561852 0.4888234 1.0138503 0.5533389]]\n"
     ]
    }
   ],
   "source": [
    "# Test activations\n",
    "tf.random.set_seed(0)\n",
    "net_acts1 = res1(tf.random.uniform([2, 4, 4, 7]))\n",
    "print(f'The shape of the netAct output from the block is {net_acts1.shape} and should be (2, 4, 4, 7)')\n",
    "print(f'The first few activations are:\\n{net_acts1[0,:,:, 0]}')\n",
    "print('and should be:')\n",
    "print('''[[0.        0.520823  0.1888617 0.       ]\n",
    " [0.        0.7621396 0.1734907 0.8486798]\n",
    " [0.        0.6156113 0.4272216 0.       ]\n",
    " [0.5561852 0.4888234 1.0138503 0.5533389]]''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eec95",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `ResidualBlock` Stride 2 (2/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a2d3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestResidualBlock_S2:\n",
      "\tConv2D layer output(TestResidualBlock_S2/main_3x3conv_2) shape: [1, 3, 3, 5]\n",
      "\tConv2D layer output(TestResidualBlock_S2/main_3x3conv_1) shape: [1, 3, 3, 5]\n",
      "\t-->Conv2D1x1 layer output(TestResidualBlock_S2/skip_conv1x1) shape: [1, 3, 3, 5]-->\n"
     ]
    }
   ],
   "source": [
    "# Testing architecture and shapes\n",
    "# Stride 2\n",
    "tf.random.set_seed(0)\n",
    "res2 = ResidualBlock('TestResidualBlock_S2', 5, prev_layer_or_block=None, strides=2)\n",
    "res2(tf.ones([1, 6, 6, 5]))\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05382",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The above cell should print:\n",
    "\n",
    "```\n",
    "TestResidualBlock_S2:\n",
    "\tConv2D layer output(TestResidualBlock_S2/main_3x3conv_2) shape: [1, 3, 3, 5]\n",
    "\tConv2D layer output(TestResidualBlock_S2/main_3x3conv_1) shape: [1, 3, 3, 5]\n",
    "\t-->Conv2D1x1 layer output(TestResidualBlock_S2/skip_conv1x1) shape: [1, 3, 3, 5]-->\n",
    "```\n",
    "\n",
    "*The layer with the --> is the residual branch.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "038d46",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the netAct output from the block is (3, 3, 3, 5) and should be (3, 3, 3, 5)\n",
      "The first few activations are:\n",
      "[[[0.2404822 0.        0.        0.2851935 0.       ]\n",
      "  [0.        0.        0.        0.1339087 0.6898913]\n",
      "  [0.        0.        0.        0.4596352 0.2781556]]\n",
      "\n",
      " [[0.        0.        0.        0.6591434 1.3703969]\n",
      "  [0.2665228 0.        0.        0.9614864 0.       ]\n",
      "  [0.        0.        0.        0.3844326 0.7111532]]\n",
      "\n",
      " [[0.0933783 0.        0.        0.1378801 0.3006182]\n",
      "  [0.1873689 0.        0.        0.4464225 1.106713 ]\n",
      "  [0.        0.        0.        0.7910072 0.345379 ]]]\n",
      "and should be:\n",
      "[[[0.2404823 0.        0.        0.2851936 0.       ]\n",
      "  [0.        0.        0.        0.1339086 0.6898913]\n",
      "  [0.        0.        0.        0.4596353 0.2781557]]\n",
      "\n",
      " [[0.        0.        0.        0.6591434 1.3703969]\n",
      "  [0.2665227 0.        0.        0.9614864 0.       ]\n",
      "  [0.        0.        0.        0.3844326 0.7111533]]\n",
      "\n",
      " [[0.0933782 0.        0.        0.1378801 0.3006183]\n",
      "  [0.1873689 0.        0.        0.4464224 1.1067129]\n",
      "  [0.        0.        0.        0.7910071 0.345379 ]]]\n"
     ]
    }
   ],
   "source": [
    "# Test activations\n",
    "tf.random.set_seed(0)\n",
    "net_acts2 = res2(tf.random.uniform([3, 6, 6, 5]))\n",
    "print(f'The shape of the netAct output from the block is {net_acts2.shape} and should be (3, 3, 3, 5)')\n",
    "print(f'The first few activations are:\\n{net_acts2[0,:,:, :]}')\n",
    "print('and should be:')\n",
    "print('''[[[0.2404823 0.        0.        0.2851936 0.       ]\n",
    "  [0.        0.        0.        0.1339086 0.6898913]\n",
    "  [0.        0.        0.        0.4596353 0.2781557]]\n",
    "\n",
    " [[0.        0.        0.        0.6591434 1.3703969]\n",
    "  [0.2665227 0.        0.        0.9614864 0.       ]\n",
    "  [0.        0.        0.        0.3844326 0.7111533]]\n",
    "\n",
    " [[0.0933782 0.        0.        0.1378801 0.3006183]\n",
    "  [0.1873689 0.        0.        0.4464224 1.1067129]\n",
    "  [0.        0.        0.        0.7910071 0.345379 ]]]''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f31db",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 7: ResNet-8\n",
    "\n",
    "Assemble the Residual Blocks and several other layers to build ResNet-8:\n",
    "\n",
    "Conv2D → ResidualBlock → ResidualBlock → ResidualBlock → GlobalAveragePooling2D → Dense\n",
    "\n",
    "After an overfit test to help check whether the network is working, you will train the network on both CIFAR-10 and CIFAR-100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a891b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from resnets import ResNet8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba72f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 7a. Build ResNet-8\n",
    "\n",
    "Implement the following classes in `resnets.py`:\n",
    "1. `ResNet`: Parent class of all specific ResNets (e.g. ResNet-8, ResNet-18, etc.). Having this class helps reduce code size/duplication because the forward pass thru all ResNets is exactly the same!\n",
    "2. `ResNet8`: Assemble the first (*and smallest*) net in the family!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985ce5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `ResNet8` architecture and shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6b7bb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output) shape: [1, 3]\n",
      "Global Avg Pooling 2D layer output(GlobalAveragePool2D) shape: [1, 128]\n",
      "ResidualBlock_3:\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_2) shape: [1, 8, 8, 128]\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_1) shape: [1, 8, 8, 128]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_3/skip_conv1x1) shape: [1, 8, 8, 128]-->\n",
      "ResidualBlock_2:\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_2) shape: [1, 16, 16, 64]\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_1) shape: [1, 16, 16, 64]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_2/skip_conv1x1) shape: [1, 16, 16, 64]-->\n",
      "ResidualBlock_1:\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_2) shape: [1, 32, 32, 32]\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_1) shape: [1, 32, 32, 32]\n",
      "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 32]\n"
     ]
    }
   ],
   "source": [
    "res8 = ResNet8(C=3, input_feats_shape=(32, 32, 3))\n",
    "res8.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc65d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The above cell should print:\n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "Dense layer output(Output) shape: [1, 3]\n",
    "Global Avg Pooling 2D layer output(GlobalAvgPool2D) shape: [1, 128]\n",
    "ResidualBlock_3:\n",
    "\tConv2D layer output(ResidualBlock_3/main_3x3conv_2) shape: [1, 8, 8, 128]\n",
    "\tConv2D layer output(ResidualBlock_3/main_3x3conv_1) shape: [1, 8, 8, 128]\n",
    "\t-->Conv2D1x1 layer output(ResidualBlock_3/skip_conv1x1) shape: [1, 8, 8, 128]-->\n",
    "ResidualBlock_2:\n",
    "\tConv2D layer output(ResidualBlock_2/main_3x3conv_2) shape: [1, 16, 16, 64]\n",
    "\tConv2D layer output(ResidualBlock_2/main_3x3conv_1) shape: [1, 16, 16, 64]\n",
    "\t-->Conv2D1x1 layer output(ResidualBlock_2/skip_conv1x1) shape: [1, 16, 16, 64]-->\n",
    "ResidualBlock_1:\n",
    "\tConv2D layer output(ResidualBlock_1/main_3x3conv_2) shape: [1, 32, 32, 32]\n",
    "\tConv2D layer output(ResidualBlock_1/main_3x3conv_1) shape: [1, 32, 32, 32]\n",
    "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 32]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49772",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 7b. CIFAR-10 overfit test\n",
    "\n",
    "In the cell below, import CIFAR-10 and reproduce our usual overfit protocol:\n",
    "1. Create a dev set from the 1st 500 training CIFAR-10 samples.\n",
    "2. Train your net on the dev set for `80` epochs (turn off early stopping for this test). *Do not use any regularization.* \n",
    "\n",
    "Your training loss should start out at ~2.3 after the first epoch and rapidly plummet to 0.01 or less by about 70 epochs.\n",
    "\n",
    "**Note:** If you coded `fit` to assume there will always be a validation set present, no problem, just plug in the dev set for both the train and val sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7e0bc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from datasets import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cd4e2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test, classnames = get_dataset('cifar10')\n",
    "x_dev = x_train[:500]\n",
    "y_dev = y_train[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca9e98",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output) shape: [1, 10]\n",
      "Global Avg Pooling 2D layer output(GlobalAveragePool2D) shape: [1, 128]\n",
      "ResidualBlock_3:\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_2) shape: [1, 8, 8, 128]\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_1) shape: [1, 8, 8, 128]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_3/skip_conv1x1) shape: [1, 8, 8, 128]-->\n",
      "ResidualBlock_2:\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_2) shape: [1, 16, 16, 64]\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_1) shape: [1, 16, 16, 64]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_2/skip_conv1x1) shape: [1, 16, 16, 64]-->\n",
      "ResidualBlock_1:\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_2) shape: [1, 32, 32, 32]\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_1) shape: [1, 32, 32, 32]\n",
      "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743958870.215802     584 service.cc:145] XLA service 0x799e0e54e640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743958870.215851     584 service.cc:153]   StreamExecutor device (0): NVIDIA L4, Compute Capability 8.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 17:01:10.628313: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743958871.801254     584 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss = 2.5854, Validation Loss = 2.3263, Validation Accuracy = 0.1473\n",
      "Epoch 1/80 took 13.3567 seconds\n",
      "Epoch 2: Training Loss = 2.2497, Validation Loss = 2.1903, Validation Accuracy = 0.1920\n",
      "Epoch 2/80 took 0.1009 seconds\n",
      "Epoch 3: Training Loss = 2.1547, Validation Loss = 2.1454, Validation Accuracy = 0.2188\n",
      "Epoch 3/80 took 0.0528 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Training Loss = 2.1165, Validation Loss = 2.0979, Validation Accuracy = 0.2031\n",
      "Epoch 4/80 took 0.0546 seconds\n",
      "Epoch 5: Training Loss = 2.0975, Validation Loss = 2.0723, Validation Accuracy = 0.2299\n",
      "Epoch 5/80 took 0.0524 seconds\n",
      "Epoch 6: Training Loss = 2.0260, Validation Loss = 2.0176, Validation Accuracy = 0.2388\n",
      "Epoch 6/80 took 0.0517 seconds\n",
      "Epoch 7: Training Loss = 2.0233, Validation Loss = 2.0264, Validation Accuracy = 0.2277\n",
      "Epoch 7/80 took 0.0515 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Training Loss = 2.0125, Validation Loss = 1.9709, Validation Accuracy = 0.2946\n",
      "Epoch 8/80 took 0.0540 seconds\n",
      "Epoch 9: Training Loss = 1.9300, Validation Loss = 1.9440, Validation Accuracy = 0.2701\n",
      "Epoch 9/80 took 0.0575 seconds\n",
      "Epoch 10: Training Loss = 1.9202, Validation Loss = 1.8925, Validation Accuracy = 0.2701\n",
      "Epoch 10/80 took 0.0519 seconds\n",
      "Epoch 11: Training Loss = 1.8509, Validation Loss = 1.8679, Validation Accuracy = 0.2946\n",
      "Epoch 11/80 took 0.0522 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Training Loss = 1.8899, Validation Loss = 1.8093, Validation Accuracy = 0.3661\n",
      "Epoch 12/80 took 0.0550 seconds\n",
      "Epoch 13: Training Loss = 1.8793, Validation Loss = 1.8117, Validation Accuracy = 0.3013\n",
      "Epoch 13/80 took 0.0515 seconds\n",
      "Epoch 14: Training Loss = 1.7787, Validation Loss = 1.7602, Validation Accuracy = 0.3214\n",
      "Epoch 14/80 took 0.0514 seconds\n",
      "Epoch 15: Training Loss = 1.7517, Validation Loss = 1.7021, Validation Accuracy = 0.3884\n",
      "Epoch 15/80 took 0.0523 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Training Loss = 1.7173, Validation Loss = 1.7423, Validation Accuracy = 0.3348\n",
      "Epoch 16/80 took 0.0522 seconds\n",
      "Epoch 17: Training Loss = 1.6980, Validation Loss = 1.6522, Validation Accuracy = 0.3817\n",
      "Epoch 17/80 took 0.0516 seconds\n",
      "Epoch 18: Training Loss = 1.5991, Validation Loss = 1.6928, Validation Accuracy = 0.3906\n",
      "Epoch 18/80 took 0.0516 seconds\n",
      "Epoch 19: Training Loss = 1.5919, Validation Loss = 1.5886, Validation Accuracy = 0.4330\n",
      "Epoch 19/80 took 0.0521 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Training Loss = 1.6312, Validation Loss = 1.6474, Validation Accuracy = 0.3929\n",
      "Epoch 20/80 took 0.0538 seconds\n",
      "Epoch 21: Training Loss = 1.6032, Validation Loss = 1.5041, Validation Accuracy = 0.4754\n",
      "Epoch 21/80 took 0.0515 seconds\n",
      "Epoch 22: Training Loss = 1.5456, Validation Loss = 1.5439, Validation Accuracy = 0.4286\n",
      "Epoch 22/80 took 0.0529 seconds\n",
      "Epoch 23: Training Loss = 1.5534, Validation Loss = 1.3962, Validation Accuracy = 0.5446\n",
      "Epoch 23/80 took 0.0515 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Training Loss = 1.4298, Validation Loss = 1.4104, Validation Accuracy = 0.5134\n",
      "Epoch 24/80 took 0.0531 seconds\n",
      "Epoch 25: Training Loss = 1.4482, Validation Loss = 1.4102, Validation Accuracy = 0.4888\n",
      "Epoch 25/80 took 0.0519 seconds\n",
      "Epoch 26: Training Loss = 1.3011, Validation Loss = 1.3455, Validation Accuracy = 0.5223\n",
      "Epoch 26/80 took 0.0522 seconds\n",
      "Epoch 27: Training Loss = 1.2721, Validation Loss = 1.3218, Validation Accuracy = 0.5156\n",
      "Epoch 27/80 took 0.0518 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Training Loss = 1.3519, Validation Loss = 1.2503, Validation Accuracy = 0.5446\n",
      "Epoch 28/80 took 0.0522 seconds\n",
      "Epoch 29: Training Loss = 1.1772, Validation Loss = 1.1688, Validation Accuracy = 0.6049\n",
      "Epoch 29/80 took 0.0516 seconds\n",
      "Epoch 30: Training Loss = 1.1537, Validation Loss = 1.1478, Validation Accuracy = 0.5982\n",
      "Epoch 30/80 took 0.0521 seconds\n",
      "Epoch 31: Training Loss = 1.1815, Validation Loss = 1.1110, Validation Accuracy = 0.6004\n",
      "Epoch 31/80 took 0.0525 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Training Loss = 1.1633, Validation Loss = 1.1085, Validation Accuracy = 0.6116\n",
      "Epoch 32/80 took 0.0547 seconds\n",
      "Epoch 33: Training Loss = 1.0988, Validation Loss = 1.1109, Validation Accuracy = 0.6161\n",
      "Epoch 33/80 took 0.0517 seconds\n",
      "Epoch 34: Training Loss = 1.0707, Validation Loss = 1.0710, Validation Accuracy = 0.6116\n",
      "Epoch 34/80 took 0.0524 seconds\n",
      "Epoch 35: Training Loss = 0.9533, Validation Loss = 0.9490, Validation Accuracy = 0.7054\n",
      "Epoch 35/80 took 0.0520 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Training Loss = 1.0494, Validation Loss = 1.1507, Validation Accuracy = 0.5625\n",
      "Epoch 36/80 took 0.0547 seconds\n",
      "Epoch 37: Training Loss = 1.0818, Validation Loss = 0.9885, Validation Accuracy = 0.6674\n",
      "Epoch 37/80 took 0.0524 seconds\n",
      "Epoch 38: Training Loss = 0.9804, Validation Loss = 1.0272, Validation Accuracy = 0.6250\n",
      "Epoch 38/80 took 0.0518 seconds\n",
      "Epoch 39: Training Loss = 0.9783, Validation Loss = 0.9010, Validation Accuracy = 0.6920\n",
      "Epoch 39/80 took 0.0515 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Training Loss = 0.9178, Validation Loss = 0.8643, Validation Accuracy = 0.7098\n",
      "Epoch 40/80 took 0.0530 seconds\n",
      "Epoch 41: Training Loss = 0.8779, Validation Loss = 0.9718, Validation Accuracy = 0.6897\n",
      "Epoch 41/80 took 0.0516 seconds\n",
      "Epoch 42: Training Loss = 0.9576, Validation Loss = 0.7852, Validation Accuracy = 0.7232\n",
      "Epoch 42/80 took 0.0519 seconds\n",
      "Epoch 43: Training Loss = 0.7696, Validation Loss = 0.8293, Validation Accuracy = 0.7121\n",
      "Epoch 43/80 took 0.0516 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Training Loss = 0.8142, Validation Loss = 0.7174, Validation Accuracy = 0.7768\n",
      "Epoch 44/80 took 0.0522 seconds\n",
      "Epoch 45: Training Loss = 0.6934, Validation Loss = 0.6895, Validation Accuracy = 0.7679\n",
      "Epoch 45/80 took 0.0518 seconds\n",
      "Epoch 46: Training Loss = 0.6646, Validation Loss = 0.7909, Validation Accuracy = 0.7076\n",
      "Epoch 46/80 took 0.0519 seconds\n",
      "Epoch 47: Training Loss = 0.7035, Validation Loss = 0.7284, Validation Accuracy = 0.7545\n",
      "Epoch 47/80 took 0.0521 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Training Loss = 0.7651, Validation Loss = 0.7334, Validation Accuracy = 0.7210\n",
      "Epoch 48/80 took 0.0527 seconds\n",
      "Epoch 49: Training Loss = 0.8158, Validation Loss = 0.7277, Validation Accuracy = 0.7567\n",
      "Epoch 49/80 took 0.0521 seconds\n",
      "Epoch 50: Training Loss = 0.7384, Validation Loss = 0.8172, Validation Accuracy = 0.7076\n",
      "Epoch 50/80 took 0.0520 seconds\n",
      "Epoch 51: Training Loss = 0.7698, Validation Loss = 0.8071, Validation Accuracy = 0.7321\n",
      "Epoch 51/80 took 0.0516 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Training Loss = 0.7460, Validation Loss = 0.7683, Validation Accuracy = 0.7500\n",
      "Epoch 52/80 took 0.0529 seconds\n",
      "Epoch 53: Training Loss = 0.6499, Validation Loss = 0.6927, Validation Accuracy = 0.7500\n",
      "Epoch 53/80 took 0.0522 seconds\n",
      "Epoch 54: Training Loss = 0.6052, Validation Loss = 0.6268, Validation Accuracy = 0.7790\n",
      "Epoch 54/80 took 0.0518 seconds\n",
      "Epoch 55: Training Loss = 0.6178, Validation Loss = 0.5428, Validation Accuracy = 0.8259\n",
      "Epoch 55/80 took 0.0521 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Training Loss = 0.5608, Validation Loss = 0.5425, Validation Accuracy = 0.8326\n",
      "Epoch 56/80 took 0.0543 seconds\n",
      "Epoch 57: Training Loss = 0.5394, Validation Loss = 0.4458, Validation Accuracy = 0.8571\n",
      "Epoch 57/80 took 0.0519 seconds\n",
      "Epoch 58: Training Loss = 0.5119, Validation Loss = 0.4871, Validation Accuracy = 0.8371\n",
      "Epoch 58/80 took 0.0669 seconds\n",
      "Epoch 59: Training Loss = 0.4394, Validation Loss = 0.4280, Validation Accuracy = 0.8705\n",
      "Epoch 59/80 took 0.0521 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Training Loss = 0.3429, Validation Loss = 0.4125, Validation Accuracy = 0.8728\n",
      "Epoch 60/80 took 0.0534 seconds\n",
      "Epoch 61: Training Loss = 0.3609, Validation Loss = 0.2834, Validation Accuracy = 0.9353\n",
      "Epoch 61/80 took 0.0517 seconds\n",
      "Epoch 62: Training Loss = 0.3262, Validation Loss = 0.3017, Validation Accuracy = 0.9085\n",
      "Epoch 62/80 took 0.0519 seconds\n",
      "Epoch 63: Training Loss = 0.2894, Validation Loss = 0.2906, Validation Accuracy = 0.9040\n",
      "Epoch 63/80 took 0.0520 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: Training Loss = 0.2480, Validation Loss = 0.2902, Validation Accuracy = 0.9107\n",
      "Epoch 64/80 took 0.0528 seconds\n",
      "Epoch 65: Training Loss = 0.2477, Validation Loss = 0.2212, Validation Accuracy = 0.9420\n",
      "Epoch 65/80 took 0.0517 seconds\n",
      "Epoch 66: Training Loss = 0.1816, Validation Loss = 0.2300, Validation Accuracy = 0.9420\n",
      "Epoch 66/80 took 0.0516 seconds\n",
      "Epoch 67: Training Loss = 0.2251, Validation Loss = 0.1557, Validation Accuracy = 0.9754\n",
      "Epoch 67/80 took 0.0518 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: Training Loss = 0.1607, Validation Loss = 0.1625, Validation Accuracy = 0.9621\n",
      "Epoch 68/80 took 0.0529 seconds\n",
      "Epoch 69: Training Loss = 0.1851, Validation Loss = 0.1756, Validation Accuracy = 0.9598\n",
      "Epoch 69/80 took 0.0518 seconds\n",
      "Epoch 70: Training Loss = 0.1694, Validation Loss = 0.2109, Validation Accuracy = 0.9308\n",
      "Epoch 70/80 took 0.0522 seconds\n",
      "Epoch 71: Training Loss = 0.1941, Validation Loss = 0.1960, Validation Accuracy = 0.9464\n",
      "Epoch 71/80 took 0.0520 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: Training Loss = 0.1501, Validation Loss = 0.1372, Validation Accuracy = 0.9732\n",
      "Epoch 72/80 took 0.0525 seconds\n",
      "Epoch 73: Training Loss = 0.1382, Validation Loss = 0.1261, Validation Accuracy = 0.9754\n",
      "Epoch 73/80 took 0.0515 seconds\n",
      "Epoch 74: Training Loss = 0.1231, Validation Loss = 0.1195, Validation Accuracy = 0.9732\n",
      "Epoch 74/80 took 0.0521 seconds\n",
      "Epoch 75: Training Loss = 0.1503, Validation Loss = 0.1631, Validation Accuracy = 0.9487\n",
      "Epoch 75/80 took 0.0520 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: Training Loss = 0.1663, Validation Loss = 0.1322, Validation Accuracy = 0.9754\n",
      "Epoch 76/80 took 0.0541 seconds\n",
      "Epoch 77: Training Loss = 0.1120, Validation Loss = 0.1144, Validation Accuracy = 0.9777\n",
      "Epoch 77/80 took 0.0519 seconds\n",
      "Epoch 78: Training Loss = 0.1122, Validation Loss = 0.0961, Validation Accuracy = 0.9888\n",
      "Epoch 78/80 took 0.0517 seconds\n",
      "Epoch 79: Training Loss = 0.0958, Validation Loss = 0.0852, Validation Accuracy = 0.9844\n",
      "Epoch 79/80 took 0.0515 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: Training Loss = 0.0722, Validation Loss = 0.0679, Validation Accuracy = 0.9933\n",
      "Epoch 80/80 took 0.0529 seconds\n",
      "Finished training after 80 epochs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2.5854297,\n",
       "  2.2497468,\n",
       "  2.1547399,\n",
       "  2.1165285,\n",
       "  2.0975192,\n",
       "  2.0260031,\n",
       "  2.0233045,\n",
       "  2.0125296,\n",
       "  1.93002,\n",
       "  1.9201531,\n",
       "  1.8509347,\n",
       "  1.889932,\n",
       "  1.8792644,\n",
       "  1.7786869,\n",
       "  1.7516723,\n",
       "  1.7173429,\n",
       "  1.697966,\n",
       "  1.5990942,\n",
       "  1.5918684,\n",
       "  1.6312492,\n",
       "  1.6032494,\n",
       "  1.545558,\n",
       "  1.5533642,\n",
       "  1.4297822,\n",
       "  1.4482217,\n",
       "  1.301119,\n",
       "  1.2720656,\n",
       "  1.3518972,\n",
       "  1.1772319,\n",
       "  1.1537479,\n",
       "  1.1814579,\n",
       "  1.1633275,\n",
       "  1.098788,\n",
       "  1.0707209,\n",
       "  0.95325476,\n",
       "  1.0494305,\n",
       "  1.0817847,\n",
       "  0.98039925,\n",
       "  0.9782729,\n",
       "  0.9178203,\n",
       "  0.87792253,\n",
       "  0.95758,\n",
       "  0.76955914,\n",
       "  0.8141868,\n",
       "  0.69339216,\n",
       "  0.6646242,\n",
       "  0.7035171,\n",
       "  0.7651026,\n",
       "  0.8157638,\n",
       "  0.7384411,\n",
       "  0.7697588,\n",
       "  0.74597955,\n",
       "  0.6499058,\n",
       "  0.6051854,\n",
       "  0.61780906,\n",
       "  0.56082433,\n",
       "  0.53941995,\n",
       "  0.5118757,\n",
       "  0.43944666,\n",
       "  0.3429498,\n",
       "  0.3608862,\n",
       "  0.32623875,\n",
       "  0.28941652,\n",
       "  0.24795817,\n",
       "  0.24768978,\n",
       "  0.1816405,\n",
       "  0.22513843,\n",
       "  0.16066617,\n",
       "  0.185137,\n",
       "  0.16936228,\n",
       "  0.19414638,\n",
       "  0.15012631,\n",
       "  0.1381653,\n",
       "  0.12310675,\n",
       "  0.15025103,\n",
       "  0.16629529,\n",
       "  0.11202556,\n",
       "  0.11215307,\n",
       "  0.09577742,\n",
       "  0.07224955],\n",
       " [2.3263412,\n",
       "  2.1903217,\n",
       "  2.1454298,\n",
       "  2.097936,\n",
       "  2.0722785,\n",
       "  2.0176456,\n",
       "  2.026427,\n",
       "  1.9709436,\n",
       "  1.9439955,\n",
       "  1.8925234,\n",
       "  1.8679421,\n",
       "  1.8092663,\n",
       "  1.8117275,\n",
       "  1.7601978,\n",
       "  1.7021434,\n",
       "  1.7422774,\n",
       "  1.6522208,\n",
       "  1.6927973,\n",
       "  1.5886105,\n",
       "  1.6474141,\n",
       "  1.5041031,\n",
       "  1.5439138,\n",
       "  1.3962096,\n",
       "  1.410425,\n",
       "  1.4102246,\n",
       "  1.345521,\n",
       "  1.3217894,\n",
       "  1.2503194,\n",
       "  1.1688378,\n",
       "  1.1478032,\n",
       "  1.1109521,\n",
       "  1.1084989,\n",
       "  1.11088,\n",
       "  1.0710433,\n",
       "  0.9489695,\n",
       "  1.1506708,\n",
       "  0.9884831,\n",
       "  1.02721,\n",
       "  0.90101355,\n",
       "  0.8643016,\n",
       "  0.9718357,\n",
       "  0.78519535,\n",
       "  0.8292659,\n",
       "  0.717416,\n",
       "  0.689535,\n",
       "  0.7908986,\n",
       "  0.72842544,\n",
       "  0.7334419,\n",
       "  0.72771984,\n",
       "  0.8171522,\n",
       "  0.8070806,\n",
       "  0.76830626,\n",
       "  0.69273365,\n",
       "  0.62680244,\n",
       "  0.54283375,\n",
       "  0.5424834,\n",
       "  0.4458262,\n",
       "  0.48705295,\n",
       "  0.4279978,\n",
       "  0.41250756,\n",
       "  0.2834334,\n",
       "  0.3016911,\n",
       "  0.29063302,\n",
       "  0.29016072,\n",
       "  0.22121589,\n",
       "  0.22995345,\n",
       "  0.15567884,\n",
       "  0.16249199,\n",
       "  0.17560911,\n",
       "  0.21090987,\n",
       "  0.19596808,\n",
       "  0.13721056,\n",
       "  0.12612839,\n",
       "  0.11946124,\n",
       "  0.16313677,\n",
       "  0.1321732,\n",
       "  0.11444882,\n",
       "  0.096068226,\n",
       "  0.085170515,\n",
       "  0.067856714],\n",
       " [0.14732143,\n",
       "  0.19196428,\n",
       "  0.21875,\n",
       "  0.203125,\n",
       "  0.22991072,\n",
       "  0.23883928,\n",
       "  0.22767857,\n",
       "  0.29464287,\n",
       "  0.2700893,\n",
       "  0.2700893,\n",
       "  0.29464287,\n",
       "  0.36607143,\n",
       "  0.3013393,\n",
       "  0.32142857,\n",
       "  0.38839287,\n",
       "  0.33482143,\n",
       "  0.38169643,\n",
       "  0.390625,\n",
       "  0.4330357,\n",
       "  0.39285713,\n",
       "  0.47544643,\n",
       "  0.42857143,\n",
       "  0.54464287,\n",
       "  0.51339287,\n",
       "  0.4888393,\n",
       "  0.5223214,\n",
       "  0.515625,\n",
       "  0.54464287,\n",
       "  0.60491073,\n",
       "  0.59821427,\n",
       "  0.6004464,\n",
       "  0.61160713,\n",
       "  0.6160714,\n",
       "  0.61160713,\n",
       "  0.70535713,\n",
       "  0.5625,\n",
       "  0.66741073,\n",
       "  0.625,\n",
       "  0.69196427,\n",
       "  0.7098214,\n",
       "  0.68973213,\n",
       "  0.72321427,\n",
       "  0.7120536,\n",
       "  0.77678573,\n",
       "  0.76785713,\n",
       "  0.70758927,\n",
       "  0.75446427,\n",
       "  0.72098213,\n",
       "  0.7566964,\n",
       "  0.70758927,\n",
       "  0.73214287,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.77901787,\n",
       "  0.82589287,\n",
       "  0.83258927,\n",
       "  0.85714287,\n",
       "  0.8370536,\n",
       "  0.87053573,\n",
       "  0.87276787,\n",
       "  0.93526787,\n",
       "  0.90848213,\n",
       "  0.90401787,\n",
       "  0.91071427,\n",
       "  0.94196427,\n",
       "  0.94196427,\n",
       "  0.9754464,\n",
       "  0.9620536,\n",
       "  0.9598214,\n",
       "  0.9308036,\n",
       "  0.9464286,\n",
       "  0.97321427,\n",
       "  0.9754464,\n",
       "  0.97321427,\n",
       "  0.94866073,\n",
       "  0.9754464,\n",
       "  0.9776786,\n",
       "  0.98883927,\n",
       "  0.984375,\n",
       "  0.9933036],\n",
       " 80)"
      ]
     },
     "execution_count": 11,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model = ResNet8(10, (32,32,3), reg = 0)\n",
    "model.compile(optimizer='adamw')\n",
    "model.fit(x_dev, y_dev, x_dev, y_dev, max_epochs = 80, val_every = 1, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66117",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 7c. Train ResNet-8 on CIFAR-10\n",
    "\n",
    "Repeat our usual training and evaluation protocol:\n",
    "1. Train ResNet-8 on CIFAR-10. Use regularization strength of `1.5`, a patience of `15`, learning rate patience of `4`, and keep the rest of the hyperparameters to their defaults.\n",
    "2. Print the test accuracy.\n",
    "\n",
    "If everything is working as expected, you should get a test accuracy in the 80s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7efc9b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output) shape: [1, 10]\n",
      "Global Avg Pooling 2D layer output(GlobalAveragePool2D) shape: [1, 128]\n",
      "ResidualBlock_3:\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_2) shape: [1, 8, 8, 128]\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_1) shape: [1, 8, 8, 128]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_3/skip_conv1x1) shape: [1, 8, 8, 128]-->\n",
      "ResidualBlock_2:\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_2) shape: [1, 16, 16, 64]\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_1) shape: [1, 16, 16, 64]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_2/skip_conv1x1) shape: [1, 16, 16, 64]-->\n",
      "ResidualBlock_1:\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_2) shape: [1, 32, 32, 32]\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_1) shape: [1, 32, 32, 32]\n",
      "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss = 1.7492, Validation Loss = 1.5184, Validation Accuracy = 0.4453\n",
      "Epoch 1/10000 took 6.6293 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Training Loss = 1.4277, Validation Loss = 1.3107, Validation Accuracy = 0.5226\n",
      "Epoch 2/10000 took 3.1285 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Training Loss = 1.3299, Validation Loss = 1.2617, Validation Accuracy = 0.5461\n",
      "Epoch 3/10000 took 3.1370 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Training Loss = 1.2878, Validation Loss = 1.1990, Validation Accuracy = 0.5723\n",
      "Epoch 4/10000 took 3.1521 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Training Loss = 1.2960, Validation Loss = 1.2461, Validation Accuracy = 0.5501\n",
      "Epoch 5/10000 took 3.2221 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Training Loss = 1.2777, Validation Loss = 1.2594, Validation Accuracy = 0.5535\n",
      "Epoch 6/10000 took 3.1624 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Training Loss = 1.2627, Validation Loss = 1.1886, Validation Accuracy = 0.5831\n",
      "Epoch 7/10000 took 3.1776 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Training Loss = 1.2336, Validation Loss = 1.1834, Validation Accuracy = 0.5815\n",
      "Epoch 8/10000 took 3.1750 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Training Loss = 1.2484, Validation Loss = 1.1796, Validation Accuracy = 0.5857\n",
      "Epoch 9/10000 took 3.1867 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Training Loss = 1.2276, Validation Loss = 1.2603, Validation Accuracy = 0.5505\n",
      "Epoch 10/10000 took 3.2105 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Training Loss = 1.2297, Validation Loss = 1.1390, Validation Accuracy = 0.5859\n",
      "Epoch 11/10000 took 3.2149 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Training Loss = 1.2252, Validation Loss = 1.2287, Validation Accuracy = 0.5601\n",
      "Epoch 12/10000 took 3.2049 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Training Loss = 1.2241, Validation Loss = 1.2764, Validation Accuracy = 0.5611\n",
      "Epoch 13/10000 took 3.2073 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 0.001 Updated lr= 0.0005\n",
      "Epoch 14: Training Loss = 1.2332, Validation Loss = 1.2713, Validation Accuracy = 0.5513\n",
      "Epoch 14/10000 took 3.2331 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Training Loss = 1.1729, Validation Loss = 1.1867, Validation Accuracy = 0.5677\n",
      "Epoch 15/10000 took 3.2256 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Training Loss = 1.1565, Validation Loss = 1.1570, Validation Accuracy = 0.5988\n",
      "Epoch 16/10000 took 3.2314 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Training Loss = 1.1674, Validation Loss = 1.2069, Validation Accuracy = 0.5689\n",
      "Epoch 17/10000 took 3.2467 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Training Loss = 1.1725, Validation Loss = 1.1347, Validation Accuracy = 0.5960\n",
      "Epoch 18/10000 took 3.2366 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Training Loss = 1.1752, Validation Loss = 1.1831, Validation Accuracy = 0.5697\n",
      "Epoch 19/10000 took 3.2346 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Training Loss = 1.1776, Validation Loss = 1.1544, Validation Accuracy = 0.5917\n",
      "Epoch 20/10000 took 3.2369 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 0.0005 Updated lr= 0.00025\n",
      "Epoch 21: Training Loss = 1.1681, Validation Loss = 1.2113, Validation Accuracy = 0.5659\n",
      "Epoch 21/10000 took 3.2365 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Training Loss = 1.1304, Validation Loss = 1.1113, Validation Accuracy = 0.6114\n",
      "Epoch 22/10000 took 3.2264 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Training Loss = 1.1412, Validation Loss = 1.1097, Validation Accuracy = 0.6070\n",
      "Epoch 23/10000 took 3.2285 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Training Loss = 1.1295, Validation Loss = 1.1107, Validation Accuracy = 0.6142\n",
      "Epoch 24/10000 took 3.2474 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Training Loss = 1.1200, Validation Loss = 1.1513, Validation Accuracy = 0.5791\n",
      "Epoch 25/10000 took 3.2386 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Training Loss = 1.1178, Validation Loss = 1.0878, Validation Accuracy = 0.6238\n",
      "Epoch 26/10000 took 3.2272 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Training Loss = 1.1254, Validation Loss = 1.0905, Validation Accuracy = 0.6204\n",
      "Epoch 27/10000 took 3.2170 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Training Loss = 1.1198, Validation Loss = 1.1413, Validation Accuracy = 0.6012\n",
      "Epoch 28/10000 took 3.2156 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 0.00025 Updated lr= 0.000125\n",
      "Epoch 29: Training Loss = 1.1397, Validation Loss = 1.1166, Validation Accuracy = 0.6088\n",
      "Epoch 29/10000 took 3.2225 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Training Loss = 1.0867, Validation Loss = 1.0618, Validation Accuracy = 0.6298\n",
      "Epoch 30/10000 took 3.2261 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Training Loss = 1.0909, Validation Loss = 1.0827, Validation Accuracy = 0.6162\n",
      "Epoch 31/10000 took 3.2175 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Training Loss = 1.0929, Validation Loss = 1.0738, Validation Accuracy = 0.6234\n",
      "Epoch 32/10000 took 3.2021 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Training Loss = 1.1016, Validation Loss = 1.0840, Validation Accuracy = 0.6186\n",
      "Epoch 33/10000 took 3.2372 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Training Loss = 1.0965, Validation Loss = 1.0726, Validation Accuracy = 0.6336\n",
      "Epoch 34/10000 took 3.2140 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Training Loss = 1.0947, Validation Loss = 1.0890, Validation Accuracy = 0.6192\n",
      "Epoch 35/10000 took 3.2231 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Training Loss = 1.1007, Validation Loss = 1.0872, Validation Accuracy = 0.6204\n",
      "Epoch 36/10000 took 3.2124 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Training Loss = 1.0958, Validation Loss = 1.0597, Validation Accuracy = 0.6312\n",
      "Epoch 37/10000 took 3.2140 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Training Loss = 1.0964, Validation Loss = 1.0909, Validation Accuracy = 0.6230\n",
      "Epoch 38/10000 took 3.2418 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Training Loss = 1.0947, Validation Loss = 1.0756, Validation Accuracy = 0.6262\n",
      "Epoch 39/10000 took 3.2152 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 0.000125 Updated lr= 6.25e-05\n",
      "Epoch 40: Training Loss = 1.0961, Validation Loss = 1.0785, Validation Accuracy = 0.6264\n",
      "Epoch 40/10000 took 3.2212 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Training Loss = 1.0791, Validation Loss = 1.0546, Validation Accuracy = 0.6348\n",
      "Epoch 41/10000 took 3.2188 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Training Loss = 1.0777, Validation Loss = 1.0730, Validation Accuracy = 0.6228\n",
      "Epoch 42/10000 took 3.2185 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Training Loss = 1.0730, Validation Loss = 1.0727, Validation Accuracy = 0.6264\n",
      "Epoch 43/10000 took 3.2187 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Training Loss = 1.0814, Validation Loss = 1.0580, Validation Accuracy = 0.6356\n",
      "Epoch 44/10000 took 3.2230 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Training Loss = 1.0641, Validation Loss = 1.0590, Validation Accuracy = 0.6342\n",
      "Epoch 45/10000 took 3.2132 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Training Loss = 1.0727, Validation Loss = 1.0573, Validation Accuracy = 0.6284\n",
      "Epoch 46/10000 took 3.2159 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Training Loss = 1.0786, Validation Loss = 1.0612, Validation Accuracy = 0.6304\n",
      "Epoch 47/10000 took 3.2223 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Training Loss = 1.0791, Validation Loss = 1.0647, Validation Accuracy = 0.6264\n",
      "Epoch 48/10000 took 3.2221 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 6.25e-05 Updated lr= 3.125e-05\n",
      "Epoch 49: Training Loss = 1.0721, Validation Loss = 1.0833, Validation Accuracy = 0.6182\n",
      "Epoch 49/10000 took 3.2165 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Training Loss = 1.0576, Validation Loss = 1.0592, Validation Accuracy = 0.6294\n",
      "Epoch 50/10000 took 3.2159 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Training Loss = 1.0612, Validation Loss = 1.0441, Validation Accuracy = 0.6400\n",
      "Epoch 51/10000 took 3.2148 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Training Loss = 1.0626, Validation Loss = 1.0661, Validation Accuracy = 0.6248\n",
      "Epoch 52/10000 took 3.2474 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: Training Loss = 1.0562, Validation Loss = 1.0397, Validation Accuracy = 0.6404\n",
      "Epoch 53/10000 took 3.2129 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Training Loss = 1.0576, Validation Loss = 1.0464, Validation Accuracy = 0.6348\n",
      "Epoch 54/10000 took 3.2155 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Training Loss = 1.0483, Validation Loss = 1.0608, Validation Accuracy = 0.6318\n",
      "Epoch 55/10000 took 3.2127 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 3.125e-05 Updated lr= 1.5625e-05\n",
      "Epoch 56: Training Loss = 1.0493, Validation Loss = 1.0526, Validation Accuracy = 0.6352\n",
      "Epoch 56/10000 took 3.2199 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Training Loss = 1.0492, Validation Loss = 1.0408, Validation Accuracy = 0.6390\n",
      "Epoch 57/10000 took 3.2108 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Training Loss = 1.0485, Validation Loss = 1.0425, Validation Accuracy = 0.6390\n",
      "Epoch 58/10000 took 3.2155 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Training Loss = 1.0485, Validation Loss = 1.0396, Validation Accuracy = 0.6356\n",
      "Epoch 59/10000 took 3.2323 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Training Loss = 1.0494, Validation Loss = 1.0426, Validation Accuracy = 0.6374\n",
      "Epoch 60/10000 took 3.2128 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: Training Loss = 1.0501, Validation Loss = 1.0429, Validation Accuracy = 0.6394\n",
      "Epoch 61/10000 took 3.2189 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 1.5625e-05 Updated lr= 7.8125e-06\n",
      "Epoch 62: Training Loss = 1.0506, Validation Loss = 1.0463, Validation Accuracy = 0.6388\n",
      "Epoch 62/10000 took 3.2114 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: Training Loss = 1.0471, Validation Loss = 1.0399, Validation Accuracy = 0.6380\n",
      "Epoch 63/10000 took 3.2149 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: Training Loss = 1.0486, Validation Loss = 1.0373, Validation Accuracy = 0.6414\n",
      "Epoch 64/10000 took 3.2161 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: Training Loss = 1.0401, Validation Loss = 1.0346, Validation Accuracy = 0.6384\n",
      "Epoch 65/10000 took 3.2205 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: Training Loss = 1.0482, Validation Loss = 1.0333, Validation Accuracy = 0.6416\n",
      "Epoch 66/10000 took 3.2465 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: Training Loss = 1.0421, Validation Loss = 1.0326, Validation Accuracy = 0.6420\n",
      "Epoch 67/10000 took 3.2209 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: Training Loss = 1.0409, Validation Loss = 1.0326, Validation Accuracy = 0.6412\n",
      "Epoch 68/10000 took 3.2178 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: Training Loss = 1.0433, Validation Loss = 1.0352, Validation Accuracy = 0.6412\n",
      "Epoch 69/10000 took 3.2266 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 7.8125e-06 Updated lr= 3.90625e-06\n",
      "Epoch 70: Training Loss = 1.0379, Validation Loss = 1.0412, Validation Accuracy = 0.6394\n",
      "Epoch 70/10000 took 3.2248 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: Training Loss = 1.0422, Validation Loss = 1.0324, Validation Accuracy = 0.6392\n",
      "Epoch 71/10000 took 3.2115 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: Training Loss = 1.0394, Validation Loss = 1.0326, Validation Accuracy = 0.6390\n",
      "Epoch 72/10000 took 3.2131 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: Training Loss = 1.0415, Validation Loss = 1.0322, Validation Accuracy = 0.6394\n",
      "Epoch 73/10000 took 3.2155 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: Training Loss = 1.0357, Validation Loss = 1.0314, Validation Accuracy = 0.6398\n",
      "Epoch 74/10000 took 3.2258 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: Training Loss = 1.0368, Validation Loss = 1.0322, Validation Accuracy = 0.6424\n",
      "Epoch 75/10000 took 3.2165 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: Training Loss = 1.0352, Validation Loss = 1.0329, Validation Accuracy = 0.6438\n",
      "Epoch 76/10000 took 3.2131 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: Training Loss = 1.0405, Validation Loss = 1.0303, Validation Accuracy = 0.6420\n",
      "Epoch 77/10000 took 3.2196 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: Training Loss = 1.0496, Validation Loss = 1.0347, Validation Accuracy = 0.6394\n",
      "Epoch 78/10000 took 3.2165 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79: Training Loss = 1.0343, Validation Loss = 1.0323, Validation Accuracy = 0.6424\n",
      "Epoch 79/10000 took 3.2120 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 3.90625e-06 Updated lr= 1.953125e-06\n",
      "Epoch 80: Training Loss = 1.0360, Validation Loss = 1.0319, Validation Accuracy = 0.6440\n",
      "Epoch 80/10000 took 3.2439 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: Training Loss = 1.0366, Validation Loss = 1.0299, Validation Accuracy = 0.6434\n",
      "Epoch 81/10000 took 3.2066 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: Training Loss = 1.0324, Validation Loss = 1.0305, Validation Accuracy = 0.6426\n",
      "Epoch 82/10000 took 3.2159 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83: Training Loss = 1.0383, Validation Loss = 1.0311, Validation Accuracy = 0.6396\n",
      "Epoch 83/10000 took 3.2135 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84: Training Loss = 1.0393, Validation Loss = 1.0305, Validation Accuracy = 0.6396\n",
      "Epoch 84/10000 took 3.2189 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: Training Loss = 1.0333, Validation Loss = 1.0299, Validation Accuracy = 0.6430\n",
      "Epoch 85/10000 took 3.2131 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86: Training Loss = 1.0444, Validation Loss = 1.0310, Validation Accuracy = 0.6412\n",
      "Epoch 86/10000 took 3.2119 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: Training Loss = 1.0403, Validation Loss = 1.0303, Validation Accuracy = 0.6424\n",
      "Epoch 87/10000 took 3.2203 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: Training Loss = 1.0427, Validation Loss = 1.0285, Validation Accuracy = 0.6414\n",
      "Epoch 88/10000 took 3.2100 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: Training Loss = 1.0438, Validation Loss = 1.0306, Validation Accuracy = 0.6446\n",
      "Epoch 89/10000 took 3.2382 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Training Loss = 1.0367, Validation Loss = 1.0316, Validation Accuracy = 0.6406\n",
      "Epoch 90/10000 took 3.2214 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 1.953125e-06 Updated lr= 9.765625e-07\n",
      "Epoch 91: Training Loss = 1.0432, Validation Loss = 1.0296, Validation Accuracy = 0.6436\n",
      "Epoch 91/10000 took 3.2137 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: Training Loss = 1.0272, Validation Loss = 1.0294, Validation Accuracy = 0.6418\n",
      "Epoch 92/10000 took 3.2105 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: Training Loss = 1.0356, Validation Loss = 1.0288, Validation Accuracy = 0.6426\n",
      "Epoch 93/10000 took 3.2243 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: Training Loss = 1.0383, Validation Loss = 1.0304, Validation Accuracy = 0.6432\n",
      "Epoch 94/10000 took 3.2329 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95: Training Loss = 1.0382, Validation Loss = 1.0293, Validation Accuracy = 0.6414\n",
      "Epoch 95/10000 took 3.2246 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 9.765625e-07 Updated lr= 4.882813e-07\n",
      "Epoch 96: Training Loss = 1.0352, Validation Loss = 1.0295, Validation Accuracy = 0.6412\n",
      "Epoch 96/10000 took 3.2248 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97: Training Loss = 1.0314, Validation Loss = 1.0296, Validation Accuracy = 0.6422\n",
      "Epoch 97/10000 took 3.2129 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98: Training Loss = 1.0409, Validation Loss = 1.0290, Validation Accuracy = 0.6408\n",
      "Epoch 98/10000 took 3.2202 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Training Loss = 1.0364, Validation Loss = 1.0288, Validation Accuracy = 0.6410\n",
      "Epoch 99/10000 took 3.2124 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Training Loss = 1.0368, Validation Loss = 1.0300, Validation Accuracy = 0.6420\n",
      "Epoch 100/10000 took 3.2166 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101: Training Loss = 1.0380, Validation Loss = 1.0294, Validation Accuracy = 0.6420\n",
      "Epoch 101/10000 took 3.2096 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 4.882813e-07 Updated lr= 2.4414064e-07\n",
      "Epoch 102: Training Loss = 1.0346, Validation Loss = 1.0290, Validation Accuracy = 0.6410\n",
      "Early stopping triggered at epoch 102\n",
      "Finished training after 102 epochs!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.6266025900840759\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model = ResNet8(10, (32,32,3), reg = 1.5)\n",
    "model.compile(optimizer='adamw')\n",
    "model.fit(x_train, y_train, x_val, y_val, val_every = 1, verbose = True, patience=15, lr_patience=4)\n",
    "print(f\"Test acc: {model.evaluate(x_test, y_test)[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6defd8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 7d. Train ResNet-8 on CIFAR-100\n",
    "\n",
    "Repeat what you did with CIFAR-10, but this time with CIFAR-100.\n",
    "\n",
    "The test accuracy that you achieve should be better than chance, but should NOT be satisfying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1df220",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output) shape: [1, 100]\n",
      "Global Avg Pooling 2D layer output(GlobalAveragePool2D) shape: [1, 128]\n",
      "ResidualBlock_3:\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_2) shape: [1, 8, 8, 128]\n",
      "\tConv2D layer output(ResidualBlock_3/main_3x3conv_1) shape: [1, 8, 8, 128]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_3/skip_conv1x1) shape: [1, 8, 8, 128]-->\n",
      "ResidualBlock_2:\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_2) shape: [1, 16, 16, 64]\n",
      "\tConv2D layer output(ResidualBlock_2/main_3x3conv_1) shape: [1, 16, 16, 64]\n",
      "\t-->Conv2D1x1 layer output(ResidualBlock_2/skip_conv1x1) shape: [1, 16, 16, 64]-->\n",
      "ResidualBlock_1:\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_2) shape: [1, 32, 32, 32]\n",
      "\tConv2D layer output(ResidualBlock_1/main_3x3conv_1) shape: [1, 32, 32, 32]\n",
      "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss = 4.0810, Validation Loss = 3.8104, Validation Accuracy = 0.1122\n",
      "Epoch 1/10000 took 9.1026 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Training Loss = 3.5850, Validation Loss = 3.4828, Validation Accuracy = 0.1693\n",
      "Epoch 2/10000 took 2.5555 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Training Loss = 3.3285, Validation Loss = 3.4021, Validation Accuracy = 0.1847\n",
      "Epoch 3/10000 took 2.5625 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Training Loss = 3.1959, Validation Loss = 3.2161, Validation Accuracy = 0.2179\n",
      "Epoch 4/10000 took 2.5911 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Training Loss = 3.0984, Validation Loss = 3.1863, Validation Accuracy = 0.2274\n",
      "Epoch 5/10000 took 2.6134 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Training Loss = 3.0771, Validation Loss = 3.1304, Validation Accuracy = 0.2330\n",
      "Epoch 6/10000 took 2.6060 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Training Loss = 3.0228, Validation Loss = 3.0843, Validation Accuracy = 0.2388\n",
      "Epoch 7/10000 took 2.6178 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Training Loss = 3.0096, Validation Loss = 3.0514, Validation Accuracy = 0.2516\n",
      "Epoch 8/10000 took 2.6094 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Training Loss = 2.9911, Validation Loss = 3.0977, Validation Accuracy = 0.2510\n",
      "Epoch 9/10000 took 2.6130 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Training Loss = 2.9795, Validation Loss = 3.0533, Validation Accuracy = 0.2588\n",
      "Epoch 10/10000 took 2.6146 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Training Loss = 2.9797, Validation Loss = 3.0164, Validation Accuracy = 0.2610\n",
      "Epoch 11/10000 took 2.6182 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Training Loss = 2.9807, Validation Loss = 3.0276, Validation Accuracy = 0.2482\n",
      "Epoch 12/10000 took 2.5887 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Training Loss = 2.9533, Validation Loss = 3.0447, Validation Accuracy = 0.2582\n",
      "Epoch 13/10000 took 2.5954 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 0.001 Updated lr= 0.0005\n",
      "Epoch 14: Training Loss = 2.9468, Validation Loss = 3.1051, Validation Accuracy = 0.2416\n",
      "Epoch 14/10000 took 2.5847 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Training Loss = 2.7795, Validation Loss = 2.8950, Validation Accuracy = 0.2869\n",
      "Epoch 15/10000 took 2.5751 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Training Loss = 2.7436, Validation Loss = 3.0017, Validation Accuracy = 0.2690\n",
      "Epoch 16/10000 took 2.5650 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Training Loss = 2.7374, Validation Loss = 2.8249, Validation Accuracy = 0.2943\n",
      "Epoch 17/10000 took 2.5729 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Training Loss = 2.7333, Validation Loss = 2.8285, Validation Accuracy = 0.2945\n",
      "Epoch 18/10000 took 2.5682 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Training Loss = 2.7296, Validation Loss = 2.8112, Validation Accuracy = 0.3001\n",
      "Epoch 19/10000 took 2.5817 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Training Loss = 2.7179, Validation Loss = 2.8047, Validation Accuracy = 0.3017\n",
      "Epoch 20/10000 took 2.5717 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Training Loss = 2.7072, Validation Loss = 2.8501, Validation Accuracy = 0.2959\n",
      "Epoch 21/10000 took 2.5671 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Training Loss = 2.7297, Validation Loss = 2.7928, Validation Accuracy = 0.2997\n",
      "Epoch 22/10000 took 2.5561 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Training Loss = 2.7143, Validation Loss = 2.8588, Validation Accuracy = 0.2921\n",
      "Epoch 23/10000 took 2.5708 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Training Loss = 2.7311, Validation Loss = 2.8466, Validation Accuracy = 0.2953\n",
      "Epoch 24/10000 took 2.5569 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 0.0005 Updated lr= 0.00025\n",
      "Epoch 25: Training Loss = 2.7233, Validation Loss = 2.8338, Validation Accuracy = 0.2981\n",
      "Epoch 25/10000 took 2.5653 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Training Loss = 2.5861, Validation Loss = 2.7875, Validation Accuracy = 0.3095\n",
      "Epoch 26/10000 took 2.5646 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Training Loss = 2.5720, Validation Loss = 2.7588, Validation Accuracy = 0.3187\n",
      "Epoch 27/10000 took 2.5625 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Training Loss = 2.5549, Validation Loss = 2.6860, Validation Accuracy = 0.3219\n",
      "Epoch 28/10000 took 2.5654 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Training Loss = 2.5703, Validation Loss = 2.7055, Validation Accuracy = 0.3217\n",
      "Epoch 29/10000 took 2.5771 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Training Loss = 2.5785, Validation Loss = 2.7104, Validation Accuracy = 0.3167\n",
      "Epoch 30/10000 took 2.5617 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 0.00025 Updated lr= 0.000125\n",
      "Epoch 31: Training Loss = 2.5616, Validation Loss = 2.7393, Validation Accuracy = 0.3167\n",
      "Epoch 31/10000 took 2.5656 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Training Loss = 2.4671, Validation Loss = 2.6449, Validation Accuracy = 0.3383\n",
      "Epoch 32/10000 took 2.5592 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Training Loss = 2.4533, Validation Loss = 2.6440, Validation Accuracy = 0.3347\n",
      "Epoch 33/10000 took 2.5544 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Training Loss = 2.4618, Validation Loss = 2.6065, Validation Accuracy = 0.3431\n",
      "Epoch 34/10000 took 2.5704 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Training Loss = 2.4651, Validation Loss = 2.6370, Validation Accuracy = 0.3387\n",
      "Epoch 35/10000 took 2.5639 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Training Loss = 2.4494, Validation Loss = 2.6480, Validation Accuracy = 0.3377\n",
      "Epoch 36/10000 took 2.5763 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 0.000125 Updated lr= 6.25e-05\n",
      "Epoch 37: Training Loss = 2.4567, Validation Loss = 2.6142, Validation Accuracy = 0.3456\n",
      "Epoch 37/10000 took 2.5690 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Training Loss = 2.3895, Validation Loss = 2.5836, Validation Accuracy = 0.3484\n",
      "Epoch 38/10000 took 2.5755 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Training Loss = 2.3966, Validation Loss = 2.5832, Validation Accuracy = 0.3490\n",
      "Epoch 39/10000 took 2.5628 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Training Loss = 2.3818, Validation Loss = 2.5909, Validation Accuracy = 0.3502\n",
      "Epoch 40/10000 took 2.5776 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Training Loss = 2.3751, Validation Loss = 2.5601, Validation Accuracy = 0.3512\n",
      "Epoch 41/10000 took 2.5762 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Training Loss = 2.3825, Validation Loss = 2.5754, Validation Accuracy = 0.3518\n",
      "Epoch 42/10000 took 2.5805 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Training Loss = 2.3752, Validation Loss = 2.5497, Validation Accuracy = 0.3622\n",
      "Epoch 43/10000 took 2.5863 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Training Loss = 2.3715, Validation Loss = 2.5745, Validation Accuracy = 0.3514\n",
      "Epoch 44/10000 took 2.5795 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Training Loss = 2.3715, Validation Loss = 2.5632, Validation Accuracy = 0.3546\n",
      "Epoch 45/10000 took 2.5685 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 6.25e-05 Updated lr= 3.125e-05\n",
      "Epoch 46: Training Loss = 2.3767, Validation Loss = 2.5604, Validation Accuracy = 0.3472\n",
      "Epoch 46/10000 took 2.5891 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Training Loss = 2.3362, Validation Loss = 2.5421, Validation Accuracy = 0.3532\n",
      "Epoch 47/10000 took 2.5951 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Training Loss = 2.3410, Validation Loss = 2.5285, Validation Accuracy = 0.3624\n",
      "Epoch 48/10000 took 2.5837 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Training Loss = 2.3262, Validation Loss = 2.5237, Validation Accuracy = 0.3602\n",
      "Epoch 49/10000 took 2.5953 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Training Loss = 2.3328, Validation Loss = 2.5220, Validation Accuracy = 0.3630\n",
      "Epoch 50/10000 took 2.5911 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Training Loss = 2.3261, Validation Loss = 2.5269, Validation Accuracy = 0.3632\n",
      "Epoch 51/10000 took 2.6037 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Training Loss = 2.3176, Validation Loss = 2.5414, Validation Accuracy = 0.3538\n",
      "Epoch 52/10000 took 2.5920 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 3.125e-05 Updated lr= 1.5625e-05\n",
      "Epoch 53: Training Loss = 2.3293, Validation Loss = 2.5303, Validation Accuracy = 0.3602\n",
      "Epoch 53/10000 took 2.5704 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Training Loss = 2.3096, Validation Loss = 2.5159, Validation Accuracy = 0.3662\n",
      "Epoch 54/10000 took 2.5807 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Training Loss = 2.3070, Validation Loss = 2.5110, Validation Accuracy = 0.3702\n",
      "Epoch 55/10000 took 2.5827 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Training Loss = 2.3069, Validation Loss = 2.5103, Validation Accuracy = 0.3640\n",
      "Epoch 56/10000 took 2.5720 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Training Loss = 2.3108, Validation Loss = 2.5141, Validation Accuracy = 0.3686\n",
      "Epoch 57/10000 took 2.5805 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Training Loss = 2.3159, Validation Loss = 2.5049, Validation Accuracy = 0.3676\n",
      "Epoch 58/10000 took 2.5872 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Training Loss = 2.3124, Validation Loss = 2.5068, Validation Accuracy = 0.3684\n",
      "Epoch 59/10000 took 2.5858 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Training Loss = 2.3020, Validation Loss = 2.5157, Validation Accuracy = 0.3640\n",
      "Epoch 60/10000 took 2.5797 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 1.5625e-05 Updated lr= 7.8125e-06\n",
      "Epoch 61: Training Loss = 2.2918, Validation Loss = 2.5148, Validation Accuracy = 0.3632\n",
      "Epoch 61/10000 took 2.5737 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: Training Loss = 2.2839, Validation Loss = 2.5069, Validation Accuracy = 0.3662\n",
      "Epoch 62/10000 took 2.5687 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: Training Loss = 2.3052, Validation Loss = 2.4974, Validation Accuracy = 0.3702\n",
      "Epoch 63/10000 took 2.5737 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: Training Loss = 2.2888, Validation Loss = 2.5052, Validation Accuracy = 0.3710\n",
      "Epoch 64/10000 took 2.5937 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: Training Loss = 2.2919, Validation Loss = 2.5064, Validation Accuracy = 0.3698\n",
      "Epoch 65/10000 took 2.5879 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 7.8125e-06 Updated lr= 3.90625e-06\n",
      "Epoch 66: Training Loss = 2.2871, Validation Loss = 2.5026, Validation Accuracy = 0.3674\n",
      "Epoch 66/10000 took 2.5674 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: Training Loss = 2.2662, Validation Loss = 2.4954, Validation Accuracy = 0.3714\n",
      "Epoch 67/10000 took 2.5745 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: Training Loss = 2.2925, Validation Loss = 2.4927, Validation Accuracy = 0.3716\n",
      "Epoch 68/10000 took 2.5688 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: Training Loss = 2.2713, Validation Loss = 2.4940, Validation Accuracy = 0.3710\n",
      "Epoch 69/10000 took 2.5685 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: Training Loss = 2.2817, Validation Loss = 2.4922, Validation Accuracy = 0.3730\n",
      "Epoch 70/10000 took 2.5741 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: Training Loss = 2.2763, Validation Loss = 2.4906, Validation Accuracy = 0.3678\n",
      "Epoch 71/10000 took 2.5637 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: Training Loss = 2.2829, Validation Loss = 2.4904, Validation Accuracy = 0.3682\n",
      "Epoch 72/10000 took 2.5656 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: Training Loss = 2.2766, Validation Loss = 2.4913, Validation Accuracy = 0.3692\n",
      "Epoch 73/10000 took 2.5679 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: Training Loss = 2.2798, Validation Loss = 2.4938, Validation Accuracy = 0.3726\n",
      "Epoch 74/10000 took 2.5757 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: Training Loss = 2.2763, Validation Loss = 2.4897, Validation Accuracy = 0.3694\n",
      "Epoch 75/10000 took 2.5666 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: Training Loss = 2.2769, Validation Loss = 2.4892, Validation Accuracy = 0.3698\n",
      "Epoch 76/10000 took 2.5937 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: Training Loss = 2.2758, Validation Loss = 2.4919, Validation Accuracy = 0.3680\n",
      "Epoch 77/10000 took 2.5804 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: Training Loss = 2.2862, Validation Loss = 2.4918, Validation Accuracy = 0.3676\n",
      "Epoch 78/10000 took 2.5817 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 3.90625e-06 Updated lr= 1.953125e-06\n",
      "Epoch 79: Training Loss = 2.2738, Validation Loss = 2.4901, Validation Accuracy = 0.3726\n",
      "Epoch 79/10000 took 2.5714 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: Training Loss = 2.2731, Validation Loss = 2.4892, Validation Accuracy = 0.3690\n",
      "Epoch 80/10000 took 2.5639 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: Training Loss = 2.2635, Validation Loss = 2.4888, Validation Accuracy = 0.3680\n",
      "Epoch 81/10000 took 2.6027 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: Training Loss = 2.2747, Validation Loss = 2.4884, Validation Accuracy = 0.3694\n",
      "Epoch 82/10000 took 2.5918 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83: Training Loss = 2.2696, Validation Loss = 2.4868, Validation Accuracy = 0.3700\n",
      "Epoch 83/10000 took 2.5775 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84: Training Loss = 2.2678, Validation Loss = 2.4906, Validation Accuracy = 0.3720\n",
      "Epoch 84/10000 took 2.5767 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: Training Loss = 2.2544, Validation Loss = 2.4884, Validation Accuracy = 0.3734\n",
      "Epoch 85/10000 took 2.5697 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 1.953125e-06 Updated lr= 9.765625e-07\n",
      "Epoch 86: Training Loss = 2.2677, Validation Loss = 2.4905, Validation Accuracy = 0.3714\n",
      "Epoch 86/10000 took 2.5693 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: Training Loss = 2.2668, Validation Loss = 2.4863, Validation Accuracy = 0.3710\n",
      "Epoch 87/10000 took 2.5746 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: Training Loss = 2.2653, Validation Loss = 2.4874, Validation Accuracy = 0.3696\n",
      "Epoch 88/10000 took 2.5768 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: Training Loss = 2.2680, Validation Loss = 2.4865, Validation Accuracy = 0.3694\n",
      "Epoch 89/10000 took 2.5681 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Training Loss = 2.2817, Validation Loss = 2.4868, Validation Accuracy = 0.3696\n",
      "Epoch 90/10000 took 2.5773 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: Training Loss = 2.2765, Validation Loss = 2.4871, Validation Accuracy = 0.3688\n",
      "Epoch 91/10000 took 2.5739 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: Training Loss = 2.2531, Validation Loss = 2.4856, Validation Accuracy = 0.3702\n",
      "Epoch 92/10000 took 2.5626 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: Training Loss = 2.2633, Validation Loss = 2.4860, Validation Accuracy = 0.3702\n",
      "Epoch 93/10000 took 2.5681 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: Training Loss = 2.2659, Validation Loss = 2.4862, Validation Accuracy = 0.3688\n",
      "Epoch 94/10000 took 2.5737 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 9.765625e-07 Updated lr= 4.882813e-07\n",
      "Epoch 95: Training Loss = 2.2737, Validation Loss = 2.4858, Validation Accuracy = 0.3690\n",
      "Epoch 95/10000 took 2.5658 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96: Training Loss = 2.2633, Validation Loss = 2.4843, Validation Accuracy = 0.3710\n",
      "Epoch 96/10000 took 2.5695 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97: Training Loss = 2.2664, Validation Loss = 2.4864, Validation Accuracy = 0.3698\n",
      "Epoch 97/10000 took 2.5888 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98: Training Loss = 2.2769, Validation Loss = 2.4851, Validation Accuracy = 0.3698\n",
      "Epoch 98/10000 took 2.5850 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Training Loss = 2.2762, Validation Loss = 2.4850, Validation Accuracy = 0.3706\n",
      "Epoch 99/10000 took 2.5783 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Training Loss = 2.2631, Validation Loss = 2.4859, Validation Accuracy = 0.3700\n",
      "Epoch 100/10000 took 2.5844 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101: Training Loss = 2.2667, Validation Loss = 2.4849, Validation Accuracy = 0.3702\n",
      "Epoch 101/10000 took 2.5763 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102: Training Loss = 2.2692, Validation Loss = 2.4858, Validation Accuracy = 0.3694\n",
      "Epoch 102/10000 took 2.5806 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103: Training Loss = 2.2672, Validation Loss = 2.4859, Validation Accuracy = 0.3682\n",
      "Epoch 103/10000 took 2.5848 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 4.882813e-07 Updated lr= 2.4414064e-07\n",
      "Epoch 104: Training Loss = 2.2760, Validation Loss = 2.4860, Validation Accuracy = 0.3722\n",
      "Epoch 104/10000 took 2.5732 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105: Training Loss = 2.2674, Validation Loss = 2.4858, Validation Accuracy = 0.3712\n",
      "Epoch 105/10000 took 2.5750 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106: Training Loss = 2.2644, Validation Loss = 2.4862, Validation Accuracy = 0.3704\n",
      "Epoch 106/10000 took 2.5794 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107: Training Loss = 2.2542, Validation Loss = 2.4857, Validation Accuracy = 0.3688\n",
      "Epoch 107/10000 took 2.5775 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108: Training Loss = 2.2704, Validation Loss = 2.4856, Validation Accuracy = 0.3692\n",
      "Epoch 108/10000 took 2.5687 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109: Training Loss = 2.2665, Validation Loss = 2.4852, Validation Accuracy = 0.3696\n",
      "Epoch 109/10000 took 2.5918 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110: Training Loss = 2.2669, Validation Loss = 2.4854, Validation Accuracy = 0.3686\n",
      "Early stopping triggered at epoch 110\n",
      "Finished training after 110 epochs!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.3891226053237915\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "x100_train, y100_train, x100_val, y100_val, x100_test, y100_test, classnames = get_dataset('cifar100')\n",
    "\n",
    "model = ResNet8(100, (32,32,3), reg = 1.5)\n",
    "model.compile(optimizer='adamw')\n",
    "model.fit(x100_train, y100_train, x100_val, y100_val, val_every = 1, verbose = True, patience=15, lr_patience=4)\n",
    "print(f\"Test acc: {model.evaluate(x100_test, y100_test)[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8b5f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 7e. Questions\n",
    "\n",
    "**Question 3:** Compare your ResNet-8 with Inception Net with respect to CIFAR-10 test accuracy, runtime (per epoch), and the train/val loss progression throughout training. \n",
    "\n",
    "**Question 4:** How did ResNet-8 do on at CIFAR-100 test set classification compared to Inception Net?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad97c0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Answer 3:**\n",
    "\n",
    "**Answer 4:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f329f6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 8: ResNet-18\n",
    "\n",
    "ResNet is an incredibly flexible/extensible neural network architecture. To get a better sense of this, let's build a deeper ResNet then train it on CIFAR-100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0d66",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 8a. Stacking multiple Residual Blocks together in sequence\n",
    "\n",
    "In ResNet-8, the spatial resolution/number of filters changed in every residual block. In deeper ResNets, this is not usually the case — there is a \"string\"/sequence of Residual Blocks with the SAME resolution and filter count stacked together after the change occurs.\n",
    "\n",
    "To streamline the process of stacking multiple Residual Blocks with the same hyperparameters together, write the `stack_residualblocks` function in `resnets.py`. This should save you lots of copy-pasting and/or typing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32a0bb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from resnets import stack_residualblocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2350e5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `stack_residualblocks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc561c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 blocks in the residual stack. There should be 1.\n",
      "There are 2 blocks in the residual stack. There should be 2.\n",
      "There are 3 blocks in the residual stack. There should be 3.\n",
      "There are 4 blocks in the residual stack. There should be 4.\n",
      "The strides in each block are: [1, 1, 1, 1]. They should be [1, 1, 1, 1]\n",
      "The strides in each block are: [2, 1, 1]. They should be [2, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    test_stack = stack_residualblocks('TestStack', 4, i+1, prev_layer_or_block=None, first_block_stride=1)\n",
    "    print(f'There are {len(test_stack)} blocks in the residual stack. There should be {i+1}.')\n",
    "\n",
    "strides_in_stack = [block.strides for block in test_stack]\n",
    "print(f'The strides in each block are: {strides_in_stack}. They should be [1, 1, 1, 1]')\n",
    "\n",
    "test_stack = stack_residualblocks('TestStack', 4, 3, prev_layer_or_block=None, first_block_stride=2)\n",
    "strides_in_stack = [block.strides for block in test_stack]\n",
    "print(f'The strides in each block are: {strides_in_stack}. They should be [2, 1, 1, 1]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8aef6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The blocks are:\n",
      "TestStack/block_1:\n",
      "\tConv2D layer output(TestStack/block_1/main_3x3conv_2) shape: None\n",
      "\tConv2D layer output(TestStack/block_1/main_3x3conv_1) shape: None\n",
      "\t-->Conv2D1x1 layer output(TestStack/block_1/skip_conv1x1) shape: None-->\n",
      "TestStack/block_2:\n",
      "\tConv2D layer output(TestStack/block_2/main_3x3conv_2) shape: None\n",
      "\tConv2D layer output(TestStack/block_2/main_3x3conv_1) shape: None\n",
      "TestStack/block_3:\n",
      "\tConv2D layer output(TestStack/block_3/main_3x3conv_2) shape: None\n",
      "\tConv2D layer output(TestStack/block_3/main_3x3conv_1) shape: None\n"
     ]
    }
   ],
   "source": [
    "print('The blocks are:')\n",
    "for block in test_stack:\n",
    "    print(block)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6494",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The above should print:\n",
    "\n",
    "```\n",
    "The blocks are:\n",
    "TestStack/block_1:\n",
    "\tConv2D layer output(TestStack/block_1/main_3x3conv_2) shape: None\n",
    "\tConv2D layer output(TestStack/block_1/main_3x3conv_1) shape: None\n",
    "\t-->Conv2D1x1 layer output(TestStack/block_1/skip_conv1x1) shape: None-->\n",
    "TestStack/block_2:\n",
    "\tConv2D layer output(TestStack/block_2/main_3x3conv_2) shape: None\n",
    "\tConv2D layer output(TestStack/block_2/main_3x3conv_1) shape: None\n",
    "TestStack/block_3:\n",
    "\tConv2D layer output(TestStack/block_3/main_3x3conv_2) shape: None\n",
    "\tConv2D layer output(TestStack/block_3/main_3x3conv_1) shape: None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b8c4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 8b. Build ResNet-18\n",
    "\n",
    "Implement the `ResNet18` class in `resnets.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12aa87",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from resnets import ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2444eb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `ResNet18`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19674f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output) shape: [1, 4]\n",
      "Global Avg Pooling 2D layer output(GlobalAveragePool2D) shape: [1, 512]\n",
      "stack_4/block_2:\n",
      "\tConv2D layer output(stack_4/block_2/main_3x3conv_2) shape: [1, 4, 4, 512]\n",
      "\tConv2D layer output(stack_4/block_2/main_3x3conv_1) shape: [1, 4, 4, 512]\n",
      "stack_4/block_1:\n",
      "\tConv2D layer output(stack_4/block_1/main_3x3conv_2) shape: [1, 4, 4, 512]\n",
      "\tConv2D layer output(stack_4/block_1/main_3x3conv_1) shape: [1, 4, 4, 512]\n",
      "\t-->Conv2D1x1 layer output(stack_4/block_1/skip_conv1x1) shape: [1, 4, 4, 512]-->\n",
      "stack_3/block_2:\n",
      "\tConv2D layer output(stack_3/block_2/main_3x3conv_2) shape: [1, 8, 8, 256]\n",
      "\tConv2D layer output(stack_3/block_2/main_3x3conv_1) shape: [1, 8, 8, 256]\n",
      "stack_3/block_1:\n",
      "\tConv2D layer output(stack_3/block_1/main_3x3conv_2) shape: [1, 8, 8, 256]\n",
      "\tConv2D layer output(stack_3/block_1/main_3x3conv_1) shape: [1, 8, 8, 256]\n",
      "\t-->Conv2D1x1 layer output(stack_3/block_1/skip_conv1x1) shape: [1, 8, 8, 256]-->\n",
      "stack_2/block_2:\n",
      "\tConv2D layer output(stack_2/block_2/main_3x3conv_2) shape: [1, 16, 16, 128]\n",
      "\tConv2D layer output(stack_2/block_2/main_3x3conv_1) shape: [1, 16, 16, 128]\n",
      "stack_2/block_1:\n",
      "\tConv2D layer output(stack_2/block_1/main_3x3conv_2) shape: [1, 16, 16, 128]\n",
      "\tConv2D layer output(stack_2/block_1/main_3x3conv_1) shape: [1, 16, 16, 128]\n",
      "\t-->Conv2D1x1 layer output(stack_2/block_1/skip_conv1x1) shape: [1, 16, 16, 128]-->\n",
      "stack_1/block_2:\n",
      "\tConv2D layer output(stack_1/block_2/main_3x3conv_2) shape: [1, 32, 32, 64]\n",
      "\tConv2D layer output(stack_1/block_2/main_3x3conv_1) shape: [1, 32, 32, 64]\n",
      "stack_1/block_1:\n",
      "\tConv2D layer output(stack_1/block_1/main_3x3conv_2) shape: [1, 32, 32, 64]\n",
      "\tConv2D layer output(stack_1/block_1/main_3x3conv_1) shape: [1, 32, 32, 64]\n",
      "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 64]\n"
     ]
    }
   ],
   "source": [
    "res18 = ResNet18(C=4, input_feats_shape=(32, 32, 3))\n",
    "res18.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da095",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The above cell should print:\n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "Dense layer output(Output) shape: [1, 4]\n",
    "Global Avg Pooling 2D layer output(GlobalAvgPool2D) shape: [1, 512]\n",
    "stack4/block_2:\n",
    "\tConv2D layer output(stack4/block_2/main_3x3conv_2) shape: [1, 4, 4, 512]\n",
    "\tConv2D layer output(stack4/block_2/main_3x3conv_1) shape: [1, 4, 4, 512]\n",
    "stack4/block_1:\n",
    "\tConv2D layer output(stack4/block_1/main_3x3conv_2) shape: [1, 4, 4, 512]\n",
    "\tConv2D layer output(stack4/block_1/main_3x3conv_1) shape: [1, 4, 4, 512]\n",
    "\t-->Conv2D1x1 layer output(stack4/block_1/skip_conv1x1) shape: [1, 4, 4, 512]-->\n",
    "stack3/block_2:\n",
    "\tConv2D layer output(stack3/block_2/main_3x3conv_2) shape: [1, 8, 8, 256]\n",
    "\tConv2D layer output(stack3/block_2/main_3x3conv_1) shape: [1, 8, 8, 256]\n",
    "stack3/block_1:\n",
    "\tConv2D layer output(stack3/block_1/main_3x3conv_2) shape: [1, 8, 8, 256]\n",
    "\tConv2D layer output(stack3/block_1/main_3x3conv_1) shape: [1, 8, 8, 256]\n",
    "\t-->Conv2D1x1 layer output(stack3/block_1/skip_conv1x1) shape: [1, 8, 8, 256]-->\n",
    "stack2/block_2:\n",
    "\tConv2D layer output(stack2/block_2/main_3x3conv_2) shape: [1, 16, 16, 128]\n",
    "\tConv2D layer output(stack2/block_2/main_3x3conv_1) shape: [1, 16, 16, 128]\n",
    "stack2/block_1:\n",
    "\tConv2D layer output(stack2/block_1/main_3x3conv_2) shape: [1, 16, 16, 128]\n",
    "\tConv2D layer output(stack2/block_1/main_3x3conv_1) shape: [1, 16, 16, 128]\n",
    "\t-->Conv2D1x1 layer output(stack2/block_1/skip_conv1x1) shape: [1, 16, 16, 128]-->\n",
    "stack1/block_2:\n",
    "\tConv2D layer output(stack1/block_2/main_3x3conv_2) shape: [1, 32, 32, 64]\n",
    "\tConv2D layer output(stack1/block_2/main_3x3conv_1) shape: [1, 32, 32, 64]\n",
    "stack1/block_1:\n",
    "\tConv2D layer output(stack1/block_1/main_3x3conv_2) shape: [1, 32, 32, 64]\n",
    "\tConv2D layer output(stack1/block_1/main_3x3conv_1) shape: [1, 32, 32, 64]\n",
    "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 64]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756e3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 8c. Overfit ResNet-18 on CIFAR-100 dev set\n",
    "\n",
    "Perform the usual overfitting protocol to test out your ResNet-18. However, this time use the 1st 500 samples of CIFAR-100 rather than CIFAR-10 to conduct the test.\n",
    "\n",
    "In the cell below, import CIFAR-100 and reproduce our usual overfit protocol:\n",
    "1. Create a dev set from the 1st 500 training CIFAR-100 samples.\n",
    "2. Train your net on the dev set for `80` epochs (turn off early stopping for this test). *Do not use any regularization.* \n",
    "\n",
    "Your training loss should start out at ~4.7 after the first epoch and rapidly plummet to 0.01 or less after about 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1efeba",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "x100_train, y100_train, x100_val, y100_val, x100_test, y100_test, classnames100 = get_dataset('cifar100')\n",
    "x100_dev = x100_train[:500]\n",
    "y100_dev = y100_train[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd66c9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output) shape: [1, 100]\n",
      "Global Avg Pooling 2D layer output(GlobalAveragePool2D) shape: [1, 512]\n",
      "stack_4/block_2:\n",
      "\tConv2D layer output(stack_4/block_2/main_3x3conv_2) shape: [1, 4, 4, 512]\n",
      "\tConv2D layer output(stack_4/block_2/main_3x3conv_1) shape: [1, 4, 4, 512]\n",
      "stack_4/block_1:\n",
      "\tConv2D layer output(stack_4/block_1/main_3x3conv_2) shape: [1, 4, 4, 512]\n",
      "\tConv2D layer output(stack_4/block_1/main_3x3conv_1) shape: [1, 4, 4, 512]\n",
      "\t-->Conv2D1x1 layer output(stack_4/block_1/skip_conv1x1) shape: [1, 4, 4, 512]-->\n",
      "stack_3/block_2:\n",
      "\tConv2D layer output(stack_3/block_2/main_3x3conv_2) shape: [1, 8, 8, 256]\n",
      "\tConv2D layer output(stack_3/block_2/main_3x3conv_1) shape: [1, 8, 8, 256]\n",
      "stack_3/block_1:\n",
      "\tConv2D layer output(stack_3/block_1/main_3x3conv_2) shape: [1, 8, 8, 256]\n",
      "\tConv2D layer output(stack_3/block_1/main_3x3conv_1) shape: [1, 8, 8, 256]\n",
      "\t-->Conv2D1x1 layer output(stack_3/block_1/skip_conv1x1) shape: [1, 8, 8, 256]-->\n",
      "stack_2/block_2:\n",
      "\tConv2D layer output(stack_2/block_2/main_3x3conv_2) shape: [1, 16, 16, 128]\n",
      "\tConv2D layer output(stack_2/block_2/main_3x3conv_1) shape: [1, 16, 16, 128]\n",
      "stack_2/block_1:\n",
      "\tConv2D layer output(stack_2/block_1/main_3x3conv_2) shape: [1, 16, 16, 128]\n",
      "\tConv2D layer output(stack_2/block_1/main_3x3conv_1) shape: [1, 16, 16, 128]\n",
      "\t-->Conv2D1x1 layer output(stack_2/block_1/skip_conv1x1) shape: [1, 16, 16, 128]-->\n",
      "stack_1/block_2:\n",
      "\tConv2D layer output(stack_1/block_2/main_3x3conv_2) shape: [1, 32, 32, 64]\n",
      "\tConv2D layer output(stack_1/block_2/main_3x3conv_1) shape: [1, 32, 32, 64]\n",
      "stack_1/block_1:\n",
      "\tConv2D layer output(stack_1/block_1/main_3x3conv_2) shape: [1, 32, 32, 64]\n",
      "\tConv2D layer output(stack_1/block_1/main_3x3conv_1) shape: [1, 32, 32, 64]\n",
      "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss = 7.7652, Validation Loss = 4.6127, Validation Accuracy = 0.0089\n",
      "Epoch 1/80 took 8.3178 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Training Loss = 4.6071, Validation Loss = 4.5911, Validation Accuracy = 0.0089\n",
      "Epoch 2/80 took 0.2087 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Training Loss = 4.5924, Validation Loss = 4.5750, Validation Accuracy = 0.0089\n",
      "Epoch 3/80 took 0.2101 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Training Loss = 4.5622, Validation Loss = 4.5537, Validation Accuracy = 0.0134\n",
      "Epoch 4/80 took 0.2059 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Training Loss = 4.5743, Validation Loss = 4.5565, Validation Accuracy = 0.0268\n",
      "Epoch 5/80 took 0.2055 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Training Loss = 4.5407, Validation Loss = 4.5497, Validation Accuracy = 0.0268\n",
      "Epoch 6/80 took 0.2169 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Training Loss = 4.5137, Validation Loss = 4.5262, Validation Accuracy = 0.0156\n",
      "Epoch 7/80 took 0.2133 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Training Loss = 4.5531, Validation Loss = 4.5302, Validation Accuracy = 0.0268\n",
      "Epoch 8/80 took 0.2045 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Training Loss = 4.5299, Validation Loss = 4.5213, Validation Accuracy = 0.0268\n",
      "Epoch 9/80 took 0.2076 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Training Loss = 4.5145, Validation Loss = 4.5153, Validation Accuracy = 0.0268\n",
      "Epoch 10/80 took 0.2127 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Training Loss = 4.5014, Validation Loss = 4.5098, Validation Accuracy = 0.0268\n",
      "Epoch 11/80 took 0.2142 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Training Loss = 4.4903, Validation Loss = 4.5183, Validation Accuracy = 0.0268\n",
      "Epoch 12/80 took 0.2061 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Training Loss = 4.5405, Validation Loss = 4.5227, Validation Accuracy = 0.0268\n",
      "Epoch 13/80 took 0.2109 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Training Loss = 4.5018, Validation Loss = 4.5209, Validation Accuracy = 0.0268\n",
      "Epoch 14/80 took 0.2081 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Training Loss = 4.5059, Validation Loss = 4.5221, Validation Accuracy = 0.0268\n",
      "Epoch 15/80 took 0.2120 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Training Loss = 4.5388, Validation Loss = 4.5060, Validation Accuracy = 0.0268\n",
      "Epoch 16/80 took 0.2098 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Training Loss = 4.5054, Validation Loss = 4.4960, Validation Accuracy = 0.0290\n",
      "Epoch 17/80 took 0.2115 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Training Loss = 4.5065, Validation Loss = 4.5015, Validation Accuracy = 0.0268\n",
      "Epoch 18/80 took 0.2063 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Training Loss = 4.4863, Validation Loss = 4.4876, Validation Accuracy = 0.0268\n",
      "Epoch 19/80 took 0.2111 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Training Loss = 4.4881, Validation Loss = 4.4810, Validation Accuracy = 0.0312\n",
      "Epoch 20/80 took 0.2120 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Training Loss = 4.4979, Validation Loss = 4.4601, Validation Accuracy = 0.0268\n",
      "Epoch 21/80 took 0.2140 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Training Loss = 4.4502, Validation Loss = 4.4354, Validation Accuracy = 0.0335\n",
      "Epoch 22/80 took 0.2051 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Training Loss = 4.4261, Validation Loss = 4.4127, Validation Accuracy = 0.0335\n",
      "Epoch 23/80 took 0.2113 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Training Loss = 4.4196, Validation Loss = 4.3951, Validation Accuracy = 0.0379\n",
      "Epoch 24/80 took 0.2078 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Training Loss = 4.3415, Validation Loss = 4.4037, Validation Accuracy = 0.0357\n",
      "Epoch 25/80 took 0.2144 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Training Loss = 4.4023, Validation Loss = 4.3593, Validation Accuracy = 0.0357\n",
      "Epoch 26/80 took 0.2066 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Training Loss = 4.3483, Validation Loss = 4.3677, Validation Accuracy = 0.0156\n",
      "Epoch 27/80 took 0.2130 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Training Loss = 4.3458, Validation Loss = 4.2989, Validation Accuracy = 0.0290\n",
      "Epoch 28/80 took 0.2052 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Training Loss = 4.2823, Validation Loss = 4.2655, Validation Accuracy = 0.0379\n",
      "Epoch 29/80 took 0.2120 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Training Loss = 4.2886, Validation Loss = 4.2113, Validation Accuracy = 0.0357\n",
      "Epoch 30/80 took 0.2109 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Training Loss = 4.1555, Validation Loss = 4.3251, Validation Accuracy = 0.0446\n",
      "Epoch 31/80 took 0.2127 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Training Loss = 4.1859, Validation Loss = 4.2405, Validation Accuracy = 0.0714\n",
      "Epoch 32/80 took 0.2051 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Training Loss = 4.1555, Validation Loss = 4.1121, Validation Accuracy = 0.0603\n",
      "Epoch 33/80 took 0.2135 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Training Loss = 4.1452, Validation Loss = 4.0591, Validation Accuracy = 0.0625\n",
      "Epoch 34/80 took 0.2082 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Training Loss = 4.0511, Validation Loss = 3.9353, Validation Accuracy = 0.0982\n",
      "Epoch 35/80 took 0.2140 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Training Loss = 3.9292, Validation Loss = 3.8666, Validation Accuracy = 0.1027\n",
      "Epoch 36/80 took 0.2121 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Training Loss = 3.8931, Validation Loss = 3.8000, Validation Accuracy = 0.1116\n",
      "Epoch 37/80 took 0.2104 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Training Loss = 3.7422, Validation Loss = 3.7108, Validation Accuracy = 0.1183\n",
      "Epoch 38/80 took 0.2133 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Training Loss = 3.6207, Validation Loss = 3.4879, Validation Accuracy = 0.1362\n",
      "Epoch 39/80 took 0.2075 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Training Loss = 3.4611, Validation Loss = 3.4306, Validation Accuracy = 0.1496\n",
      "Epoch 40/80 took 0.2142 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Training Loss = 3.4135, Validation Loss = 3.3559, Validation Accuracy = 0.1585\n",
      "Epoch 41/80 took 0.2072 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Training Loss = 3.1410, Validation Loss = 3.1866, Validation Accuracy = 0.1942\n",
      "Epoch 42/80 took 0.2235 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Training Loss = 3.1141, Validation Loss = 3.0232, Validation Accuracy = 0.2433\n",
      "Epoch 43/80 took 0.2100 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Training Loss = 2.8727, Validation Loss = 2.7813, Validation Accuracy = 0.2924\n",
      "Epoch 44/80 took 0.2074 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Training Loss = 2.7759, Validation Loss = 2.4738, Validation Accuracy = 0.3750\n",
      "Epoch 45/80 took 0.2154 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Training Loss = 2.4954, Validation Loss = 2.3168, Validation Accuracy = 0.3683\n",
      "Epoch 46/80 took 0.2117 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Training Loss = 2.2750, Validation Loss = 2.1809, Validation Accuracy = 0.4509\n",
      "Epoch 47/80 took 0.2087 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Training Loss = 2.1306, Validation Loss = 1.8859, Validation Accuracy = 0.5179\n",
      "Epoch 48/80 took 0.2140 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Training Loss = 1.8017, Validation Loss = 1.5069, Validation Accuracy = 0.5804\n",
      "Epoch 49/80 took 0.2094 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Training Loss = 1.3765, Validation Loss = 1.4632, Validation Accuracy = 0.6183\n",
      "Epoch 50/80 took 0.2151 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Training Loss = 1.3615, Validation Loss = 1.2228, Validation Accuracy = 0.6964\n",
      "Epoch 51/80 took 0.2112 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Training Loss = 1.0855, Validation Loss = 1.1311, Validation Accuracy = 0.7076\n",
      "Epoch 52/80 took 0.2103 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: Training Loss = 1.0066, Validation Loss = 0.8174, Validation Accuracy = 0.7746\n",
      "Epoch 53/80 took 0.2142 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Training Loss = 0.7784, Validation Loss = 0.6644, Validation Accuracy = 0.8438\n",
      "Epoch 54/80 took 0.2090 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Training Loss = 0.6468, Validation Loss = 0.6464, Validation Accuracy = 0.8482\n",
      "Epoch 55/80 took 0.2151 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Training Loss = 0.5809, Validation Loss = 0.5779, Validation Accuracy = 0.8504\n",
      "Epoch 56/80 took 0.2115 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Training Loss = 0.5030, Validation Loss = 0.5158, Validation Accuracy = 0.8683\n",
      "Epoch 57/80 took 0.2107 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Training Loss = 0.4739, Validation Loss = 0.4189, Validation Accuracy = 0.8884\n",
      "Epoch 58/80 took 0.2155 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Training Loss = 0.2743, Validation Loss = 0.3711, Validation Accuracy = 0.9062\n",
      "Epoch 59/80 took 0.2114 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Training Loss = 0.2609, Validation Loss = 0.3744, Validation Accuracy = 0.9174\n",
      "Epoch 60/80 took 0.2126 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: Training Loss = 0.2218, Validation Loss = 0.2941, Validation Accuracy = 0.9353\n",
      "Epoch 61/80 took 0.2180 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: Training Loss = 0.2481, Validation Loss = 0.2252, Validation Accuracy = 0.9554\n",
      "Epoch 62/80 took 0.2141 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: Training Loss = 0.2203, Validation Loss = 0.2101, Validation Accuracy = 0.9397\n",
      "Epoch 63/80 took 0.2098 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: Training Loss = 0.1607, Validation Loss = 0.1577, Validation Accuracy = 0.9665\n",
      "Epoch 64/80 took 0.2151 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: Training Loss = 0.1325, Validation Loss = 0.1162, Validation Accuracy = 0.9688\n",
      "Epoch 65/80 took 0.2110 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: Training Loss = 0.0817, Validation Loss = 0.1045, Validation Accuracy = 0.9665\n",
      "Epoch 66/80 took 0.2111 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: Training Loss = 0.1265, Validation Loss = 0.0783, Validation Accuracy = 0.9754\n",
      "Epoch 67/80 took 0.2141 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: Training Loss = 0.0876, Validation Loss = 0.1056, Validation Accuracy = 0.9754\n",
      "Epoch 68/80 took 0.2084 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: Training Loss = 0.0493, Validation Loss = 0.1262, Validation Accuracy = 0.9688\n",
      "Epoch 69/80 took 0.2137 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: Training Loss = 0.1069, Validation Loss = 0.1178, Validation Accuracy = 0.9777\n",
      "Epoch 70/80 took 0.2087 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: Training Loss = 0.1005, Validation Loss = 0.0785, Validation Accuracy = 0.9799\n",
      "Epoch 71/80 took 0.2145 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: Training Loss = 0.0753, Validation Loss = 0.0920, Validation Accuracy = 0.9777\n",
      "Epoch 72/80 took 0.2148 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: Training Loss = 0.0862, Validation Loss = 0.1733, Validation Accuracy = 0.9554\n",
      "Epoch 73/80 took 0.2071 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: Training Loss = 0.0934, Validation Loss = 0.1278, Validation Accuracy = 0.9665\n",
      "Epoch 74/80 took 0.2155 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: Training Loss = 0.0865, Validation Loss = 0.1403, Validation Accuracy = 0.9754\n",
      "Epoch 75/80 took 0.2120 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: Training Loss = 0.0812, Validation Loss = 0.0764, Validation Accuracy = 0.9821\n",
      "Epoch 76/80 took 0.2122 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: Training Loss = 0.0789, Validation Loss = 0.1563, Validation Accuracy = 0.9710\n",
      "Epoch 77/80 took 0.2160 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: Training Loss = 0.1551, Validation Loss = 0.3448, Validation Accuracy = 0.9420\n",
      "Epoch 78/80 took 0.2127 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79: Training Loss = 0.1381, Validation Loss = 0.2727, Validation Accuracy = 0.9598\n",
      "Epoch 79/80 took 0.2098 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: Training Loss = 0.2125, Validation Loss = 0.1021, Validation Accuracy = 0.9777\n",
      "Epoch 80/80 took 0.2154 seconds\n",
      "Finished training after 80 epochs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([7.7651725,\n",
       "  4.6070657,\n",
       "  4.592352,\n",
       "  4.562155,\n",
       "  4.5742607,\n",
       "  4.540709,\n",
       "  4.5136595,\n",
       "  4.5531416,\n",
       "  4.529939,\n",
       "  4.514531,\n",
       "  4.501354,\n",
       "  4.4903398,\n",
       "  4.5405436,\n",
       "  4.5017595,\n",
       "  4.505933,\n",
       "  4.53881,\n",
       "  4.505358,\n",
       "  4.506524,\n",
       "  4.486269,\n",
       "  4.4880586,\n",
       "  4.497943,\n",
       "  4.450206,\n",
       "  4.426097,\n",
       "  4.419592,\n",
       "  4.341523,\n",
       "  4.4022803,\n",
       "  4.3482614,\n",
       "  4.345825,\n",
       "  4.2823424,\n",
       "  4.2886295,\n",
       "  4.155503,\n",
       "  4.185897,\n",
       "  4.155451,\n",
       "  4.145169,\n",
       "  4.05106,\n",
       "  3.9292145,\n",
       "  3.8931155,\n",
       "  3.7422056,\n",
       "  3.6206708,\n",
       "  3.461061,\n",
       "  3.413474,\n",
       "  3.1410463,\n",
       "  3.1140924,\n",
       "  2.872694,\n",
       "  2.7758555,\n",
       "  2.4953969,\n",
       "  2.2750418,\n",
       "  2.1306148,\n",
       "  1.801698,\n",
       "  1.376468,\n",
       "  1.361461,\n",
       "  1.0854856,\n",
       "  1.0065608,\n",
       "  0.77844626,\n",
       "  0.64682215,\n",
       "  0.5809196,\n",
       "  0.5030327,\n",
       "  0.4738898,\n",
       "  0.27428418,\n",
       "  0.260916,\n",
       "  0.22176293,\n",
       "  0.24809341,\n",
       "  0.22025491,\n",
       "  0.16066559,\n",
       "  0.1324631,\n",
       "  0.08172591,\n",
       "  0.12648809,\n",
       "  0.0875947,\n",
       "  0.049269788,\n",
       "  0.106942065,\n",
       "  0.10053298,\n",
       "  0.07531144,\n",
       "  0.08623174,\n",
       "  0.09335752,\n",
       "  0.08647495,\n",
       "  0.08121104,\n",
       "  0.07888458,\n",
       "  0.15508842,\n",
       "  0.13814007,\n",
       "  0.212492],\n",
       " [4.6127167,\n",
       "  4.5910516,\n",
       "  4.575048,\n",
       "  4.5537033,\n",
       "  4.556475,\n",
       "  4.549689,\n",
       "  4.5262403,\n",
       "  4.5301747,\n",
       "  4.5212812,\n",
       "  4.515349,\n",
       "  4.509826,\n",
       "  4.5183177,\n",
       "  4.5226765,\n",
       "  4.5209384,\n",
       "  4.522141,\n",
       "  4.5060453,\n",
       "  4.4959993,\n",
       "  4.5015473,\n",
       "  4.4876447,\n",
       "  4.480963,\n",
       "  4.46005,\n",
       "  4.4354334,\n",
       "  4.4127007,\n",
       "  4.3951273,\n",
       "  4.40367,\n",
       "  4.359256,\n",
       "  4.3677354,\n",
       "  4.2989106,\n",
       "  4.265506,\n",
       "  4.2113123,\n",
       "  4.325146,\n",
       "  4.240516,\n",
       "  4.1121097,\n",
       "  4.0590854,\n",
       "  3.935286,\n",
       "  3.866573,\n",
       "  3.7999573,\n",
       "  3.7107804,\n",
       "  3.48791,\n",
       "  3.4305522,\n",
       "  3.355942,\n",
       "  3.186584,\n",
       "  3.0232217,\n",
       "  2.7812903,\n",
       "  2.4737546,\n",
       "  2.3167717,\n",
       "  2.1809442,\n",
       "  1.8858637,\n",
       "  1.5069467,\n",
       "  1.4632356,\n",
       "  1.2228334,\n",
       "  1.1311114,\n",
       "  0.8173661,\n",
       "  0.6644243,\n",
       "  0.646442,\n",
       "  0.5778803,\n",
       "  0.5157949,\n",
       "  0.41890255,\n",
       "  0.37113637,\n",
       "  0.37443632,\n",
       "  0.29410443,\n",
       "  0.22524044,\n",
       "  0.21009314,\n",
       "  0.15773313,\n",
       "  0.116208725,\n",
       "  0.104527496,\n",
       "  0.07834948,\n",
       "  0.105622984,\n",
       "  0.12620266,\n",
       "  0.11776801,\n",
       "  0.07851547,\n",
       "  0.09196943,\n",
       "  0.17329752,\n",
       "  0.12780005,\n",
       "  0.14030781,\n",
       "  0.07636232,\n",
       "  0.15632701,\n",
       "  0.3447718,\n",
       "  0.27273703,\n",
       "  0.10205091],\n",
       " [0.008928572,\n",
       "  0.008928572,\n",
       "  0.008928572,\n",
       "  0.013392857,\n",
       "  0.026785715,\n",
       "  0.026785715,\n",
       "  0.015625,\n",
       "  0.026785715,\n",
       "  0.026785715,\n",
       "  0.026785715,\n",
       "  0.026785715,\n",
       "  0.026785715,\n",
       "  0.026785715,\n",
       "  0.026785715,\n",
       "  0.026785715,\n",
       "  0.026785715,\n",
       "  0.029017856,\n",
       "  0.026785715,\n",
       "  0.026785715,\n",
       "  0.03125,\n",
       "  0.026785715,\n",
       "  0.03348214,\n",
       "  0.03348214,\n",
       "  0.03794643,\n",
       "  0.035714287,\n",
       "  0.035714287,\n",
       "  0.015625,\n",
       "  0.029017856,\n",
       "  0.03794643,\n",
       "  0.035714287,\n",
       "  0.04464286,\n",
       "  0.071428575,\n",
       "  0.06026786,\n",
       "  0.0625,\n",
       "  0.09821428,\n",
       "  0.102678575,\n",
       "  0.11160714,\n",
       "  0.118303575,\n",
       "  0.13616072,\n",
       "  0.14955357,\n",
       "  0.15848215,\n",
       "  0.19419643,\n",
       "  0.24330357,\n",
       "  0.2924107,\n",
       "  0.375,\n",
       "  0.36830357,\n",
       "  0.45089287,\n",
       "  0.51785713,\n",
       "  0.58035713,\n",
       "  0.6183036,\n",
       "  0.6964286,\n",
       "  0.70758927,\n",
       "  0.7745536,\n",
       "  0.84375,\n",
       "  0.84821427,\n",
       "  0.8504464,\n",
       "  0.8683036,\n",
       "  0.88839287,\n",
       "  0.90625,\n",
       "  0.91741073,\n",
       "  0.93526787,\n",
       "  0.95535713,\n",
       "  0.93973213,\n",
       "  0.96651787,\n",
       "  0.96875,\n",
       "  0.96651787,\n",
       "  0.9754464,\n",
       "  0.9754464,\n",
       "  0.96875,\n",
       "  0.9776786,\n",
       "  0.97991073,\n",
       "  0.9776786,\n",
       "  0.95535713,\n",
       "  0.96651787,\n",
       "  0.9754464,\n",
       "  0.98214287,\n",
       "  0.97098213,\n",
       "  0.94196427,\n",
       "  0.9598214,\n",
       "  0.9776786],\n",
       " 80)"
      ]
     },
     "execution_count": 40,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model = ResNet18(100, (32,32,3), reg = 0)\n",
    "model.compile(optimizer='adamw')\n",
    "model.fit(x100_dev, y100_dev, x100_dev, y100_dev, max_epochs = 80, val_every = 1, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4733a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 8d. Train ResNet-18 on CIFAR-100\n",
    "\n",
    "In the cell below, train your ResNet-18 on CIFAR-100. Print out the test set after training concludes.\n",
    "\n",
    "Use regularization strength of `1.5`, a patience of `15`, learning rate patience of `4`, and keep the rest of the hyperparameters to their defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02bb64",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output) shape: [1, 100]\n",
      "Global Avg Pooling 2D layer output(GlobalAveragePool2D) shape: [1, 512]\n",
      "stack_4/block_2:\n",
      "\tConv2D layer output(stack_4/block_2/main_3x3conv_2) shape: [1, 4, 4, 512]\n",
      "\tConv2D layer output(stack_4/block_2/main_3x3conv_1) shape: [1, 4, 4, 512]\n",
      "stack_4/block_1:\n",
      "\tConv2D layer output(stack_4/block_1/main_3x3conv_2) shape: [1, 4, 4, 512]\n",
      "\tConv2D layer output(stack_4/block_1/main_3x3conv_1) shape: [1, 4, 4, 512]\n",
      "\t-->Conv2D1x1 layer output(stack_4/block_1/skip_conv1x1) shape: [1, 4, 4, 512]-->\n",
      "stack_3/block_2:\n",
      "\tConv2D layer output(stack_3/block_2/main_3x3conv_2) shape: [1, 8, 8, 256]\n",
      "\tConv2D layer output(stack_3/block_2/main_3x3conv_1) shape: [1, 8, 8, 256]\n",
      "stack_3/block_1:\n",
      "\tConv2D layer output(stack_3/block_1/main_3x3conv_2) shape: [1, 8, 8, 256]\n",
      "\tConv2D layer output(stack_3/block_1/main_3x3conv_1) shape: [1, 8, 8, 256]\n",
      "\t-->Conv2D1x1 layer output(stack_3/block_1/skip_conv1x1) shape: [1, 8, 8, 256]-->\n",
      "stack_2/block_2:\n",
      "\tConv2D layer output(stack_2/block_2/main_3x3conv_2) shape: [1, 16, 16, 128]\n",
      "\tConv2D layer output(stack_2/block_2/main_3x3conv_1) shape: [1, 16, 16, 128]\n",
      "stack_2/block_1:\n",
      "\tConv2D layer output(stack_2/block_1/main_3x3conv_2) shape: [1, 16, 16, 128]\n",
      "\tConv2D layer output(stack_2/block_1/main_3x3conv_1) shape: [1, 16, 16, 128]\n",
      "\t-->Conv2D1x1 layer output(stack_2/block_1/skip_conv1x1) shape: [1, 16, 16, 128]-->\n",
      "stack_1/block_2:\n",
      "\tConv2D layer output(stack_1/block_2/main_3x3conv_2) shape: [1, 32, 32, 64]\n",
      "\tConv2D layer output(stack_1/block_2/main_3x3conv_1) shape: [1, 32, 32, 64]\n",
      "stack_1/block_1:\n",
      "\tConv2D layer output(stack_1/block_1/main_3x3conv_2) shape: [1, 32, 32, 64]\n",
      "\tConv2D layer output(stack_1/block_1/main_3x3conv_1) shape: [1, 32, 32, 64]\n",
      "Conv2D layer output(Conv2D_1) shape: [1, 32, 32, 64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss = 4.4807, Validation Loss = 4.3247, Validation Accuracy = 0.0310\n",
      "Epoch 1/10000 took 22.5567 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Training Loss = 4.0047, Validation Loss = 3.8745, Validation Accuracy = 0.0857\n",
      "Epoch 2/10000 took 15.0865 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Training Loss = 3.6677, Validation Loss = 3.5173, Validation Accuracy = 0.1434\n",
      "Epoch 3/10000 took 14.9365 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Training Loss = 3.3394, Validation Loss = 3.3380, Validation Accuracy = 0.1863\n",
      "Epoch 4/10000 took 14.8153 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Training Loss = 3.1051, Validation Loss = 3.1257, Validation Accuracy = 0.2250\n",
      "Epoch 5/10000 took 14.7356 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Training Loss = 2.9119, Validation Loss = 2.9891, Validation Accuracy = 0.2632\n",
      "Epoch 6/10000 took 14.8328 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Training Loss = 2.7207, Validation Loss = 2.8123, Validation Accuracy = 0.2782\n",
      "Epoch 7/10000 took 15.0379 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Training Loss = 2.5909, Validation Loss = 2.7603, Validation Accuracy = 0.2953\n",
      "Epoch 8/10000 took 15.0378 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Training Loss = 2.4966, Validation Loss = 2.8089, Validation Accuracy = 0.2851\n",
      "Epoch 9/10000 took 15.0243 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Training Loss = 2.3849, Validation Loss = 2.7024, Validation Accuracy = 0.3213\n",
      "Epoch 10/10000 took 15.0783 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Training Loss = 2.3353, Validation Loss = 2.4976, Validation Accuracy = 0.3552\n",
      "Epoch 11/10000 took 15.1127 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Training Loss = 2.2788, Validation Loss = 2.4546, Validation Accuracy = 0.3622\n",
      "Epoch 12/10000 took 15.1059 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Training Loss = 2.2390, Validation Loss = 2.4102, Validation Accuracy = 0.3692\n",
      "Epoch 13/10000 took 15.1006 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Training Loss = 2.2255, Validation Loss = 2.5137, Validation Accuracy = 0.3566\n",
      "Epoch 14/10000 took 15.0910 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Training Loss = 2.2052, Validation Loss = 2.4308, Validation Accuracy = 0.3612\n",
      "Epoch 15/10000 took 15.0509 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Training Loss = 2.1687, Validation Loss = 2.3821, Validation Accuracy = 0.3740\n",
      "Epoch 16/10000 took 15.0760 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Training Loss = 2.1961, Validation Loss = 2.5463, Validation Accuracy = 0.3417\n",
      "Epoch 17/10000 took 15.0761 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Training Loss = 2.1444, Validation Loss = 2.3689, Validation Accuracy = 0.3810\n",
      "Epoch 18/10000 took 15.0882 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Training Loss = 2.1514, Validation Loss = 2.3846, Validation Accuracy = 0.3858\n",
      "Epoch 19/10000 took 15.1253 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Training Loss = 2.1057, Validation Loss = 2.3828, Validation Accuracy = 0.3788\n",
      "Epoch 20/10000 took 15.1341 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 0.001 Updated lr= 0.0005\n",
      "Epoch 21: Training Loss = 2.0858, Validation Loss = 2.5655, Validation Accuracy = 0.3490\n",
      "Epoch 21/10000 took 15.1431 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Training Loss = 1.7754, Validation Loss = 2.1037, Validation Accuracy = 0.4495\n",
      "Epoch 22/10000 took 15.1719 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Training Loss = 1.7072, Validation Loss = 2.2265, Validation Accuracy = 0.4225\n",
      "Epoch 23/10000 took 15.1405 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Training Loss = 1.6943, Validation Loss = 2.0471, Validation Accuracy = 0.4621\n",
      "Epoch 24/10000 took 15.1093 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Training Loss = 1.6668, Validation Loss = 2.0925, Validation Accuracy = 0.4377\n",
      "Epoch 25/10000 took 15.1471 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Training Loss = 1.6295, Validation Loss = 2.1270, Validation Accuracy = 0.4505\n",
      "Epoch 26/10000 took 15.1239 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Training Loss = 1.6176, Validation Loss = 2.0334, Validation Accuracy = 0.4575\n",
      "Epoch 27/10000 took 15.1943 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Training Loss = 1.5862, Validation Loss = 2.0980, Validation Accuracy = 0.4577\n",
      "Epoch 28/10000 took 15.1391 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Training Loss = 1.5762, Validation Loss = 2.1222, Validation Accuracy = 0.4459\n",
      "Epoch 29/10000 took 15.1134 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 0.0005 Updated lr= 0.00025\n",
      "Epoch 30: Training Loss = 1.5910, Validation Loss = 2.2245, Validation Accuracy = 0.4233\n",
      "Epoch 30/10000 took 15.1207 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Training Loss = 1.3033, Validation Loss = 1.9171, Validation Accuracy = 0.5004\n",
      "Epoch 31/10000 took 15.1128 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Training Loss = 1.2278, Validation Loss = 1.9719, Validation Accuracy = 0.4860\n",
      "Epoch 32/10000 took 15.1007 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Training Loss = 1.2165, Validation Loss = 1.9966, Validation Accuracy = 0.4958\n",
      "Epoch 33/10000 took 15.1249 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Training Loss = 1.1748, Validation Loss = 1.9575, Validation Accuracy = 0.4942\n",
      "Epoch 34/10000 took 15.1170 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Training Loss = 1.1578, Validation Loss = 1.9153, Validation Accuracy = 0.4974\n",
      "Epoch 35/10000 took 15.1159 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Training Loss = 1.1264, Validation Loss = 2.0925, Validation Accuracy = 0.4896\n",
      "Epoch 36/10000 took 15.1126 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Training Loss = 1.0911, Validation Loss = 2.0563, Validation Accuracy = 0.4886\n",
      "Epoch 37/10000 took 15.1205 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 0.00025 Updated lr= 0.000125\n",
      "Epoch 38: Training Loss = 1.0607, Validation Loss = 2.1085, Validation Accuracy = 0.4679\n",
      "Epoch 38/10000 took 15.1340 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Training Loss = 0.8567, Validation Loss = 2.0345, Validation Accuracy = 0.5072\n",
      "Epoch 39/10000 took 15.1466 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Training Loss = 0.7949, Validation Loss = 1.9935, Validation Accuracy = 0.5124\n",
      "Epoch 40/10000 took 15.1391 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Training Loss = 0.7598, Validation Loss = 2.0647, Validation Accuracy = 0.5020\n",
      "Epoch 41/10000 took 15.1635 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Training Loss = 0.7185, Validation Loss = 2.0647, Validation Accuracy = 0.5096\n",
      "Epoch 42/10000 took 15.1397 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 0.000125 Updated lr= 6.25e-05\n",
      "Epoch 43: Training Loss = 0.7002, Validation Loss = 2.1014, Validation Accuracy = 0.5028\n",
      "Epoch 43/10000 took 15.1498 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Training Loss = 0.5203, Validation Loss = 2.1462, Validation Accuracy = 0.5246\n",
      "Epoch 44/10000 took 15.1734 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Training Loss = 0.4782, Validation Loss = 2.1999, Validation Accuracy = 0.5214\n",
      "Epoch 45/10000 took 15.1492 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Training Loss = 0.4624, Validation Loss = 2.3012, Validation Accuracy = 0.4988\n",
      "Epoch 46/10000 took 15.1659 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Training Loss = 0.4267, Validation Loss = 2.3198, Validation Accuracy = 0.5164\n",
      "Epoch 47/10000 took 15.1437 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr= 6.25e-05 Updated lr= 3.125e-05\n",
      "Epoch 48: Training Loss = 0.4138, Validation Loss = 2.3522, Validation Accuracy = 0.5230\n",
      "Epoch 48/10000 took 15.1525 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Training Loss = 0.2974, Validation Loss = 2.4827, Validation Accuracy = 0.5200\n",
      "Early stopping triggered at epoch 49\n",
      "Finished training after 49 epochs!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.5331530570983887\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "model = ResNet18(100, (32,32,3), reg = 1.5)\n",
    "model.compile(optimizer='adamw')\n",
    "model.fit(x100_train, y100_train, x100_val, y100_val, val_every = 1, verbose = True, patience=15, lr_patience=4)\n",
    "print(f\"Test acc: {model.evaluate(x100_test, y100_test)[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09f13",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 8e. Visualize the predictions made by ResNet-18 on the CIFAR-100 test set.\n",
    "\n",
    "In the cell below, use your trained ResNet-18 to get the predicted classes of thr 1st 225 test set images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "519f31",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae12fe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Run the code below to create a 15x15 grid of CIFAR-100 images with the true and predicted classes in the title. The predicted classes are color-coded  blue if they are correct, red if they are incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "d31257",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "_,_,_,_, x100_test_vis, y100_test_vis, classnames = get_dataset('cifar100', standardize_ds=False)\n",
    "\n",
    "panel_sz = 4\n",
    "grid = 15\n",
    "fig, axes, = plt.subplots(nrows=grid, ncols=grid, figsize=(grid*panel_sz, grid*panel_sz))\n",
    "\n",
    "for r in range(grid):\n",
    "    for c in range(grid):\n",
    "        ind = grid*r + c\n",
    "        axes[r,c].imshow(x100_test_vis[ind])\n",
    "        axes[r,c].set_xticks([])\n",
    "        axes[r,c].set_yticks([])\n",
    "        title = f'{classnames[y100_test[ind]]}\\nPredicted: '\n",
    "        title += f'{classnames[y_pred[ind]]}'\n",
    "\n",
    "        color = 'blue'\n",
    "        if y100_test[ind] != y_pred[ind]:\n",
    "            color = 'red'\n",
    "\n",
    "        axes[r,c].set_title(title, color=color)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52896a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 8f. Questions\n",
    "\n",
    "**Question 5:** Take a look at the above montage. Does the mistakes made by ResNet-18 seem reasonable? Provide some specific examples to support your conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5d3c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Answer 5:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35002",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Extensions\n",
    "\n",
    "### General guidelines\n",
    "\n",
    "1. Never integrate extensions into your base project so that they change the expected behavior of core functions. If your extension changes the core design/behavior, no problem, duplicate your working base project and add features from there.\n",
    "2. Check the rubric to keep in mind how extensions on this project will be graded.\n",
    "3. While I may consult your code and \"written log\" of what you did, **I am grading your extensions based on what you present in your 3-5 min video.**\n",
    "3. I suggest documenting your explorations in a \"log\" or \"lab notebook\" style (i.e. documenting your thought/progression/discovery/learning process). I'm not grading your writing, so you can keep it succinct. **Whatever is most useful to you to remember what you did.** \n",
    "4. I suggest taking a hypothesis driven approach. For example \"I was curious about X so I explored Y. I found Z, which was not what I expected because..., so then tried A...\"\n",
    "5. Make plots to help showcase your results.\n",
    "6. **More is not necessarily better.** Generally, a small number of \"in-depth\" extensions count for more than many \"shallow\" extensions.\n",
    "\n",
    "### AI guidelines\n",
    "\n",
    "You may use AI in mostly any capacity for extensions. However, keep in mind:\n",
    "1. There is no need to use AI at all!\n",
    "2. You are welcome to use AI as a tool (e.g. automate something that is tedious, help you get unstuck, etc.). However, you should be coding, you should be thinking, you should be writing, you should be creating. If you are spending most (or even close to most) of your time typing into a chatbot and copy-pasting, you have probably gone too far with AI use.\n",
    "3. I don't find large volumes of AI generated code/text/plots to be particularly impressive and you risk losing my interest while grading. Remember: I'm grading your extensions based on your video presentation. **More is not necessarily better.**\n",
    "\n",
    "### Video guidelines\n",
    "\n",
    "1. Please try to keep your video to 5 minutes (*I have other projects to grade!*). If you turn in a longer video, I make no promise that I will watch more than 5 minutes.\n",
    "2. Your screen should be shared as you show me what you did. A live video of your face should also appear somewhere on the screen (e.g. picture-in-picture overlay / split screen).\n",
    "3. Your partner should join you for the video and take turns talking, but, if necessary, it is fine to have one team member present during the record the video.\n",
    "4. Do not simply read text from your notebook, do not read from a prepared script. I am not grading how polished your video presentation is (see extension grading criteria on rubric). \n",
    "5. I am looking for original and creative explorations sparked by your curiosity/interest/passion in a topic. This should be apparent in your video.\n",
    "6. Be natural,, don't feel the need to impress me with fancy language. If it is helpful, imagine that we are talking one-on-one about your extension. Tell me what you did :)\n",
    "\n",
    "### Extension ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5341",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1. ResNet-34\n",
    "\n",
    "Create and train the well-known network of the ResNet family called ResNet-34. Here is a suggested network configuration to experiment with:\n",
    "\n",
    "```\n",
    "block_units = [64, 128, 256, 512]\n",
    "num_blocks = [3, 4, 6, 3]\n",
    "first_block_strides = [1, 2, 2, 2]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764354",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2. ResNet-50\n",
    "\n",
    "Create and train the well-known network of the ResNet family called ResNet-50. Given its depth, it uses a \"Bottleneck block\" rather than a normal Residual Block, but the overall structure is very similar. Here is a suggested network configuration to experiment with:\n",
    "\n",
    "```\n",
    "block_units = [64, 128, 256, 512]\n",
    "num_blocks = [3, 4, 6, 3]\n",
    "first_block_strides = [1, 2, 2, 2]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc0b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 3. VGG networks on CIFAR-100\n",
    "\n",
    "How does one or more of your VGG networks do at classifying images in CIFAR-100?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de648",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 4. Other ResNets on CIFAR-10\n",
    "\n",
    "How do the other ResNets do at classifying images in CIFAR-10?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc06f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 5. Multi-network comparison\n",
    "\n",
    "Compare the accuracy, efficiency, etc of any number of networks from the VGG, Inception Net, and ResNet families."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bc08",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 6. Add support for saving/loading network weights\n",
    "\n",
    "A key limitation of your current deep learning library is that parameters that capture the learning in networks are completely reset/lost/wiped out when the notebook kernel is terminated. Add (and test!) support for saving network parameters to disk after (or periodically during) training. Add (and test!) support for loading network parameters back into the network from disk before training. \n",
    "\n",
    "Be careful to include the moving mean and standard deviation parameters in batch normalization layers otherwise the whole net will not work!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216e3a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 7. Other image datasets\n",
    "\n",
    "Apply any of the three deep network families to another dataset of your choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1707f2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 8. Hyperparameter tuning\n",
    "\n",
    "Try and find hyperparameters that allow Inception Net and the ResNets to achieve better accuracy on CIFAR-10 and/or CIFAR-100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704954",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 9. Build other Inception Nets\n",
    "\n",
    "We only built a single network, but just like VGG and ResNet, you can modify the network depth while following the computational motifs of the Inception Net architecture. Design and experiment with your own Inception Net!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0ede",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 10. Analyze errors made by one or more of the nets\n",
    "\n",
    "Make a confusion matrix for CIFAR-10 or CIFAR-100 (*a challenge to make it useful!*).\n",
    "\n",
    "Visualize the predictions made by Inception Net and/or a VGG net, perhaps similar what was done with the ResNet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel",
    "--HistoryManager.enabled=False",
    "--matplotlib=inline",
    "-c",
    "%config InlineBackend.figure_formats = set(['retina'])\nimport matplotlib; matplotlib.rcParams['figure.figsize'] = (12, 7)",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (system-wide)",
   "env": {
   },
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}