{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trey Tuscai and Gordon Doore\n",
    "\n",
    "Spring 2025\n",
    "\n",
    "CS 444: Deep Learning\n",
    "\n",
    "Project 1: Deep Neural Networks \n",
    "\n",
    "#### Week 4: Batch normalization and learning rate decay\n",
    "\n",
    "The continued focus this week is on strategies for training deep neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9. Batch normalization\n",
    "\n",
    "Batch normalization is one of the most powerful techniques for effectively training very deep neural networks. Let's implement batch normalization in the deep learning library and experiment with how integrating it with VGG networks affects classification accuracy on CIFAR-10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9a. Implement batch normalization\n",
    "\n",
    "Implement the following methods / make the following changes:\n",
    "\n",
    "**Layer:**\n",
    "- Constructor: If you have not already done so, make instance variables for the two batch normalization related parameters.\n",
    "- `is_doing_batchnorm`\n",
    "- `init_batchnorm_params`: Initialize the batch normalization parameters. The gain, bias, mean, and standard deviation.\n",
    "- `__call__`: Update how you compute the forward pass through the layer. If we are doing batch norm AND the batch norm moving mean is not `None`, perform batch normalization on the net input before the layer's activation is computed.\n",
    "\n",
    "**Dense**:\n",
    "- `compute_batch_norm(net_in, eps=0.001)`: Updates the running mini-batch mean and standard deviation during training and performs batch normalization on the net input signal.\n",
    "\n",
    "**Conv2D**:\n",
    "- `compute_batch_norm(net_in, eps=0.001)`: Updates the running mini-batch mean and standard deviation during training and performs batch normalization on the net input signal.\n",
    "\n",
    "**VGGConvBlock** and **VGGDenseBlock**:\n",
    "- In the constructors, pass along the `do_batch_norm` parameter to constituent layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "tex"
    }
   },
   "source": [
    "#### Test: `Dense` batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Test: Dense w/ linear (not training) ------------------------------\n",
      "Your net_acts (not in training mode) are\n",
      "[[ 0.1316 -0.1246  0.867  -0.0392 -0.1553]\n",
      " [ 0.1964 -0.0568  0.3891 -0.4167 -0.5647]]\n",
      "They should be:\n",
      "[[ 0.1316 -0.1246  0.867  -0.0392 -0.1553]\n",
      " [ 0.1964 -0.0568  0.3891 -0.4167 -0.5647]]\n",
      "------------------------------ Test: Dense w/ ReLU (not training) ------------------------------\n",
      "Your net_acts (not in training mode) are\n",
      "[[0.1861 0.     1.2261 0.     0.    ]\n",
      " [0.2777 0.     0.5503 0.     0.    ]]\n",
      "They should be:\n",
      "[[0.1861 0.     1.2261 0.     0.    ]\n",
      " [0.2777 0.     0.5503 0.     0.    ]]\n"
     ]
    }
   ],
   "source": [
    "print(30*'-', 'Test: Dense w/ linear (not training)', 30*'-')\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "dense = Dense('Test', units=5, prev_layer_or_block=None, wt_init='he', activation='linear', do_batch_norm=True)\n",
    "dense(tf.ones([1, 3]))\n",
    "dense.init_batchnorm_params()\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "net_acts = dense(tf.random.uniform([2, 3]))\n",
    "print(f'Your net_acts (not in training mode) are\\n{net_acts}')\n",
    "print('They should be:')\n",
    "print('''[[ 0.1316 -0.1246  0.867  -0.0392 -0.1553]\n",
    " [ 0.1964 -0.0568  0.3891 -0.4167 -0.5647]]''')\n",
    "\n",
    "print(30*'-', 'Test: Dense w/ ReLU (not training)', 30*'-')\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "dense = Dense('Test', units=5, prev_layer_or_block=None, wt_init='he', do_batch_norm=True)\n",
    "dense(tf.ones([1, 3]))\n",
    "dense.init_batchnorm_params()\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "net_acts = dense(tf.random.uniform([2, 3]))\n",
    "print(f'Your net_acts (not in training mode) are\\n{net_acts}')\n",
    "print('They should be:')\n",
    "print('''[[0.1861 0.     1.2261 0.     0.    ]\n",
    " [0.2777 0.     0.5503 0.     0.    ]]''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Test: Dense w/ linear (training) ------------------------------\n",
      "Your net_acts (in training mode) are\n",
      "[[-1.2303  1.1081 -0.1128  1.1738]\n",
      " [ 1.2109  0.16   -1.1564 -1.2605]\n",
      " [ 0.0194 -1.2681  1.2692  0.0866]]\n",
      "They should be:\n",
      "[[-1.2303  1.1081 -0.1128  1.1738]\n",
      " [ 1.2109  0.16   -1.1564 -1.2605]\n",
      " [ 0.0194 -1.2681  1.2692  0.0866]]\n",
      "------------------------------ Test: Dense w/ ReLU (training) ------------------------------\n",
      "Your net_acts (in training mode) are\n",
      "[[0.     0.     0.9971 0.9963 0.9966]\n",
      " [0.9787 0.9796 0.     0.     0.    ]]\n",
      "They should be:\n",
      "[[0.     0.     0.9971 0.9963 0.9966]\n",
      " [0.9787 0.9796 0.     0.     0.    ]]\n"
     ]
    }
   ],
   "source": [
    "print(30*'-', 'Test: Dense w/ linear (training)', 30*'-')\n",
    "tf.random.set_seed(0)\n",
    "dense = Dense('Test', units=4, prev_layer_or_block=None, wt_init='he', activation='linear', do_batch_norm=True)\n",
    "dense(tf.ones([1, 6]))\n",
    "dense.init_batchnorm_params()\n",
    "\n",
    "dense.set_mode(True)\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "net_acts = dense(tf.random.uniform([3, 6]))\n",
    "print(f'Your net_acts (in training mode) are\\n{net_acts}')\n",
    "print('They should be:')\n",
    "print('''[[-1.2303  1.1081 -0.1128  1.1738]\n",
    " [ 1.2109  0.16   -1.1564 -1.2605]\n",
    " [ 0.0194 -1.2681  1.2692  0.0866]]''')\n",
    "\n",
    "print(30*'-', 'Test: Dense w/ ReLU (training)', 30*'-')\n",
    "tf.random.set_seed(0)\n",
    "dense = Dense('Test', units=5, prev_layer_or_block=None, wt_init='he', do_batch_norm=True)\n",
    "dense(tf.ones([1, 3]))\n",
    "dense.init_batchnorm_params()\n",
    "\n",
    "dense.set_mode(True)\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "net_acts = dense(tf.random.uniform([2, 3]))\n",
    "print(f'Your net_acts (in training mode) are\\n{net_acts}')\n",
    "print('They should be:')\n",
    "print('''[[0.     0.     0.9971 0.9963 0.9966]\n",
    " [0.9787 0.9796 0.     0.     0.    ]]''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Test: Dense w/ ReLU multiple mini-batches ------------------------------\n",
      "Your net_acts after some mini-batches are\n",
      "[[0.9975 0.9953 0.     0.     0.    ]\n",
      " [0.     0.     0.9984 0.9953 0.9946]]\n",
      "They should be:\n",
      "[[0.9975 0.9953 0.     0.     0.    ]\n",
      " [0.     0.     0.9984 0.9953 0.9946]]\n",
      "After processing mini-batches in non-training mode, the net_acts are:\n",
      "[[0.2089 0.     0.5334 0.     0.    ]\n",
      " [0.2175 0.     1.505  0.     0.    ]]\n",
      "[[0.8584 0.0224 1.0932 0.     0.    ]\n",
      " [1.1234 0.2351 0.2997 0.     0.    ]]\n",
      "and should be:\n",
      "[[0.2089 0.     0.5334 0.     0.    ]\n",
      " [0.2175 0.     1.505  0.     0.    ]]\n",
      "[[0.8584 0.0224 1.0932 0.     0.    ]\n",
      " [1.1234 0.2351 0.2997 0.     0.    ]]\n"
     ]
    }
   ],
   "source": [
    "print(30*'-', 'Test: Dense w/ ReLU multiple mini-batches', 30*'-')\n",
    "tf.random.set_seed(0)\n",
    "dense = Dense('Test', units=5, prev_layer_or_block=None, wt_init='he', do_batch_norm=True)\n",
    "dense(tf.ones([1, 3]))\n",
    "dense.init_batchnorm_params()\n",
    "\n",
    "dense.set_mode(True)\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "for i in range(5):\n",
    "    net_acts = dense(tf.random.uniform([2, 3]))\n",
    "print(f'Your net_acts after some mini-batches are\\n{net_acts}')\n",
    "print('They should be:')\n",
    "print('''[[0.9975 0.9953 0.     0.     0.    ]\n",
    " [0.     0.     0.9984 0.9953 0.9946]]''')\n",
    "\n",
    "dense.set_mode(False)\n",
    "\n",
    "tf.random.set_seed(2)\n",
    "net_acts1 = dense(tf.random.uniform([2, 3]))\n",
    "net_acts2 = dense(tf.random.uniform([2, 3]))\n",
    "\n",
    "print('After processing mini-batches in non-training mode, the net_acts are:')\n",
    "print(net_acts1.numpy())\n",
    "print(net_acts2.numpy())\n",
    "print('and should be:')\n",
    "print('''[[0.2089 0.     0.5334 0.     0.    ]\n",
    " [0.2175 0.     1.505  0.     0.    ]]\n",
    "[[0.8584 0.0224 1.0932 0.     0.    ]\n",
    " [1.1234 0.2351 0.2997 0.     0.    ]]''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: `Conv2D` batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Test: Conv2D w/ linear (not training) ------------------------------\n",
      "Your net_acts (not in training mode) are\n",
      "[[[[-0.4583  0.3257 -0.7078 -0.3702]\n",
      "   [-0.1189  0.2832 -0.1614 -0.0745]]\n",
      "\n",
      "  [[ 0.4845  0.4109 -0.5069 -0.2724]\n",
      "   [ 0.1433  0.2664 -0.2008 -0.0392]]]\n",
      "\n",
      "\n",
      " [[[-0.2477  0.4331 -0.2983 -0.2121]\n",
      "   [-0.0728  0.2052 -0.1844  0.1303]]\n",
      "\n",
      "  [[ 0.2266  0.4893 -0.3521 -0.0567]\n",
      "   [ 0.0542  0.0702 -0.0703 -0.0319]]]]\n",
      "They should be:\n",
      "[[[[-0.4583  0.3257 -0.7078 -0.3702]\n",
      "   [-0.1189  0.2832 -0.1614 -0.0745]]\n",
      "\n",
      "  [[ 0.4845  0.4109 -0.5069 -0.2724]\n",
      "   [ 0.1433  0.2664 -0.2008 -0.0392]]]\n",
      "\n",
      "\n",
      " [[[-0.2477  0.4331 -0.2983 -0.2121]\n",
      "   [-0.0728  0.2052 -0.1844  0.1303]]\n",
      "\n",
      "  [[ 0.2266  0.4893 -0.3521 -0.0567]\n",
      "   [ 0.0542  0.0702 -0.0703 -0.0319]]]]\n"
     ]
    }
   ],
   "source": [
    "print(30*'-', 'Test: Conv2D w/ linear (not training)', 30*'-')\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "conv = Conv2D('Test', units=4, kernel_size=(2, 2), prev_layer_or_block=None, wt_init='he', activation='linear',\n",
    "              do_batch_norm=True)\n",
    "conv(tf.ones([1, 2, 2, 3]))\n",
    "conv.init_batchnorm_params()\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "net_acts = conv(tf.random.uniform([2, 2, 2, 3]))\n",
    "print(f'Your net_acts (not in training mode) are\\n{net_acts}')\n",
    "print('They should be:')\n",
    "print('''[[[[-0.4583  0.3257 -0.7078 -0.3702]\n",
    "   [-0.1189  0.2832 -0.1614 -0.0745]]\n",
    "\n",
    "  [[ 0.4845  0.4109 -0.5069 -0.2724]\n",
    "   [ 0.1433  0.2664 -0.2008 -0.0392]]]\n",
    "\n",
    "\n",
    " [[[-0.2477  0.4331 -0.2983 -0.2121]\n",
    "   [-0.0728  0.2052 -0.1844  0.1303]]\n",
    "\n",
    "  [[ 0.2266  0.4893 -0.3521 -0.0567]\n",
    "   [ 0.0542  0.0702 -0.0703 -0.0319]]]]''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Test: Conv2D w/ linear (training) ------------------------------\n",
      "Your net_acts (not in training mode) are\n",
      "[[[[-1.6719  0.1188 -2.0219 -1.6977]\n",
      "   [-0.4375 -0.2133  0.7571  0.2757]]\n",
      "\n",
      "  [[ 1.7572  0.7852 -1.     -1.0448]\n",
      "   [ 0.5163 -0.3449  0.5564  0.5117]]]\n",
      "\n",
      "\n",
      " [[[-0.9058  0.9583  0.0608 -0.6427]\n",
      "   [-0.2695 -0.8235  0.64    1.6431]]\n",
      "\n",
      "  [[ 0.8191  1.3981 -0.2129  0.3946]\n",
      "   [ 0.1922 -1.8786  1.2204  0.5601]]]]\n",
      "They should be:\n",
      "[[[[-1.6719  0.1188 -2.0219 -1.6977]\n",
      "   [-0.4375 -0.2133  0.7571  0.2757]]\n",
      "\n",
      "  [[ 1.7572  0.7852 -1.     -1.0448]\n",
      "   [ 0.5163 -0.3449  0.5564  0.5117]]]\n",
      "\n",
      "\n",
      " [[[-0.9058  0.9583  0.0608 -0.6427]\n",
      "   [-0.2695 -0.8235  0.64    1.6431]]\n",
      "\n",
      "  [[ 0.8191  1.3981 -0.2129  0.3946]\n",
      "   [ 0.1922 -1.8786  1.2204  0.5601]]]]\n"
     ]
    }
   ],
   "source": [
    "print(30*'-', 'Test: Conv2D w/ linear (training)', 30*'-')\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "conv = Conv2D('Test', units=4, kernel_size=(2, 2), prev_layer_or_block=None, wt_init='he', activation='linear',\n",
    "              do_batch_norm=True)\n",
    "conv(tf.ones([1, 2, 2, 3]))\n",
    "conv.init_batchnorm_params()\n",
    "\n",
    "conv.set_mode(True)\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "net_acts = conv(tf.random.uniform([2, 2, 2, 3]))\n",
    "print(f'Your net_acts (not in training mode) are\\n{net_acts}')\n",
    "print('They should be:')\n",
    "print('''[[[[-1.6719  0.1188 -2.0219 -1.6977]\n",
    "   [-0.4375 -0.2133  0.7571  0.2757]]\n",
    "\n",
    "  [[ 1.7572  0.7852 -1.     -1.0448]\n",
    "   [ 0.5163 -0.3449  0.5564  0.5117]]]\n",
    "\n",
    "\n",
    " [[[-0.9058  0.9583  0.0608 -0.6427]\n",
    "   [-0.2695 -0.8235  0.64    1.6431]]\n",
    "\n",
    "  [[ 0.8191  1.3981 -0.2129  0.3946]\n",
    "   [ 0.1922 -1.8786  1.2204  0.5601]]]]''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Test: Conv2D w/ ReLU multiple mini-batches ------------------------------\n",
      "Your net_acts after some mini-batches are\n",
      "[[[[0.     0.     0.252  0.    ]\n",
      "   [0.     0.1891 1.3142 0.4295]]\n",
      "\n",
      "  [[1.1739 0.     0.0018 0.4892]\n",
      "   [0.7065 0.     0.2646 0.7403]]]\n",
      "\n",
      "\n",
      " [[[0.     1.7817 0.     0.    ]\n",
      "   [0.     0.447  0.8604 0.5298]]\n",
      "\n",
      "  [[1.1745 0.8703 0.     0.5416]\n",
      "   [0.7664 0.     0.2116 0.6486]]]]\n",
      "They should be:\n",
      "[[[[0.     0.     0.252  0.    ]\n",
      "   [0.     0.1891 1.3142 0.4295]]\n",
      "\n",
      "  [[1.1739 0.     0.0018 0.4892]\n",
      "   [0.7065 0.     0.2646 0.7403]]]\n",
      "\n",
      "\n",
      " [[[0.     1.7817 0.     0.    ]\n",
      "   [0.     0.447  0.8604 0.5298]]\n",
      "\n",
      "  [[1.1745 0.8703 0.     0.5416]\n",
      "   [0.7664 0.     0.2116 0.6486]]]]\n"
     ]
    }
   ],
   "source": [
    "print(30*'-', 'Test: Conv2D w/ ReLU multiple mini-batches', 30*'-')\n",
    "tf.random.set_seed(0)\n",
    "conv = Conv2D('Test', units=4, kernel_size=(2, 2), prev_layer_or_block=None, wt_init='he', do_batch_norm=True)\n",
    "conv(tf.ones([1, 2, 2, 3]))\n",
    "conv.init_batchnorm_params()\n",
    "\n",
    "conv.set_mode(True)\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "for i in range(5):\n",
    "    net_acts = conv(tf.random.uniform([2, 2, 2, 3]))\n",
    "print(f'Your net_acts after some mini-batches are\\n{net_acts}')\n",
    "print('They should be:')\n",
    "print('''[[[[0.     0.     0.252  0.    ]\n",
    "   [0.     0.1891 1.3142 0.4295]]\n",
    "\n",
    "  [[1.1739 0.     0.0018 0.4892]\n",
    "   [0.7065 0.     0.2646 0.7403]]]\n",
    "\n",
    "\n",
    " [[[0.     1.7817 0.     0.    ]\n",
    "   [0.     0.447  0.8604 0.5298]]\n",
    "\n",
    "  [[1.1745 0.8703 0.     0.5416]\n",
    "   [0.7664 0.     0.2116 0.6486]]]]''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.set_mode(False)\n",
    "\n",
    "tf.random.set_seed(2)\n",
    "for i in range(2):\n",
    "    net_acts = conv(tf.random.uniform([2, 2, 2, 3]))\n",
    "\n",
    "print('After processing mini-batches in non-training mode, the net_acts are:')\n",
    "print(net_acts.numpy())\n",
    "print('and should be:')\n",
    "print('''[[[[0.     0.0107 0.     0.    ]\n",
    "   [0.     0.2271 0.3021 0.    ]]\n",
    "\n",
    "  [[0.0629 0.0541 0.     0.0349]\n",
    "   [0.     0.3308 0.     0.1565]]]\n",
    "\n",
    "\n",
    " [[[0.     0.4355 0.     0.    ]\n",
    "   [0.     0.     0.2244 0.4117]]\n",
    "\n",
    "  [[0.0396 0.2184 0.     0.058 ]\n",
    "   [0.4179 0.3454 0.     0.    ]]]]''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9b. Create VGG networks that use batch normalization\n",
    "\n",
    "In `vgg_nets.py`, create the `VGG4Plus`, `VGG15Plus`, and `VGG15PlusPlus` networks. These are the same as the corresponding nets you have already implemented, except these networks have batch normalization throughout in the conv and dense layers. The `VGG15PlusPlus` network differs from `VGG15Plus` in the use of dropout in the all of the conv blocks (not just before the final dense layer). This should be quick with some copy-pasting.\n",
    "\n",
    "**NOTE:** If your net_acts below are off in some cases by one number in the right-most least significant decimal place **that is fine!**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg_nets import VGG4Plus, VGG15Plus, VGG15PlusPlus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: VGG4Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = VGG4Plus(C=3, input_feats_shape=(32, 32, 3), wt_init='he')\n",
    "v.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above should print:\n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "Dense layer output(output) shape: [1, 3]\n",
    "Dropout layer output(dropout1) shape: [1, 128]\n",
    "Dense layer output(dense1) shape: [1, 128]\n",
    "Flatten layer output(flat) shape: [1, 16384]\n",
    "MaxPool2D layer output(maxpool1) shape: [1, 16, 16, 64]\n",
    "Conv2D layer output(conv2) shape: [1, 32, 32, 64]\n",
    "Conv2D layer output(conv1) shape: [1, 32, 32, 64]\n",
    "---------------------------------------------------------------------------\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "v = VGG4Plus(C=3, input_feats_shape=(32, 32, 5), wt_init='he')\n",
    "tf.random.set_seed(1)\n",
    "net_acts = v(tf.random.uniform([2, 32, 32, 5]))\n",
    "\n",
    "print(f'Your net_acts are\\n{net_acts.numpy()} and should be')\n",
    "print('''[[0.2328 0.6381 0.1291]\n",
    " [0.2    0.6335 0.1664]]''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: VGG15Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = VGG15Plus(C=7, input_feats_shape=(32, 32, 3), wt_init='he')\n",
    "v.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above should print:\n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "Dense layer output(output) shape: [1, 7]\n",
    "DenseBlock1:\n",
    "\tDropout layer output(DenseBlock1/dropout) shape: [1, 512]\n",
    "\tDense layer output(DenseBlock1/dense0) shape: [1, 512]\n",
    "Flatten layer output(flat) shape: [1, 512]\n",
    "ConvBlock4:\n",
    "\tMaxPool2D layer output(ConvBlock4/maxpool2) shape: [1, 1, 1, 512]\n",
    "\tConv2D layer output(ConvBlock4/conv2) shape: [1, 2, 2, 512]\n",
    "\tConv2D layer output(ConvBlock4/conv1) shape: [1, 2, 2, 512]\n",
    "\tConv2D layer output(ConvBlock4/conv0) shape: [1, 2, 2, 512]\n",
    "ConvBlock3:\n",
    "\tMaxPool2D layer output(ConvBlock3/maxpool2) shape: [1, 2, 2, 512]\n",
    "\tConv2D layer output(ConvBlock3/conv2) shape: [1, 4, 4, 512]\n",
    "\tConv2D layer output(ConvBlock3/conv1) shape: [1, 4, 4, 512]\n",
    "\tConv2D layer output(ConvBlock3/conv0) shape: [1, 4, 4, 512]\n",
    "ConvBlock3:\n",
    "\tMaxPool2D layer output(ConvBlock3/maxpool2) shape: [1, 4, 4, 256]\n",
    "\tConv2D layer output(ConvBlock3/conv2) shape: [1, 8, 8, 256]\n",
    "\tConv2D layer output(ConvBlock3/conv1) shape: [1, 8, 8, 256]\n",
    "\tConv2D layer output(ConvBlock3/conv0) shape: [1, 8, 8, 256]\n",
    "ConvBlock2:\n",
    "\tMaxPool2D layer output(ConvBlock2/maxpool2) shape: [1, 8, 8, 128]\n",
    "\tConv2D layer output(ConvBlock2/conv1) shape: [1, 16, 16, 128]\n",
    "\tConv2D layer output(ConvBlock2/conv0) shape: [1, 16, 16, 128]\n",
    "ConvBlock1:\n",
    "\tMaxPool2D layer output(ConvBlock1/maxpool2) shape: [1, 16, 16, 64]\n",
    "\tConv2D layer output(ConvBlock1/conv1) shape: [1, 32, 32, 64]\n",
    "\tConv2D layer output(ConvBlock1/conv0) shape: [1, 32, 32, 64]\n",
    "---------------------------------------------------------------------------\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "v = VGG15Plus(C=7, input_feats_shape=(32, 32, 3), wt_init='he')\n",
    "tf.random.set_seed(1)\n",
    "net_acts = v(tf.random.uniform([2, 32, 32, 3]))\n",
    "\n",
    "print(f'Your net_acts are\\n{net_acts.numpy()} and should be')\n",
    "print('''[[0.0607 0.0949 0.0982 0.0789 0.3175 0.091  0.2587]\n",
    " [0.0693 0.0891 0.0968 0.0766 0.3231 0.0881 0.257 ]]''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: VGG15PlusPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = VGG15PlusPlus(C=5, input_feats_shape=(32, 32, 3), wt_init='he')\n",
    "v.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above should print:\n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "Dense layer output(output) shape: [1, 5]\n",
    "DenseBlock1:\n",
    "\tDropout layer output(DenseBlock1/dropout) shape: [1, 512]\n",
    "\tDense layer output(DenseBlock1/dense0) shape: [1, 512]\n",
    "Flatten layer output(flat) shape: [1, 512]\n",
    "ConvBlock4:\n",
    "\tDropout layer output(ConvBlock4/dropout) shape: [1, 1, 1, 512]\n",
    "\tMaxPool2D layer output(ConvBlock4/maxpool2) shape: [1, 1, 1, 512]\n",
    "\tConv2D layer output(ConvBlock4/conv2) shape: [1, 2, 2, 512]\n",
    "\tConv2D layer output(ConvBlock4/conv1) shape: [1, 2, 2, 512]\n",
    "\tConv2D layer output(ConvBlock4/conv0) shape: [1, 2, 2, 512]\n",
    "ConvBlock3:\n",
    "\tDropout layer output(ConvBlock3/dropout) shape: [1, 2, 2, 512]\n",
    "\tMaxPool2D layer output(ConvBlock3/maxpool2) shape: [1, 2, 2, 512]\n",
    "\tConv2D layer output(ConvBlock3/conv2) shape: [1, 4, 4, 512]\n",
    "\tConv2D layer output(ConvBlock3/conv1) shape: [1, 4, 4, 512]\n",
    "\tConv2D layer output(ConvBlock3/conv0) shape: [1, 4, 4, 512]\n",
    "ConvBlock3:\n",
    "\tDropout layer output(ConvBlock3/dropout) shape: [1, 4, 4, 256]\n",
    "\tMaxPool2D layer output(ConvBlock3/maxpool2) shape: [1, 4, 4, 256]\n",
    "\tConv2D layer output(ConvBlock3/conv2) shape: [1, 8, 8, 256]\n",
    "\tConv2D layer output(ConvBlock3/conv1) shape: [1, 8, 8, 256]\n",
    "\tConv2D layer output(ConvBlock3/conv0) shape: [1, 8, 8, 256]\n",
    "ConvBlock2:\n",
    "\tDropout layer output(ConvBlock2/dropout) shape: [1, 8, 8, 128]\n",
    "\tMaxPool2D layer output(ConvBlock2/maxpool2) shape: [1, 8, 8, 128]\n",
    "\tConv2D layer output(ConvBlock2/conv1) shape: [1, 16, 16, 128]\n",
    "\tConv2D layer output(ConvBlock2/conv0) shape: [1, 16, 16, 128]\n",
    "ConvBlock1:\n",
    "\tDropout layer output(ConvBlock1/dropout) shape: [1, 16, 16, 64]\n",
    "\tMaxPool2D layer output(ConvBlock1/maxpool2) shape: [1, 16, 16, 64]\n",
    "\tConv2D layer output(ConvBlock1/conv1) shape: [1, 32, 32, 64]\n",
    "\tConv2D layer output(ConvBlock1/conv0) shape: [1, 32, 32, 64]\n",
    "---------------------------------------------------------------------------\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "v = VGG15PlusPlus(C=5, input_feats_shape=(32, 32, 3), wt_init='he')\n",
    "tf.random.set_seed(1)\n",
    "net_acts = v(tf.random.uniform([2, 32, 32, 3]))\n",
    "\n",
    "print(f'Your net_acts are\\n{net_acts.numpy()} and should be')\n",
    "print('''[[0.0962 0.2981 0.2029 0.3189 0.0838]\n",
    " [0.0893 0.2785 0.2156 0.3299 0.0868]]''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9c. Trial run of training VGG4Plus, VGG15Plus, and VGG15PlusPlus on CIFAR-10\n",
    "\n",
    "Load in CIFAR-10 below and train the 3 networks that use batch normalization for `1` epoch. Use the AdamW optimizer and otherwise keep default hyperparameters. Print out the test accuracy after teach training run. You should get (*approximately*):\n",
    "\n",
    "```\n",
    "VGG4Plus test acc: 61.41\n",
    "VGG15Plus test acc: 37.71\n",
    "VGG15PlusPlus test acc: 22.29\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9d. Train VGG4Plus, VGG15Plus, and VGG15PlusPlus on CIFAR-10\n",
    "\n",
    "Now that the networks have been tested, do a full training session with the following networks on CIFAR-10:\n",
    "- VGG4Plus\n",
    "- VGG15\n",
    "- VGG15Plus\n",
    "- VGG15PlusPlus\n",
    "\n",
    "Use default hyperparameters except:\n",
    "- Use AdamW optimizer.\n",
    "- Use He initialization\n",
    "- Use a patience of `4`. *If your earlier early stopping test did not end in the same number of epochs as the test code, you might want to try a patience of 5 or 6.*\n",
    "\n",
    "After training each net, store/record:\n",
    "1. the network's final test accuracy.\n",
    "2. the history of training loss (averaged across mini-batches, so one per epoch).\n",
    "3. the history of validation loss (checked every epoch).\n",
    "4. the history of validation accuracy (checked every epoch).\n",
    "\n",
    "**Notes:**\n",
    "- Set random seed before creating each net for consistency.\n",
    "- Use `tf.keras.backend.clear_session()` before creating each of the network to help prevent the memory used from growing.\n",
    "\n",
    "Training these networks should take ~30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg_nets import VGG15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_acc_x3(train_losses, val_losses, val_accs, epochs,\n",
    "                     net_names=['VGG15PlusPlus', 'VGG15', 'VGG15Plus', 'VGG4Plus']):\n",
    "    '''Makes a 3x1 plot of the training losses, val losses, and val accs for the 4 nets.\n",
    "\n",
    "    This complete function is provided to you. Feel free to modify if necessary.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_losses: Python list of list. len(train_losses)=4.\n",
    "        List of the training loss histories of the 4 nets.\n",
    "    val_losses: Python list of list. len(val_losses)=4.\n",
    "        List of the val loss histories of the 4 nets.\n",
    "    val_accs: Python list of list. len(val_accs)=4.\n",
    "        List of the val accuracy histories of the 4 nets.\n",
    "    epochs: Python list of int. len(epochs)=4.\n",
    "        The number of epochs used to train each network.\n",
    "    net_names: Python list of str. len(epochs)=4.\n",
    "        The string name of the networks. The order must correspond to the order of the loss and acc lists.\n",
    "    '''\n",
    "    fig, axes = plt.subplots(ncols=1, nrows=3, sharex=True, figsize=(5, 12))\n",
    "\n",
    "    titles = ['CIFAR-10 Training Loss', 'CIFAR-10 Val Loss', 'CIFAR-10 Val Acc']\n",
    "    xlabels = 3*['Epoch']\n",
    "    data = [train_losses, val_losses, val_accs]\n",
    "\n",
    "    for i in range(len(titles)):\n",
    "        curr_hist = data[i]\n",
    "\n",
    "        for n in range(len(net_names)):\n",
    "            curr_data = np.copy(np.array(curr_hist[n]))\n",
    "\n",
    "            if 'acc' in titles[i].lower():\n",
    "                curr_data = 100*curr_data[:epochs[n]]\n",
    "\n",
    "            axes[i].plot(curr_data, label=net_names[n])\n",
    "\n",
    "        axes[i].set_xlabel(xlabels[i])\n",
    "        # axes[i].set_ylabel(ylabels[i])\n",
    "        axes[i].set_title(titles[i])\n",
    "\n",
    "        if i == 0:\n",
    "            axes[i].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9e. Questions\n",
    "\n",
    "**Question 13** How does the runtime (per epoch) of the networks with batch normalization compare without it (e.g. `VGG15` vs. `VGG15Plus`)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 13:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10. Learning rate decay\n",
    "\n",
    "The classification accuracy of the networks with batch normalization may seem a little underwhelming...but we can change that! A synergistic tool to potentially unlock improved classification accuracy is **learning rate decay.** We will adopt the simple approach of multiplicatively adjusting the learning rate. That is:\n",
    "\n",
    "$$\n",
    "\\eta_{new} = d \\times \\eta_{curr}\n",
    "$$\n",
    "\n",
    "where $\\eta$ is the learning rate and $d$ is a float between 0.0 and 1.0. This learning rate update does not occur on every epoch — it only gets applied when the validation loss stops improving for some number of epochs (i.e. the learning rate patience). This means we add and maintain an independent early stopping process dedicated to the learning rate.\n",
    "\n",
    "Let's add this to the training workflow then revisit the performance of the networks with batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg_nets import VGG15PlusPlus, VGG15, VGG15Plus, VGG4Plus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10a. Add support for learning rate decay in `DeepNetwork`\n",
    "\n",
    "Follow the procedure outlined in class add learning rate decay to the training workflow. Here is a brief summary:\n",
    "1. Implement `update_lr(lr_decay_rate)` to multiplicatively adjust the optimizer's learning rate.\n",
    "2. In `fit`, create a separate new empty list before the training loop to represent the rolling validation loss related to the learning rate decay process.\n",
    "3. In `fit`, adjacent to where you check early stopping for training epochs, check \"early stopping\" for learning rate. If \"early stopping\" is triggered for the learning rate, decrease the learning rate. Only decrease the learning rate a preset number of times (`lr_max_decays`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import Dense\n",
    "from network import DeepNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: Learning rate decay\n",
    "\n",
    "The following test trains a single layer softmax network on Iris. If everything is working as expected, you should see:\n",
    "- learning rate decays from 0.1 to 0.05 during epoch 6.\n",
    "- learning rate decays from 0.05 to 0.025 during epoch 25.\n",
    "- learning rate decays from 0.025 to 0.0125 during epoch 39.\n",
    "- learning rate decays from 0.0125 to 0.00625 during epoch 53.\n",
    "- training ends after 65 epochs.\n",
    "\n",
    "**Note:** If you do not get these exact results, that could be fine. What you are looking for is a drop in the learning rate when the val loss does not improve/decrease within a window of 3 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quickly make a mock network for testing\n",
    "class SoftmaxNet(DeepNetwork):\n",
    "    def __init__(self, input_feats_shape, C, reg=0):\n",
    "        super().__init__(input_feats_shape, reg)\n",
    "        self.output_layer = Dense('TestDense', units=C, activation='softmax', prev_layer_or_block=None)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Load in Iris train/validation sets\n",
    "train_samps = tf.constant(np.load('data/iris/iris_train_samps.npy'), dtype=tf.float32)\n",
    "train_labels = tf.constant(np.load('data/iris/iris_train_labels.npy'), dtype=tf.int32)\n",
    "val_samps = tf.constant(np.load('data/iris/iris_val_samps.npy'), dtype=tf.float32)\n",
    "val_labels = tf.constant(np.load('data/iris/iris_val_labels.npy'), dtype=tf.int32)\n",
    "\n",
    "# Set some vars\n",
    "C = 3\n",
    "M = train_samps.shape[1]\n",
    "mini_batch_sz = 25\n",
    "lr = 1e-1\n",
    "max_epochs = 5000\n",
    "patience = 7\n",
    "val_every = 1  # how often (in epochs) we check the val loss/acc/early stopping\n",
    "\n",
    "# Create our test net\n",
    "tf.random.set_seed(0)\n",
    "slnet = SoftmaxNet((M,), C)\n",
    "slnet.compile(lr=lr)\n",
    "\n",
    "_, val_loss_hist, val_acc_hist, e = slnet.fit(train_samps, train_labels, val_samps, val_labels,\n",
    "                                              batch_size=mini_batch_sz,\n",
    "                                              max_epochs=max_epochs,\n",
    "                                              patience=patience,\n",
    "                                              val_every=val_every,\n",
    "                                              lr_patience=3,\n",
    "                                              lr_max_decays=4)\n",
    "\n",
    "print(75*'-')\n",
    "print(f'Iris test ended after {e} epochs with final val loss/acc of {val_loss_hist[-1]:.2f}/{val_acc_hist[-1]:.2f}')\n",
    "print(75*'-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10b. Train VGG nets with batch normalization redux\n",
    "\n",
    "Repeat the training session you performed in the previous task involving the \"plus networks\" on CIFAR-10:\n",
    "- VGG4Plus\n",
    "- VGG15\n",
    "- VGG15Plus\n",
    "- VGG15PlusPlus\n",
    "\n",
    "Use default hyperparameters except:\n",
    "- Use AdamW optimizer.\n",
    "- Use He initialization\n",
    "- Use a patience of `15`.\n",
    "- Use a learning rate patience of 4.\n",
    "\n",
    "After training each net, store/record:\n",
    "1. the network's final test accuracy.\n",
    "2. the history of training loss (averaged across mini-batches, so one per epoch).\n",
    "3. the history of validation loss (checked every epoch).\n",
    "4. the history of validation accuracy (checked every epoch).\n",
    "\n",
    "**Notes:**\n",
    "- Set random seed before creating each net for consistency.\n",
    "- Use `tf.keras.backend.clear_session()` before creating each of the network to help prevent the memory used from growing.\n",
    "\n",
    "Training these networks should take a few hours. Your VGG15PlusPlus network should achieve the best results and shatter your previous CIFAR-10 val/test accuracy record by a substantial margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapt the following code to plot your findings. `plot_loss_acc_x3` is defined in the previous task above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_acc_x3(train_losses_bn, val_losses_bn, val_accs_bn, epochs_bn)\n",
    "\n",
    "print('CIFAR-10 test accuracy:')\n",
    "for i in range(len(net_names)):\n",
    "    print(f'{net_names[i]}: {100*accs_bn[i]:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10c. Questions\n",
    "\n",
    "**Question 14** What did the results of this experiment reveal about the relationship about network depth/size and classification accuracy? Please be specific.\n",
    "\n",
    "**Question 15** Are there any downsides to the highest performing network (or is it just totally awesome :)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 14:** \n",
    "\n",
    "**Answer 15:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "### General guidelines\n",
    "\n",
    "1. Never integrate extensions into your base project so that they change the expected behavior of core functions. If your extension changes the core design/behavior, no problem, duplicate your working base project and add features from there.\n",
    "2. Check the rubric to keep in mind how extensions on this project will be graded.\n",
    "3. While I may consult your code and \"written log\" of what you did, **I am grading your extensions based on what you present in your 3-5 min video.**\n",
    "3. I suggest documenting your explorations in a \"log\" or \"lab notebook\" style (i.e. documenting your thought/progression/discovery/learning process). I'm not grading your writing, so you can keep it succinct. **Whatever is most useful to you to remember what you did.** \n",
    "4. I suggest taking a hypothesis driven approach. For example \"I was curious about X so I explored Y. I found Z, which was not what I expected because..., so then tried A...\"\n",
    "5. Make plots to help showcase your results.\n",
    "6. **More is not necessarily better.** Generally, a small number of \"in-depth\" extensions count for more than many \"shallow\" extensions.\n",
    "\n",
    "### AI guidelines\n",
    "\n",
    "You may use AI in mostly any capacity for extensions. However, keep in mind:\n",
    "1. There is no need to use AI at all!\n",
    "2. You are welcome to use AI as a tool (e.g. automate something that is tedious, help you get unstuck, etc.). However, you should be coding, you should be thinking, you should be writing, you should be creating. If you are spending most (or even close to most) of your time typing into a chatbot and copy-pasting, you have probably gone too far with AI use.\n",
    "3. I don't find large volumes of AI generated code/text/plots to be particularly impressive and you risk losing my interest while grading. Remember: I'm grading your extensions based on your video presentation. **More is not necessarily better.**\n",
    "\n",
    "### Video guidelines\n",
    "\n",
    "1. Please try to keep your video to 5 minutes (*I have other projects to grade!*). If you turn in a longer video, I make no promise that I will watch more than 5 minutes.\n",
    "2. Your screen should be shared as you show me what you did. A live video of your face should also appear somewhere on the screen (e.g. picture-in-picture overlay / split screen).\n",
    "3. Your partner should join you for the video and take turns talking, but, if necessary, it is fine to have one team member present during the record the video.\n",
    "4. Do not simply read text from your notebook, do not read from a prepared script. I am not grading how polished your video presentation is (see extension grading criteria on rubric). \n",
    "5. I am looking for original and creative explorations sparked by your curiosity/interest/passion in a topic. This should be apparent in your video.\n",
    "6. Be natural,, don't feel the need to impress me with fancy language. If it is helpful, imagine that we are talking one-on-one about your extension. Tell me what you did :)\n",
    "\n",
    "### Extension ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Tune hyperparameters to achieve even better classification accuracy\n",
    "\n",
    "Try to squeeze out a few extra percent test accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Other image datasets\n",
    "\n",
    "You now have a family of fast, high performing neural networks ranging in size. Apply them to another dataset of your choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. AlexNet\n",
    "\n",
    "Research the original AlexNet architecture and create a network that implements it. *You may have to ignore a few \"hacks\" Krizhevsky and colleagues had to perform — as pioneers, they were operating at the absolute limit of what GPUs of the day could do!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Add support for saving/loading network weights\n",
    "\n",
    "A key limitation of your current deep learning library is that parameters that capture the learning in networks are completely reset/lost/wiped out when the notebook kernel is terminated. Add (and test!) support for saving network parameters to disk after (or periodically during) training. Add (and test!) support for loading network parameters back into the network from disk before training. \n",
    "\n",
    "Be careful to include the moving mean and standard deviation parameters in batch normalization layers otherwise the whole net will not work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. VGG15 vs. VGG16\n",
    "\n",
    "VGG16 has another Block of Dense layers compared to VGG15. Additionally, the VGG nets in the paper use 4096 dense units per Dense layer (vs 512 in your nets). Is deeper and more units better? Try it out!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs444",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
